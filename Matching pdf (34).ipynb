{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0751f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import pandas as pd\n",
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "# Define a list of common stopwords to exclude from matching\n",
    "stopwords = [\"in\", \"the\", \"what\", \"why\", \"at\", \"and\", \"to\", \"of\", \"a\", \"an\", \"is\"]  # Add more stopwords as needed\n",
    "\n",
    "# ... (same code as before to extract PDF paragraphs and prepare Excel data) ...\n",
    "\n",
    "# Set the threshold for the match score\n",
    "threshold_score = 60\n",
    "\n",
    "matching_results = []\n",
    "\n",
    "for paragraph_number, paragraph_text in enumerate(pdf_paragraphs, start=1):\n",
    "    for index, row in excel_data.iterrows():\n",
    "        title = row['Title']\n",
    "        description = row['Description']\n",
    "        objective = row['Objective']\n",
    "        objective_name = row['Objective Name']  # Assuming this column exists in your Excel data\n",
    "        \n",
    "        matched_title_keywords = []\n",
    "        matched_description_keywords = []\n",
    "        matched_objective_keywords = []\n",
    "        \n",
    "        for keyword in title.split('\\n'):\n",
    "            keyword = keyword.strip()\n",
    "            \n",
    "            best_match_info = process.extractOne(keyword.lower(), paragraph_text.lower().split(), scorer=fuzz.token_sort_ratio)\n",
    "            match_score = best_match_info[1]\n",
    "            \n",
    "            if match_score >= threshold_score and best_match_info[0] not in stopwords:\n",
    "                matched_title_keywords.append(best_match_info[0])\n",
    "        \n",
    "        for keyword in description.split('\\n'):\n",
    "            keyword = keyword.strip()\n",
    "            \n",
    "            best_match_info = process.extractOne(keyword.lower(), paragraph_text.lower().split(), scorer=fuzz.token_sort_ratio)\n",
    "            match_score = best_match_info[1]\n",
    "            \n",
    "            if match_score >= threshold_score and best_match_info[0] not in stopwords:\n",
    "                matched_description_keywords.append(best_match_info[0])\n",
    "        \n",
    "        for keyword in objective_name.split('\\n'):\n",
    "            keyword = keyword.strip()\n",
    "            \n",
    "            best_match_info = process.extractOne(keyword.lower(), paragraph_text.lower().split(), scorer=fuzz.token_sort_ratio)\n",
    "            match_score = best_match_info[1]\n",
    "            \n",
    "            if match_score >= threshold_score and best_match_info[0] not in stopwords:\n",
    "                matched_objective_keywords.append(best_match_info[0])\n",
    "        \n",
    "        description_score = round(fuzz.token_sort_ratio(description.lower(), paragraph_text.lower()))\n",
    "        objective_score = round(fuzz.token_sort_ratio(objective.lower(), paragraph_text.lower()))\n",
    "        \n",
    "        matching_entry = {\n",
    "            'All paragraph': paragraph_text,\n",
    "            'Title': title,\n",
    "            'Objective': objective,\n",
    "            'Description': description,\n",
    "            'Matched Description': ', '.join(matched_description_keywords),\n",
    "            'Description Match Score with paragraph': description_score,\n",
    "            'Objective Name': objective_name,\n",
    "            'Matched objective name': ', '.join(matched_objective_keywords),\n",
    "            'Objective Name Match Score with paragraph': objective_score,\n",
    "            'Page Number': paragraph_number\n",
    "        }\n",
    "        \n",
    "        # Only append the entry if there are matched keywords in Description or Objective Name\n",
    "        if matched_description_keywords or matched_objective_keywords:\n",
    "            matching_results.append(matching_entry)\n",
    "\n",
    "# Create a new DataFrame to store the results\n",
    "matching_df = pd.DataFrame(matching_results)\n",
    "\n",
    "# Save the matching results to a CSV file\n",
    "matching_df.to_csv('matching_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058fd22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import pandas as pd\n",
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "# Define a list of common stopwords to exclude from matching\n",
    "stopwords = [\"in\", \"the\", \"what\", \"why\", \"at\", \"and\", \"to\", \"of\", \"a\", \"an\", \"is\"]  # Add more stopwords as needed\n",
    "\n",
    "# ... (same code as before to extract PDF paragraphs and prepare Excel data) ...\n",
    "\n",
    "# Set the threshold for the match score\n",
    "threshold_score = 60\n",
    "\n",
    "matching_results = []\n",
    "\n",
    "for paragraph_number, paragraph_text in enumerate(pdf_paragraphs, start=1):\n",
    "    for index, row in excel_data.iterrows():\n",
    "        title = row['Title']\n",
    "        description = row['Description']\n",
    "        objective = row['Objective']\n",
    "        objective_name = row['Objective Name']  # Assuming this column exists in your Excel data\n",
    "        \n",
    "        matched_title_keywords = []\n",
    "        matched_description_keywords = []\n",
    "        matched_objective_keywords = []\n",
    "        \n",
    "        for keyword in title.split('\\n'):\n",
    "            keyword = keyword.strip()\n",
    "            \n",
    "            best_match_info = process.extractOne(keyword.lower(), paragraph_text.lower().split(), scorer=fuzz.token_sort_ratio)\n",
    "            match_score = best_match_info[1]\n",
    "            \n",
    "            if match_score >= threshold_score and best_match_info[0] not in stopwords:\n",
    "                matched_title_keywords.append(best_match_info[0])\n",
    "        \n",
    "        for keyword in description.split('\\n'):\n",
    "            keyword = keyword.strip()\n",
    "            \n",
    "            best_match_info = process.extractOne(keyword.lower(), paragraph_text.lower().split(), scorer=fuzz.token_sort_ratio)\n",
    "            match_score = best_match_info[1]\n",
    "            \n",
    "            if match_score >= threshold_score and best_match_info[0] not in stopwords:\n",
    "                matched_description_keywords.append(best_match_info[0])\n",
    "        \n",
    "        for keyword in objective_name.split('\\n'):\n",
    "            keyword = keyword.strip()\n",
    "            \n",
    "            best_match_info = process.extractOne(keyword.lower(), paragraph_text.lower().split(), scorer=fuzz.token_sort_ratio)\n",
    "            match_score = best_match_info[1]\n",
    "            \n",
    "            if match_score >= threshold_score and best_match_info[0] not in stopwords:\n",
    "                matched_objective_keywords.append(best_match_info[0])\n",
    "        \n",
    "        description_score = round(fuzz.token_sort_ratio(description.lower(), paragraph_text.lower()))\n",
    "        objective_score = round(fuzz.token_sort_ratio(objective.lower(), paragraph_text.lower()))\n",
    "        \n",
    "        matching_entry = {\n",
    "            'All paragraph': paragraph_text,\n",
    "            'Title': title,\n",
    "            'Objective': objective,\n",
    "            'Description': description,\n",
    "            'Matched Description': ', '.join(set(matched_description_keywords)),  # Use set to remove duplicates\n",
    "            'Description Match Score with paragraph': description_score,\n",
    "            'Objective Name': objective_name,\n",
    "            'Matched objective name': ', '.join(set(matched_objective_keywords)),  # Use set to remove duplicates\n",
    "            'Objective Name Match Score with paragraph': objective_score,\n",
    "            'Page Number': paragraph_number\n",
    "        }\n",
    "        \n",
    "        # Only append the entry if there are matched keywords in Description or Objective Name\n",
    "        if matched_description_keywords or matched_objective_keywords:\n",
    "            matching_results.append(matching_entry)\n",
    "\n",
    "# Create a new DataFrame to store the results\n",
    "matching_df = pd.DataFrame(matching_results)\n",
    "\n",
    "# Save the matching results to a CSV file\n",
    "matching_df.to_csv('matching_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004d4a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import pandas as pd\n",
    "from rapidfuzz import process, fuzz\n",
    "import re\n",
    "\n",
    "# Define a list of common stopwords and unwanted characters to exclude from matching\n",
    "stopwords = [\"in\", \"the\", \"what\", \"why\", \"at\", \"and\", \"to\", \"of\", \"a\", \"an\", \"is\"]  # Add more stopwords as needed\n",
    "unwanted_characters = r\"[,.;@#?!&$-]\"\n",
    "\n",
    "# ... (same code as before to extract PDF paragraphs and prepare Excel data) ...\n",
    "\n",
    "# Set the threshold for the match score\n",
    "threshold_score = 60\n",
    "\n",
    "matching_results = []\n",
    "\n",
    "def clean_keyword(keyword):\n",
    "    # Remove unwanted characters\n",
    "    cleaned_keyword = re.sub(unwanted_characters, '', keyword)\n",
    "    return cleaned_keyword\n",
    "\n",
    "for paragraph_number, paragraph_text in enumerate(pdf_paragraphs, start=1):\n",
    "    for index, row in excel_data.iterrows():\n",
    "        title = row['Title']\n",
    "        description = row['Description']\n",
    "        objective = row['Objective']\n",
    "        objective_name = row['Objective Name']  # Assuming this column exists in your Excel data\n",
    "        \n",
    "        matched_title_keywords = []\n",
    "        matched_description_keywords = []\n",
    "        matched_objective_keywords = []\n",
    "        \n",
    "        for keyword in title.split('\\n'):\n",
    "            keyword = keyword.strip()\n",
    "            keyword = clean_keyword(keyword)\n",
    "            \n",
    "            best_match_info = process.extractOne(keyword.lower(), paragraph_text.lower().split(), scorer=fuzz.token_set_ratio)\n",
    "            match_score = best_match_info[1]\n",
    "            \n",
    "            if match_score >= threshold_score and best_match_info[0] not in stopwords and len(best_match_info[0]) > 2:\n",
    "                matched_title_keywords.append(best_match_info[0])\n",
    "        \n",
    "        for keyword in description.split('\\n'):\n",
    "            keyword = keyword.strip()\n",
    "            keyword = clean_keyword(keyword)\n",
    "            \n",
    "            best_match_info = process.extractOne(keyword.lower(), paragraph_text.lower().split(), scorer=fuzz.token_set_ratio)\n",
    "            match_score = best_match_info[1]\n",
    "            \n",
    "            if match_score >= threshold_score and best_match_info[0] not in stopwords and len(best_match_info[0]) > 2:\n",
    "                matched_description_keywords.append(best_match_info[0])\n",
    "        \n",
    "        for keyword in objective_name.split('\\n'):\n",
    "            keyword = keyword.strip()\n",
    "            keyword = clean_keyword(keyword)\n",
    "            \n",
    "            best_match_info = process.extractOne(keyword.lower(), paragraph_text.lower().split(), scorer=fuzz.token_set_ratio)\n",
    "            match_score = best_match_info[1]\n",
    "            \n",
    "            if match_score >= threshold_score and best_match_info[0] not in stopwords and len(best_match_info[0]) > 2:\n",
    "                matched_objective_keywords.append(best_match_info[0])\n",
    "        \n",
    "        description_score = round(fuzz.token_set_ratio(description.lower(), paragraph_text.lower()))\n",
    "        objective_score = round(fuzz.token_set_ratio(objective.lower(), paragraph_text.lower()))\n",
    "        \n",
    "        matching_entry = {\n",
    "            'All paragraph': paragraph_text,\n",
    "            'Title': title,\n",
    "            'Objective': objective,\n",
    "            'Description': description,\n",
    "            'Matched Description': ', '.join(set(matched_description_keywords)),  # Use set to remove duplicates\n",
    "            'Description Match Score with paragraph': description_score,\n",
    "            'Objective Name': objective_name,\n",
    "            'Matched objective name': ', '.join(set(matched_objective_keywords)),  # Use set to remove duplicates\n",
    "            'Objective Name Match Score with paragraph': objective_score,\n",
    "            'Page Number': paragraph_number\n",
    "        }\n",
    "        \n",
    "        # Only append the entry if there are matched keywords in Description or Objective Name\n",
    "        if matched_description_keywords or matched_objective_keywords:\n",
    "            matching_results.append(matching_entry)\n",
    "\n",
    "# Create a new DataFrame to store the results\n",
    "matching_df = pd.DataFrame(matching_results)\n",
    "\n",
    "# Save the matching results to a CSV file\n",
    "matching_df.to_csv('matching_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed33fb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import pandas as pd\n",
    "from rapidfuzz import process, fuzz\n",
    "import re\n",
    "\n",
    "# Define a list of common stopwords and unwanted characters to exclude from matching\n",
    "stopwords = [\"in\", \"the\", \"what\", \"why\", \"at\", \"and\", \"to\", \"of\", \"a\", \"an\", \"is\"]  # Add more stopwords as needed\n",
    "unwanted_characters = r\"[,.;@#?!&$-]\"\n",
    "\n",
    "# ... (same code as before to extract PDF paragraphs and prepare Excel data) ...\n",
    "\n",
    "# Set the threshold for the match score\n",
    "threshold_score = 60\n",
    "\n",
    "matching_results = []\n",
    "\n",
    "def clean_keyword(keyword):\n",
    "    # Remove unwanted characters and digits\n",
    "    cleaned_keyword = re.sub(unwanted_characters, '', keyword)\n",
    "    cleaned_keyword = ''.join(filter(lambda x: not x.isdigit(), cleaned_keyword))\n",
    "    return cleaned_keyword.strip()\n",
    "\n",
    "for paragraph_number, paragraph_text in enumerate(pdf_paragraphs, start=1):\n",
    "    for index, row in excel_data.iterrows():\n",
    "        title = row['Title']\n",
    "        description = row['Description']\n",
    "        objective = row['Objective']\n",
    "        objective_name = row['Objective Name']  # Assuming this column exists in your Excel data\n",
    "        \n",
    "        matched_title_keywords = []\n",
    "        matched_description_keywords = []\n",
    "        matched_objective_keywords = []\n",
    "        \n",
    "        for keyword in title.split('\\n'):\n",
    "            keyword = keyword.strip()\n",
    "            keyword = clean_keyword(keyword)\n",
    "            \n",
    "            best_match_info = process.extractOne(keyword.lower(), paragraph_text.lower().split(), scorer=fuzz.token_set_ratio)\n",
    "            match_score = best_match_info[1]\n",
    "            \n",
    "            if match_score >= threshold_score and best_match_info[0] not in stopwords and len(best_match_info[0]) > 2:\n",
    "                matched_title_keywords.append(best_match_info[0])\n",
    "        \n",
    "        for keyword in description.split('\\n'):\n",
    "            keyword = keyword.strip()\n",
    "            keyword = clean_keyword(keyword)\n",
    "            \n",
    "            best_match_info = process.extractOne(keyword.lower(), paragraph_text.lower().split(), scorer=fuzz.token_set_ratio)\n",
    "            match_score = best_match_info[1]\n",
    "            \n",
    "            if match_score >= threshold_score and best_match_info[0] not in stopwords and len(best_match_info[0]) > 2:\n",
    "                matched_description_keywords.append(best_match_info[0])\n",
    "        \n",
    "        for keyword in objective_name.split('\\n'):\n",
    "            keyword = keyword.strip()\n",
    "            keyword = clean_keyword(keyword)\n",
    "            \n",
    "            best_match_info = process.extractOne(keyword.lower(), paragraph_text.lower().split(), scorer=fuzz.token_set_ratio)\n",
    "            match_score = best_match_info[1]\n",
    "            \n",
    "            if match_score >= threshold_score and best_match_info[0] not in stopwords and len(best_match_info[0]) > 2:\n",
    "                matched_objective_keywords.append(best_match_info[0])\n",
    "        \n",
    "        description_score = round(fuzz.token_set_ratio(description.lower(), paragraph_text.lower()))\n",
    "        objective_score = round(fuzz.token_set_ratio(objective.lower(), paragraph_text.lower()))\n",
    "        \n",
    "        matching_entry = {\n",
    "            'All paragraph': paragraph_text,\n",
    "            'Title': title,\n",
    "            'Objective': objective,\n",
    "            'Description': description,\n",
    "            'Matched Description': ', '.join(set(matched_description_keywords)),  # Use set to remove duplicates\n",
    "            'Description Match Score with paragraph': description_score,\n",
    "            'Objective Name': objective_name,\n",
    "            'Matched objective name': ', '.join(set(matched_objective_keywords)),  # Use set to remove duplicates\n",
    "            'Objective Name Match Score with paragraph': objective_score,\n",
    "            'Page Number': paragraph_number\n",
    "        }\n",
    "        \n",
    "        # Only append the entry if there are matched keywords in Description or Objective Name\n",
    "        if matched_description_keywords or matched_objective_keywords:\n",
    "            matching_results.append(matching_entry)\n",
    "\n",
    "# Create a new DataFrame to store the results\n",
    "matching_df = pd.DataFrame(matching_results)\n",
    "\n",
    "# Save the matching results to a CSV file\n",
    "#matching_df.to_csv('matching_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9060c871",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import pandas as pd\n",
    "from rapidfuzz import process, fuzz\n",
    "import re\n",
    "\n",
    "# Define a list of common stopwords and unwanted characters to exclude from matching\n",
    "stopwords = [\"in\", \"the\", \"what\", \"why\", \"at\", \"and\", \"to\", \"of\", \"a\", \"an\", \"is\"]  # Add more stopwords as needed\n",
    "unwanted_characters = r\"[,.;@#?!&$-]\"\n",
    "\n",
    "# ... (same code as before to extract PDF paragraphs and prepare Excel data) ...\n",
    "\n",
    "# Set the threshold for the match score\n",
    "threshold_score = 60\n",
    "\n",
    "matching_results = []\n",
    "\n",
    "def clean_keyword(keyword):\n",
    "    # Remove unwanted characters and digits\n",
    "    cleaned_keyword = re.sub(unwanted_characters, '', keyword)\n",
    "    cleaned_keyword = ''.join(filter(lambda x: not x.isdigit(), cleaned_keyword))\n",
    "    return cleaned_keyword.strip()\n",
    "\n",
    "for paragraph_number, paragraph_text in enumerate(pdf_paragraphs, start=1):\n",
    "    for index, row in excel_data.iterrows():\n",
    "        title = row['Title']\n",
    "        description = row['Description']\n",
    "        objective = row['Objective']\n",
    "        objective_name = row['Objective Name']  # Assuming this column exists in your Excel data\n",
    "        \n",
    "        matched_title_keywords = []\n",
    "        matched_description_keywords = []\n",
    "        matched_objective_keywords = []\n",
    "        \n",
    "        for keyword in title.split('\\n'):\n",
    "            keyword = keyword.strip()\n",
    "            keyword = clean_keyword(keyword)\n",
    "            \n",
    "            best_match_info = process.extractOne(keyword.lower(), paragraph_text.lower().split(), scorer=fuzz.token_set_ratio)\n",
    "            match_score = best_match_info[1]\n",
    "            \n",
    "            if match_score >= threshold_score and best_match_info[0] not in stopwords and len(best_match_info[0]) > 2:\n",
    "                matched_title_keywords.append(best_match_info[0])\n",
    "        \n",
    "        for keyword in description.split('\\n'):\n",
    "            keyword = keyword.strip()\n",
    "            keyword = clean_keyword(keyword)\n",
    "            \n",
    "            best_match_info = process.extractOne(keyword.lower(), paragraph_text.lower().split(), scorer=fuzz.token_set_ratio)\n",
    "            match_score = best_match_info[1]\n",
    "            \n",
    "            if match_score >= threshold_score and best_match_info[0] not in stopwords and len(best_match_info[0]) > 2:\n",
    "                matched_description_keywords.append(best_match_info[0])\n",
    "        \n",
    "        for keyword in objective_name.split('\\n'):\n",
    "            keyword = keyword.strip()\n",
    "            keyword = clean_keyword(keyword)\n",
    "            \n",
    "            best_match_info = process.extractOne(keyword.lower(), paragraph_text.lower().split(), scorer=fuzz.token_set_ratio)\n",
    "            match_score = best_match_info[1]\n",
    "            \n",
    "            if match_score >= threshold_score and best_match_info[0] not in stopwords and len(best_match_info[0]) > 2:\n",
    "                matched_objective_keywords.append(best_match_info[0])\n",
    "        \n",
    "        description_score = round(fuzz.token_set_ratio(description.lower(), paragraph_text.lower()))\n",
    "        objective_score = round(fuzz.token_set_ratio(objective.lower(), paragraph_text.lower()))\n",
    "        title_score = round(fuzz.token_set_ratio(title.lower(), paragraph_text.lower()))\n",
    "        \n",
    "        matching_entry = {\n",
    "            'All paragraph': paragraph_text,\n",
    "            'Title': title,\n",
    "            'Objective': objective,\n",
    "            'Description': description,\n",
    "            'Matched Description': ', '.join(set(matched_description_keywords)),  # Use set to remove duplicates\n",
    "            'Description Match Score with Paragraph': description_score,\n",
    "            'Matched Title': ', '.join(set(matched_title_keywords)),  # Use set to remove duplicates\n",
    "            'Title Match Score with Paragraph': title_score,\n",
    "            'Objective Name': objective_name,\n",
    "            'Matched Objective Name': ', '.join(set(matched_objective_keywords)),  # Use set to remove duplicates\n",
    "            'Objective Name Match Score with Paragraph': objective_score,\n",
    "            'Page Number': paragraph_number\n",
    "        }\n",
    "        \n",
    "        # Only append the entry if there are matched keywords in Description, Title, or Objective Name\n",
    "        if matched_description_keywords or matched_title_keywords or matched_objective_keywords:\n",
    "            matching_results.append(matching_entry)\n",
    "\n",
    "# Create a new DataFrame to store the results\n",
    "matching_df = pd.DataFrame(matching_results)\n",
    "\n",
    "# Save the matching results to a CSV file\n",
    "matching_df.to_csv('matching_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e46e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import pandas as pd\n",
    "from rapidfuzz import process, fuzz\n",
    "import re\n",
    "\n",
    "# Define a list of common stopwords and unwanted characters to exclude from matching\n",
    "stopwords = [\"in\", \"the\", \"what\", \"why\", \"at\", \"and\", \"to\", \"of\", \"a\", \"an\", \"is\"]  # Add more stopwords as needed\n",
    "unwanted_characters = r\"[,.;@#?!&$-]\"\n",
    "\n",
    "# ... (same code as before to extract PDF paragraphs and prepare Excel data) ...\n",
    "\n",
    "# Set the threshold for the match score\n",
    "threshold_score = 60\n",
    "\n",
    "# Choose the column to match (e.g., \"Description\")\n",
    "column_to_match = \"Description\"\n",
    "\n",
    "matching_results = []\n",
    "\n",
    "def clean_keyword(keyword):\n",
    "    # Remove unwanted characters and digits\n",
    "    cleaned_keyword = re.sub(unwanted_characters, '', keyword)\n",
    "    cleaned_keyword = ''.join(filter(lambda x: not x.isdigit(), cleaned_keyword))\n",
    "    return cleaned_keyword.strip()\n",
    "\n",
    "for paragraph_number, paragraph_text in enumerate(pdf_paragraphs, start=1):\n",
    "    for index, row in excel_data.iterrows():\n",
    "        keyword = row[column_to_match]\n",
    "        keyword = keyword.strip()\n",
    "        keyword = clean_keyword(keyword)\n",
    "        \n",
    "        best_match_info = process.extractOne(keyword.lower(), paragraph_text.lower().split(), scorer=fuzz.token_set_ratio)\n",
    "        match_score = best_match_info[1]\n",
    "        \n",
    "        if match_score >= threshold_score and best_match_info[0] not in stopwords and len(best_match_info[0]) > 2:\n",
    "            matched_keywords = best_match_info[0]\n",
    "            \n",
    "            # Store the matching details in the results\n",
    "            matching_entry = {\n",
    "                'All paragraph': paragraph_text,\n",
    "                f'Matched {column_to_match}': matched_keywords,\n",
    "                f'{column_to_match} Match Score with Paragraph': match_score,\n",
    "                'Page Number': paragraph_number\n",
    "            }\n",
    "            \n",
    "            matching_results.append(matching_entry)\n",
    "\n",
    "# Create a new DataFrame to store the results\n",
    "matching_df = pd.DataFrame(matching_results)\n",
    "\n",
    "# Save the matching results to a CSV file\n",
    "matching_df.to_csv('matching_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40766196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import pandas as pd\n",
    "from rapidfuzz import process, fuzz\n",
    "import re\n",
    "\n",
    "# Define a list of common stopwords and unwanted characters to exclude from matching\n",
    "stopwords = [\"in\", \"the\", \"what\", \"why\", \"at\", \"and\", \"to\", \"of\", \"a\", \"an\", \"is\"]  # Add more stopwords as needed\n",
    "unwanted_characters = r\"[,.;@#?!&$-]\"\n",
    "\n",
    "# ... (same code as before to extract PDF paragraphs and prepare Excel data) ...\n",
    "\n",
    "# Set the threshold for the match score\n",
    "threshold_score = 60\n",
    "\n",
    "# Choose the column to match (e.g., \"Description\")\n",
    "column_to_match = \"Description\"\n",
    "\n",
    "matching_results = []\n",
    "\n",
    "def clean_keyword(keyword):\n",
    "    # Remove unwanted characters and digits\n",
    "    cleaned_keyword = re.sub(unwanted_characters, '', keyword)\n",
    "    cleaned_keyword = ''.join(filter(lambda x: not x.isdigit(), cleaned_keyword))\n",
    "    return cleaned_keyword.strip()\n",
    "\n",
    "for paragraph_number, paragraph_text in enumerate(pdf_paragraphs, start=1):\n",
    "    for index, row in excel_data.iterrows():\n",
    "        keyword = row[column_to_match]\n",
    "        keyword = keyword.strip()\n",
    "        keyword = clean_keyword(keyword)\n",
    "        \n",
    "        best_match_info = process.extractOne(keyword.lower(), paragraph_text.lower().split(), scorer=fuzz.token_set_ratio)\n",
    "        match_score = best_match_info[1]\n",
    "        \n",
    "        if match_score >= threshold_score and best_match_info[0] not in stopwords and len(best_match_info[0]) > 2:\n",
    "            matched_keywords = best_match_info[0]\n",
    "            \n",
    "            # Store the matching details in the results\n",
    "            matching_entry = {\n",
    "                'All paragraph': paragraph_text,\n",
    "                f'Original {column_to_match}': keyword,\n",
    "                f'Matched {column_to_match}': matched_keywords,\n",
    "                f'{column_to_match} Match Score with Paragraph': match_score,\n",
    "                'Page Number': paragraph_number\n",
    "            }\n",
    "            \n",
    "            matching_results.append(matching_entry)\n",
    "\n",
    "# Create a new DataFrame to store the results\n",
    "matching_df = pd.DataFrame(matching_results)\n",
    "\n",
    "# Save the matching results to a CSV file\n",
    "#matching_df.to_csv('matching_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587a7116",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import pandas as pd\n",
    "from rapidfuzz import process, fuzz\n",
    "import re\n",
    "\n",
    "# Define a list of common stopwords and unwanted characters to exclude from matching\n",
    "stopwords = [\"in\", \"the\", \"what\", \"why\", \"at\", \"and\", \"to\", \"of\", \"a\", \"an\", \"is\"]  # Add more stopwords as needed\n",
    "unwanted_characters = r\"[,.;@#?!&$-]\"\n",
    "\n",
    "# ... (same code as before to extract PDF paragraphs and prepare Excel data) ...\n",
    "\n",
    "# Set the threshold for the match score\n",
    "threshold_score = 60\n",
    "\n",
    "# Choose the column to match (e.g., \"Description\")\n",
    "column_to_match = \"Description\"\n",
    "\n",
    "matching_results = []\n",
    "\n",
    "def clean_keyword(keyword):\n",
    "    # Remove unwanted characters and digits\n",
    "    cleaned_keyword = re.sub(unwanted_characters, '', keyword)\n",
    "    cleaned_keyword = ''.join(filter(lambda x: not x.isdigit(), cleaned_keyword))\n",
    "    return cleaned_keyword.strip()\n",
    "\n",
    "for paragraph_number, paragraph_text in enumerate(pdf_paragraphs, start=1):\n",
    "    for index, row in excel_data.iterrows():\n",
    "        keyword = row[column_to_match]\n",
    "        keyword = keyword.strip()\n",
    "        keyword = clean_keyword(keyword)\n",
    "        \n",
    "        matched_keywords = []\n",
    "        \n",
    "        # Split the keyword into individual words and match each word\n",
    "        for kw in keyword.lower().split():\n",
    "            best_match_info = process.extractOne(kw, paragraph_text.lower().split(), scorer=fuzz.token_set_ratio)\n",
    "            match_score = best_match_info[1]\n",
    "            \n",
    "            if match_score >= threshold_score and best_match_info[0] not in stopwords and len(best_match_info[0]) > 2:\n",
    "                matched_keywords.append((best_match_info[0], match_score))\n",
    "            \n",
    "        # Store the matching details in the results\n",
    "        if matched_keywords:\n",
    "            matching_entry = {\n",
    "                'All paragraph': paragraph_text,\n",
    "                f'Original {column_to_match}': keyword,\n",
    "                f'Matched {column_to_match}': ', '.join([kw[0] for kw in matched_keywords]),\n",
    "                f'{column_to_match} Match Scores with Paragraph': ', '.join([str(kw[1]) for kw in matched_keywords]),\n",
    "                'Page Number': paragraph_number\n",
    "            }\n",
    "            \n",
    "            matching_results.append(matching_entry)\n",
    "\n",
    "# Create a new DataFrame to store the results\n",
    "matching_df = pd.DataFrame(matching_results)\n",
    "\n",
    "# Save the matching results to a CSV file\n",
    "matching_df.to_csv('matching_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328a70c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import pandas as pd\n",
    "from rapidfuzz import process, fuzz\n",
    "import re\n",
    "\n",
    "# Define a list of common stopwords and unwanted characters to exclude from matching\n",
    "stopwords = [\"in\", \"the\", \"what\", \"why\", \"at\", \"and\", \"to\", \"of\", \"a\", \"an\", \"is\"]  # Add more stopwords as needed\n",
    "unwanted_characters = r\"[,.;@#?!&$-]\"\n",
    "\n",
    "# ... (same code as before to extract PDF paragraphs and prepare Excel data) ...\n",
    "\n",
    "# Set the threshold for the match score\n",
    "threshold_score = 60\n",
    "\n",
    "# Choose the column to match (e.g., \"Description\")\n",
    "column_to_match = \"Description\"\n",
    "\n",
    "matching_results = []\n",
    "\n",
    "def clean_keyword(keyword):\n",
    "    # Remove unwanted characters and digits\n",
    "    cleaned_keyword = re.sub(unwanted_characters, '', keyword)\n",
    "    cleaned_keyword = ''.join(filter(lambda x: not x.isdigit(), cleaned_keyword))\n",
    "    return cleaned_keyword.strip()\n",
    "\n",
    "for paragraph_number, paragraph_text in enumerate(pdf_paragraphs, start=1):\n",
    "    for index, row in excel_data.iterrows():\n",
    "        keyword = row[column_to_match]\n",
    "        keyword = keyword.strip()\n",
    "        keyword = clean_keyword(keyword)\n",
    "        \n",
    "        matched_keywords = []\n",
    "        \n",
    "        # Split the keyword into individual words and match each word\n",
    "        for kw in keyword.lower().split():\n",
    "            best_match_info = process.extractOne(kw, paragraph_text.lower().split(), scorer=fuzz.token_set_ratio)\n",
    "            match_score = best_match_info[1]\n",
    "            \n",
    "            if match_score >= threshold_score and best_match_info[0] not in stopwords and len(best_match_info[0]) > 2:\n",
    "                matched_keywords.append((best_match_info[0], match_score))\n",
    "            \n",
    "        # Store the matching details in the results\n",
    "        if matched_keywords:\n",
    "            matching_entry = {\n",
    "                'All paragraph': paragraph_text,\n",
    "                f'Original {column_to_match}': keyword,\n",
    "                f'Matched {column_to_match}': ', '.join([kw[0] for kw in matched_keywords]),\n",
    "                f'{column_to_match} Match Scores with Paragraph': ', '.join([str(kw[1]) for kw in matched_keywords]),\n",
    "                'Page Number': paragraph_number,\n",
    "                'A': row['A']  # Assuming 'A' is a column in your Excel data\n",
    "            }\n",
    "            \n",
    "            matching_results.append(matching_entry)\n",
    "\n",
    "# Create a new DataFrame to store the results\n",
    "matching_df = pd.DataFrame(matching_results)\n",
    "\n",
    "# Save the matching results to a CSV file\n",
    "matching_df.to_csv('matching_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01476d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import pandas as pd\n",
    "from rapidfuzz import process, fuzz\n",
    "import re\n",
    "\n",
    "# Define a list of common stopwords and unwanted characters to exclude from matching\n",
    "stopwords = [\"in\", \"the\", \"what\", \"why\", \"at\", \"and\", \"to\", \"of\", \"a\", \"an\", \"is\"]  # Add more stopwords as needed\n",
    "unwanted_characters = r\"[,.;@#?!&$-]\"\n",
    "\n",
    "# ... (same code as before to extract PDF paragraphs and prepare Excel data) ...\n",
    "\n",
    "# Set the threshold for the match score\n",
    "threshold_score = 60\n",
    "\n",
    "# List of root words to exclude\n",
    "exclusion_roots = [\"technology\", \"secure\"]  # Add more root words as needed\n",
    "\n",
    "def clean_keyword(keyword):\n",
    "    # Remove unwanted characters and digits\n",
    "    cleaned_keyword = re.sub(unwanted_characters, '', keyword)\n",
    "    cleaned_keyword = ''.join(filter(lambda x: not x.isdigit(), cleaned_keyword))\n",
    "    \n",
    "    # Remove variations of exclusion root words\n",
    "    for root in exclusion_roots:\n",
    "        if root in cleaned_keyword:\n",
    "            cleaned_keyword = cleaned_keyword.replace(root, '')\n",
    "    \n",
    "    return cleaned_keyword.strip()\n",
    "\n",
    "for paragraph_number, paragraph_text in enumerate(pdf_paragraphs, start=1):\n",
    "    for index, row in excel_data.iterrows():\n",
    "        keyword = row[column_to_match]\n",
    "        keyword = keyword.strip()\n",
    "        keyword = clean_keyword(keyword)\n",
    "        \n",
    "        matched_keywords = []\n",
    "        \n",
    "        # Split the keyword into individual words and match each word\n",
    "        for kw in keyword.lower().split():\n",
    "            best_match_info = process.extractOne(kw, paragraph_text.lower().split(), scorer=fuzz.token_set_ratio)\n",
    "            match_score = best_match_info[1]\n",
    "            \n",
    "            if match_score >= threshold_score and best_match_info[0] not in stopwords and len(best_match_info[0]) > 2:\n",
    "                matched_keywords.append((best_match_info[0], match_score))\n",
    "            \n",
    "        # Store the matching details in the results\n",
    "        if matched_keywords:\n",
    "            matching_entry = {\n",
    "                'All paragraph': paragraph_text,\n",
    "                f'Original {column_to_match}': keyword,\n",
    "                f'Matched {column_to_match}': ', '.join([kw[0] for kw in matched_keywords]),\n",
    "                f'{column_to_match} Match Scores with Paragraph': ', '.join([str(kw[1]) for kw in matched_keywords]),\n",
    "                'Page Number': paragraph_number,\n",
    "                'A': row['A']  # Assuming 'A' is a column in your Excel data\n",
    "            }\n",
    "            \n",
    "            matching_results.append(matching_entry)\n",
    "\n",
    "# Create a new DataFrame to store the results\n",
    "matching_df = pd.DataFrame(matching_results)\n",
    "\n",
    "# Save the matching results to a CSV file\n",
    "matching_df.to_csv('matching_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ad98a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example data\n",
    "data = {'your_column': ['COO-123- abc Something', 'COO-456def Another', 'COO-789ghi More']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Remove the pattern [SOME_TEXT]-[NUMERIC]-[ALPHABETIC] from the beginning of each value in the 'your_column'\n",
    "df['your_column'] = df['your_column'].str.replace(r'^[A-Z]+-\\d+-\\s*', '')\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34f9105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example data\n",
    "data = {'your_column': ['COO-123- abc Something', 'COO-456def Another', 'COO-789ghi More']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Remove alphanumeric characters from the beginning of each value in the 'your_column'\n",
    "df['your_column'] = df['your_column'].str.replace(r'^[0-9a-zA-Z]+', '')\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e159c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example data\n",
    "data = {'your_column': ['COO-123- abc Something', 'COO-456def Another', 'COO-789ghi More']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Remove \"COO-\" and any numeric part from the beginning of each value in the 'your_column'\n",
    "df['your_column'] = df['your_column'].str.replace(r'^[A-Z]+-\\d+-\\s*', '')\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc9eaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example data\n",
    "data = {'your_column': ['COO-123- abc Something', 'COO-456def Another', 'COO-789ghi More']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Remove \"COO-\" and any numeric part from the beginning of each value in the 'your_column'\n",
    "df['your_column'] = df['your_column'].str.replace(r'^[A-Z]+-\\d+-\\s*', '')\n",
    "\n",
    "# Remove any remaining leading numbers\n",
    "df['your_column'] = df['your_column'].str.replace(r'^\\d+', '')\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d1e590",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example data\n",
    "data = {'your_column': ['COO-123- abc Something', 'COO-456def Another', 'COO-789ghi More']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Remove \"COO-\" and any numeric part from the beginning of each value in the 'your_column'\n",
    "df['your_column'] = df['your_column'].str.replace(r'^[A-Za-z]+-\\d+-\\s*', '')\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7897082",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import pandas as pd\n",
    "from rapidfuzz import process, fuzz\n",
    "import re\n",
    "\n",
    "# Define a list of common stopwords and unwanted characters to exclude from matching\n",
    "stopwords = [\"in\", \"the\", \"what\", \"why\", \"at\", \"and\", \"to\", \"of\", \"a\", \"an\", \"is\"]  # Add more stopwords as needed\n",
    "unwanted_characters = r\"[,.;@#?!&$-]\"\n",
    "\n",
    "# ... (same code as before to extract PDF paragraphs and prepare Excel data) ...\n",
    "\n",
    "# Set the threshold for the match score\n",
    "threshold_score = 60\n",
    "\n",
    "# List of root words to exclude\n",
    "exclusion_roots = [\"technology\", \"secure\"]  # Add more root words as needed\n",
    "\n",
    "def clean_keyword(keyword):\n",
    "    # Remove unwanted characters and digits\n",
    "    cleaned_keyword = re.sub(unwanted_characters, '', keyword)\n",
    "    cleaned_keyword = ''.join(filter(lambda x: not x.isdigit(), cleaned_keyword))\n",
    "    \n",
    "    # Remove variations of exclusion root words\n",
    "    for root in exclusion_roots:\n",
    "        if root in cleaned_keyword:\n",
    "            cleaned_keyword = cleaned_keyword.replace(root, '')\n",
    "    \n",
    "    return cleaned_keyword.strip()\n",
    "\n",
    "for paragraph_number, paragraph_text in enumerate(pdf_paragraphs, start=1):\n",
    "    for index, row in excel_data.iterrows():\n",
    "        keyword = row[column_to_match]\n",
    "        keyword = keyword.strip()\n",
    "        keyword = clean_keyword(keyword)\n",
    "        \n",
    "        matched_keywords = []\n",
    "        \n",
    "        # Split the keyword into individual words and match each word\n",
    "        for kw in keyword.lower().split():\n",
    "            best_match_info = process.extractOne(kw, paragraph_text.lower().split(), scorer=fuzz.token_set_ratio)\n",
    "            match_score = best_match_info[1]\n",
    "            \n",
    "            if match_score >= threshold_score and best_match_info[0] not in stopwords and len(best_match_info[0]) > 2:\n",
    "                matched_keywords.append((best_match_info[0], match_score))\n",
    "            \n",
    "        # Store the matching details in the results\n",
    "        if matched_keywords:\n",
    "            matching_entry = {\n",
    "                'All paragraph': paragraph_text,\n",
    "                f'Original {column_to_match}': keyword,\n",
    "                f'Matched {column_to_match}': ', '.join([kw[0] for kw in matched_keywords]),\n",
    "                f'{column_to_match} Match Scores with Paragraph': ', '.join([str(kw[1]) for kw in matched_keywords]),\n",
    "                'Page Number': paragraph_number,\n",
    "                'A': row['A']  # Assuming 'A' is a column in your Excel data\n",
    "            }\n",
    "            \n",
    "            matching_results.append(matching_entry)\n",
    "\n",
    "# Create a new DataFrame to store the results\n",
    "matching_df = pd.DataFrame(matching_results)\n",
    "\n",
    "# Save the matching results to a CSV file\n",
    "matching_df.to_csv('matching_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5db67a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import pandas as pd\n",
    "from rapidfuzz import process, fuzz\n",
    "import re\n",
    "\n",
    "# Define a list of common stopwords and unwanted characters to exclude from matching\n",
    "stopwords = [\"is\", \"am\", \"that\", \"and\", \"the\", \"in\", \"to\", \"of\", \"a\", \"an\"]  # Add more stopwords as needed\n",
    "unwanted_characters = r\"[,.;@#?!&$-]\"\n",
    "\n",
    "# ... (same code as before to extract PDF paragraphs and prepare Excel data) ...\n",
    "\n",
    "# Set the threshold for the match score\n",
    "threshold_score = 60\n",
    "\n",
    "# ... (same code as before to clean the keyword) ...\n",
    "\n",
    "# Function to remove stopwords from a keyword\n",
    "def remove_stopwords(keyword):\n",
    "    return ' '.join([word for word in keyword.split() if word.lower() not in stopwords])\n",
    "\n",
    "for paragraph_number, paragraph_text in enumerate(pdf_paragraphs, start=1):\n",
    "    for index, row in excel_data.iterrows():\n",
    "        keyword = row[column_to_match]\n",
    "        keyword = keyword.strip()\n",
    "        \n",
    "        # Clean the keyword and remove stopwords\n",
    "        keyword = clean_keyword(keyword)\n",
    "        keyword = remove_stopwords(keyword)\n",
    "        \n",
    "        matched_keywords = []\n",
    "        \n",
    "        # Split the keyword into individual words and match each word\n",
    "        for kw in keyword.lower().split():\n",
    "            best_match_info = process.extractOne(kw, paragraph_text.lower().split(), scorer=fuzz.token_set_ratio)\n",
    "            match_score = best_match_info[1]\n",
    "            \n",
    "            if match_score >= threshold_score and best_match_info[0] not in stopwords and len(best_match_info[0]) > 2:\n",
    "                matched_keywords.append((best_match_info[0], match_score))\n",
    "            \n",
    "        # Store the matching details in the results\n",
    "        if matched_keywords:\n",
    "            matching_entry = {\n",
    "                'All paragraph': paragraph_text,\n",
    "                f'Original {column_to_match}': keyword,\n",
    "                f'Matched {column_to_match}': ', '.join([kw[0] for kw in matched_keywords]),\n",
    "                f'{column_to_match} Match Scores with Paragraph': ', '.join([str(kw[1]) for kw in matched_keywords]),\n",
    "                'Page Number': paragraph_number,\n",
    "                'A': row['A']  # Assuming 'A' is a column in your Excel data\n",
    "            }\n",
    "            \n",
    "            matching_results.append(matching_entry)\n",
    "\n",
    "# ... (same code as before to save the matching results) ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4d2846",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import pandas as pd\n",
    "from rapidfuzz import process, fuzz\n",
    "import re\n",
    "\n",
    "# Define a list of common stopwords and unwanted characters to exclude from matching\n",
    "stopwords = [\"in\", \"the\", \"what\", \"why\", \"at\", \"and\", \"to\", \"of\", \"a\", \"an\", \"is\"]  # Add more stopwords as needed\n",
    "unwanted_characters = r\"[,.;@#?!&$-]\"\n",
    "\n",
    "# ... (same code as before to extract PDF paragraphs and prepare Excel data) ...\n",
    "\n",
    "# Set the threshold for the match score\n",
    "threshold_score = 60\n",
    "\n",
    "# Define the column to match (e.g., \"Description\")\n",
    "column_to_match = \"Description\"\n",
    "\n",
    "# List of root words to exclude\n",
    "exclusion_roots = [\"technology\", \"secure\"]  # Add more root words as needed\n",
    "\n",
    "def clean_keyword(keyword):\n",
    "    # Remove unwanted characters and digits\n",
    "    cleaned_keyword = re.sub(unwanted_characters, '', keyword)\n",
    "    cleaned_keyword = ''.join(filter(lambda x: not x.isdigit(), cleaned_keyword))\n",
    "    \n",
    "    # Remove variations of exclusion root words\n",
    "    for root in exclusion_roots:\n",
    "        if root in cleaned_keyword:\n",
    "            cleaned_keyword = cleaned_keyword.replace(root, '')\n",
    "    \n",
    "    return cleaned_keyword.strip()\n",
    "\n",
    "for paragraph_number, paragraph_text in enumerate(pdf_paragraphs, start=1):\n",
    "    for index, row in excel_data.iterrows():\n",
    "        keyword = row[column_to_match]\n",
    "        keyword = keyword.strip()\n",
    "        keyword = clean_keyword(keyword)\n",
    "        \n",
    "        matched_keywords = []\n",
    "        \n",
    "        # Split the keyword into individual words and match each word\n",
    "        for kw in keyword.lower().split():\n",
    "            best_match_info = process.extractOne(kw, paragraph_text.lower().split(), scorer=fuzz.token_set_ratio)\n",
    "            match_score = best_match_info[1]\n",
    "            \n",
    "            if match_score >= threshold_score and best_match_info[0] not in stopwords and len(best_match_info[0]) > 2:\n",
    "                matched_keywords.append((best_match_info[0], match_score))\n",
    "            \n",
    "        # Store the matching details in the results\n",
    "        if matched_keywords:\n",
    "            matching_entry = {\n",
    "                'All paragraph': paragraph_text,\n",
    "                f'Original {column_to_match}': keyword,\n",
    "                f'Matched {column_to_match}': ', '.join([kw[0] for kw in matched_keywords]),\n",
    "                f'{column_to_match} Match Scores with Paragraph': ', '.join([str(kw[1]) for kw in matched_keywords]),\n",
    "                'Page Number': paragraph_number,\n",
    "                'A': row['A']  # Assuming 'A' is a column in your Excel data\n",
    "            }\n",
    "            \n",
    "            matching_results.append(matching_entry)\n",
    "\n",
    "# Create a new DataFrame to store the results\n",
    "matching_df = pd.DataFrame(matching_results)\n",
    "\n",
    "# Save the matching results to a CSV file\n",
    "matching_df.to_csv('matching_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72cb51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import pandas as pd\n",
    "from rapidfuzz import process, fuzz\n",
    "import re\n",
    "\n",
    "# Define a list of common stopwords and unwanted characters to exclude from matching\n",
    "stopwords = [\"in\", \"the\", \"what\", \"why\", \"at\", \"and\", \"to\", \"of\", \"a\", \"an\", \"is\"]  # Add more stopwords as needed\n",
    "unwanted_characters = r\"[,.;@#?!&$-]\"\n",
    "\n",
    "# ... (same code as before to extract PDF paragraphs and prepare Excel data) ...\n",
    "\n",
    "# Set the threshold for the match score\n",
    "threshold_score = 60\n",
    "\n",
    "# Define the column to match (e.g., \"Description\")\n",
    "column_to_match = \"Description\"\n",
    "\n",
    "# List of root words to exclude\n",
    "exclusion_roots = [\"technology\", \"secure\"]  # Add more root words as needed\n",
    "\n",
    "# Page number to start processing from (exclude the first 3-4 pages)\n",
    "start_page_number = 5\n",
    "\n",
    "def clean_keyword(keyword):\n",
    "    # Remove unwanted characters and digits\n",
    "    cleaned_keyword = re.sub(unwanted_characters, '', keyword)\n",
    "    cleaned_keyword = ''.join(filter(lambda x: not x.isdigit(), cleaned_keyword))\n",
    "    \n",
    "    # Remove variations of exclusion root words\n",
    "    for root in exclusion_roots:\n",
    "        if root in cleaned_keyword:\n",
    "            cleaned_keyword = cleaned_keyword.replace(root, '')\n",
    "    \n",
    "    return cleaned_keyword.strip()\n",
    "\n",
    "for paragraph_number, paragraph_text in enumerate(pdf_paragraphs[start_page_number - 1:], start=start_page_number):\n",
    "    for index, row in excel_data.iterrows():\n",
    "        keyword = row[column_to_match]\n",
    "        keyword = keyword.strip()\n",
    "        keyword = clean_keyword(keyword)\n",
    "        \n",
    "        matched_keywords = []\n",
    "        \n",
    "        # Split the keyword into individual words and match each word\n",
    "        for kw in keyword.lower().split():\n",
    "            best_match_info = process.extractOne(kw, paragraph_text.lower().split(), scorer=fuzz.token_set_ratio)\n",
    "            match_score = best_match_info[1]\n",
    "            \n",
    "            if match_score >= threshold_score and best_match_info[0] not in stopwords and len(best_match_info[0]) > 2:\n",
    "                matched_keywords.append((best_match_info[0], match_score))\n",
    "            \n",
    "        # Store the matching details in the results\n",
    "        if matched_keywords:\n",
    "            matching_entry = {\n",
    "                'All paragraph': paragraph_text,\n",
    "                f'Original {column_to_match}': keyword,\n",
    "                f'Matched {column_to_match}': ', '.join([kw[0] for kw in matched_keywords]),\n",
    "                f'{column_to_match} Match Scores with Paragraph': ', '.join([str(kw[1]) for kw in matched_keywords]),\n",
    "                'Page Number': paragraph_number,\n",
    "                'A': row['A']  # Assuming 'A' is a column in your Excel data\n",
    "            }\n",
    "            \n",
    "            matching_results.append(matching_entry)\n",
    "\n",
    "# Create a new DataFrame to store the results\n",
    "matching_df = pd.DataFrame(matching_results)\n",
    "\n",
    "# Save the matching results to a CSV file\n",
    "matching_df.to_csv('matching_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8fd266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import pandas as pd\n",
    "from rapidfuzz import process, fuzz\n",
    "import re\n",
    "\n",
    "# Define a list of common stopwords and unwanted characters to exclude from matching\n",
    "stopwords = set([\"in\", \"the\", \"what\", \"why\", \"at\", \"and\", \"to\", \"of\", \"a\", \"an\", \"is\"])  # Add more stopwords as needed\n",
    "unwanted_characters = r\"[,.;@#?!&$-]\"\n",
    "\n",
    "# ... (same code as before to extract PDF paragraphs and prepare Excel data) ...\n",
    "\n",
    "# Set the threshold for the match score\n",
    "threshold_score = 60\n",
    "\n",
    "# Define the column to match (e.g., \"Description\")\n",
    "column_to_match = \"Description\"\n",
    "\n",
    "# List of root words to exclude\n",
    "exclusion_roots = [\"technology\", \"secure\"]  # Add more root words as needed\n",
    "\n",
    "# Page number to start processing from (exclude the first 3-4 pages)\n",
    "start_page_number = 5\n",
    "\n",
    "def clean_keyword(keyword):\n",
    "    # Remove unwanted characters and digits\n",
    "    cleaned_keyword = re.sub(unwanted_characters, '', keyword)\n",
    "    cleaned_keyword = ''.join(filter(lambda x: not x.isdigit(), cleaned_keyword))\n",
    "    \n",
    "    # Remove variations of exclusion root words\n",
    "    for root in exclusion_roots:\n",
    "        if root in cleaned_keyword:\n",
    "            cleaned_keyword = cleaned_keyword.replace(root, '')\n",
    "    \n",
    "    # Remove stopwords\n",
    "    cleaned_keyword = ' '.join([word for word in cleaned_keyword.split() if word.lower() not in stopwords])\n",
    "    \n",
    "    return cleaned_keyword.strip()\n",
    "\n",
    "for paragraph_number, paragraph_text in enumerate(pdf_paragraphs[start_page_number - 1:], start=start_page_number):\n",
    "    for index, row in excel_data.iterrows():\n",
    "        keyword = row[column_to_match]\n",
    "        keyword = keyword.strip()\n",
    "        keyword = clean_keyword(keyword)\n",
    "        \n",
    "        matched_keywords = []\n",
    "        \n",
    "        # Split the keyword into individual words and match each word\n",
    "        for kw in keyword.lower().split():\n",
    "            best_match_info = process.extractOne(kw, paragraph_text.lower().split(), scorer=fuzz.token_set_ratio)\n",
    "            match_score = best_match_info[1]\n",
    "            \n",
    "            if match_score >= threshold_score and best_match_info[0] not in stopwords and len(best_match_info[0]) > 2:\n",
    "                matched_keywords.append((best_match_info[0], match_score))\n",
    "            \n",
    "        # Store the matching details in the results\n",
    "        if matched_keywords:\n",
    "            matching_entry = {\n",
    "                'All paragraph': paragraph_text,\n",
    "                f'Original {column_to_match}': keyword,\n",
    "                f'Matched {column_to_match}': ', '.join([kw[0] for kw in matched_keywords]),\n",
    "                f'{column_to_match} Match Scores with Paragraph': ', '.join([str(kw[1]) for kw in matched_keywords]),\n",
    "                'Page Number': paragraph_number,\n",
    "                'A': row['A']  # Assuming 'A' is a column in your Excel data\n",
    "            }\n",
    "            \n",
    "            matching_results.append(matching_entry)\n",
    "\n",
    "# Create a new DataFrame to store the results\n",
    "matching_df = pd.DataFrame(matching_results)\n",
    "\n",
    "# Save the matching results to a CSV file\n",
    "matching_df.to_csv('matching_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a3debd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import pandas as pd\n",
    "from rapidfuzz import process, fuzz\n",
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Define a list of common stopwords and unwanted characters to exclude from matching\n",
    "stopwords = set([\"in\", \"the\", \"what\", \"why\", \"at\", \"and\", \"to\", \"of\", \"a\", \"an\", \"is\"])  # Add more stopwords as needed\n",
    "unwanted_characters = r\"[,.;@#?!&$-]\"\n",
    "\n",
    "# ... (same code as before to extract PDF paragraphs and prepare Excel data) ...\n",
    "\n",
    "# Set the threshold for the match score\n",
    "threshold_score = 60\n",
    "\n",
    "# Define the column to match (e.g., \"Description\")\n",
    "column_to_match = \"Description\"\n",
    "\n",
    "# List of root words to exclude\n",
    "exclusion_roots = [\"technology\"]  # Add more root words as needed\n",
    "\n",
    "# Page number to start processing from (exclude the first 3-4 pages)\n",
    "start_page_number = 5\n",
    "\n",
    "# Initialize the Porter Stemmer\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "def stem(word):\n",
    "    return porter_stemmer.stem(word)\n",
    "\n",
    "def clean_keyword(keyword):\n",
    "    # Remove unwanted characters and digits\n",
    "    cleaned_keyword = re.sub(unwanted_characters, '', keyword)\n",
    "    cleaned_keyword = ''.join(filter(lambda x: not x.isdigit(), cleaned_keyword))\n",
    "    \n",
    "    # Remove variations of exclusion root words\n",
    "    for root in exclusion_roots:\n",
    "        if stem(root) in stem(cleaned_keyword):\n",
    "            cleaned_keyword = cleaned_keyword.replace(root, '')\n",
    "    \n",
    "    # Remove stopwords\n",
    "    cleaned_keyword = ' '.join([word for word in cleaned_keyword.split() if word.lower() not in stopwords])\n",
    "    \n",
    "    return cleaned_keyword.strip()\n",
    "\n",
    "for paragraph_number, paragraph_text in enumerate(pdf_paragraphs[start_page_number - 1:], start=start_page_number):\n",
    "    for index, row in excel_data.iterrows():\n",
    "        keyword = row[column_to_match]\n",
    "        keyword = keyword.strip()\n",
    "        keyword = clean_keyword(keyword)\n",
    "        \n",
    "        matched_keywords = []\n",
    "        \n",
    "        # Split the keyword into individual words and match each whole word\n",
    "        for kw in keyword.lower().split():\n",
    "            if re.search(rf'\\b{re.escape(kw)}\\b', paragraph_text.lower()):\n",
    "                matched_keywords.append((kw, 100))  # Exact match, score 100\n",
    "            \n",
    "        # Store the matching details in the results\n",
    "        if matched_keywords:\n",
    "            matching_entry = {\n",
    "                'All paragraph': paragraph_text,\n",
    "                f'Original {column_to_match}': keyword,\n",
    "                f'Matched {column_to_match}': ', '.join([kw[0] for kw in matched_keywords]),\n",
    "                f'{column_to_match} Match Scores with Paragraph': ', '.join([str(kw[1]) for kw in matched_keywords]),\n",
    "                'Page Number': paragraph_number,\n",
    "                'A': row['A']  # Assuming 'A' is a column in your Excel data\n",
    "            }\n",
    "            \n",
    "            matching_results.append(matching_entry)\n",
    "\n",
    "# Create a new DataFrame to store the results\n",
    "matching_df = pd.DataFrame(matching_results)\n",
    "\n",
    "# Save the matching results to a CSV file\n",
    "matching_df.to_csv('matching_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df4bcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import pandas as pd\n",
    "from rapidfuzz import fuzz\n",
    "import re\n",
    "\n",
    "# ... (same code as before to extract PDF paragraphs and prepare Excel data) ...\n",
    "\n",
    "# Set the threshold for the match score\n",
    "threshold_score = 60\n",
    "\n",
    "# Define the column to match (e.g., \"Description\")\n",
    "column_to_match = \"Description\"\n",
    "\n",
    "# ... (same code as before for initialization and cleaning) ...\n",
    "\n",
    "for paragraph_number, paragraph_text in enumerate(pdf_paragraphs[start_page_number - 1:], start=start_page_number):\n",
    "    for index, row in excel_data.iterrows():\n",
    "        keyword = row[column_to_match]\n",
    "        keyword = keyword.strip()\n",
    "        keyword = clean_keyword(keyword)\n",
    "        \n",
    "        matched_keywords = []\n",
    "        \n",
    "        # Split the keyword into individual words and match each whole word\n",
    "        keywords_to_match = keyword.lower().split()\n",
    "        paragraph_words = paragraph_text.lower().split()\n",
    "        \n",
    "        for kw in keywords_to_match:\n",
    "            if any(re.fullmatch(rf'\\b{re.escape(kw)}\\b', word) for word in paragraph_words):\n",
    "                matched_keywords.append((kw, 100))  # Exact match, score 100\n",
    "            \n",
    "        # Store the matching details in the results\n",
    "        if matched_keywords:\n",
    "            matching_entry = {\n",
    "                'All paragraph': paragraph_text,\n",
    "                f'Original {column_to_match}': keyword,\n",
    "                f'Matched {column_to_match}': ', '.join([kw[0] for kw in matched_keywords]),\n",
    "                f'{column_to_match} Match Scores with Paragraph': ', '.join([str(kw[1]) for kw in matched_keywords]),\n",
    "                'Page Number': paragraph_number,\n",
    "                'A': row['A']  # Assuming 'A' is a column in your Excel data\n",
    "            }\n",
    "            \n",
    "            matching_results.append(matching_entry)\n",
    "\n",
    "# Create a new DataFrame to store the results\n",
    "matching_df = pd.DataFrame(matching_results)\n",
    "\n",
    "# Save the matching results to a CSV file\n",
    "matching_df.to_csv('matching_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2195a4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stopwords list\n",
    "#[i, me, my, myself, we, our, ours, ourselves, you, youre, youve, youll, youd, your, yours, \n",
    "#yourself, yourselves, he, him, his, himself, she, shes, her, hers, herself, it, its, its, \n",
    "#itself, they, them, their, theirs, themselves, what, which, who, whom, this, that, thatll, these, \n",
    "#those, am, is, are, was, were, be, been, being, have, has, had, having, do, does, did, doing,\n",
    "#a, an, the, and, but, if, or, because, as, until, while, of, at, by, for, with, about,\n",
    "#against, between, into, through, during, before, after, above, below, to, from, up, down, in, out,\n",
    "#on, off, over, under, again, further, then, once, here, there, when, where, why, how, all, any,\n",
    "#both, each, few, more, most, other, some, such, no, nor, not, only, own, same, so, than, too,\n",
    "#very, s, t, can, will, just, don, dont, should, shouldve, now, d, ll, m, o, re, ve, y, \n",
    "#ain, aren, arent, couldn, couldnt, didn, didnt, doesn, doesnt, hadn, hadnt, hasn, hasnt,\n",
    "#haven, havent, isn, isnt, ma, mightn, mightnt, mustn, mustnt, needn, neednt, shan, shant, \n",
    "#shouldn, shouldnt, wasn, wasnt, weren, werent, won, wont, wouldn, wouldnt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b675e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rapidfuzz import fuzz\n",
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# ... (same code as before to prepare Excel data) ...\n",
    "\n",
    "# Set the threshold for the match score\n",
    "threshold_score = 60\n",
    "\n",
    "# Define the column to match (e.g., \"Description\" from the first Excel data)\n",
    "column_to_match = \"Description\"\n",
    "\n",
    "# Load the second Excel file and extract the \"State\" column\n",
    "second_excel_path = \"path/to/second_excel.xlsx\"  # Update with the actual path\n",
    "second_excel_data = pd.read_excel(second_excel_path)\n",
    "state_column = second_excel_data[\"State\"]\n",
    "\n",
    "# Words to remove\n",
    "words_to_remove = [\"risk\", \"tech\"]  # Add more words to remove as needed\n",
    "\n",
    "# Initialize the Porter Stemmer\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "# Function to clean and preprocess keywords\n",
    "def clean_keyword(keyword):\n",
    "    # Remove unwanted characters and digits\n",
    "    cleaned_keyword = re.sub(r\"[^a-zA-Z ]\", \"\", keyword)\n",
    "    cleaned_keyword = ' '.join(cleaned_keyword.split())  # Remove extra spaces\n",
    "    \n",
    "    # Remove specific words\n",
    "    for word in words_to_remove:\n",
    "        cleaned_keyword = cleaned_keyword.replace(word, '')\n",
    "    \n",
    "    # Perform stemming\n",
    "    cleaned_keyword = ' '.join(porter_stemmer.stem(word) for word in cleaned_keyword.lower().split())\n",
    "    \n",
    "    return cleaned_keyword.strip()\n",
    "\n",
    "for index, row in excel_data.iterrows():\n",
    "    keyword = row[column_to_match]\n",
    "    keyword = keyword.strip()\n",
    "    keyword = clean_keyword(keyword)\n",
    "    \n",
    "    matched_keywords = []\n",
    "    \n",
    "    # Split the keyword into individual words and match each whole word\n",
    "    keywords_to_match = keyword.lower().split()\n",
    "    \n",
    "    for state in state_column:\n",
    "        state = str(state).strip()\n",
    "        state = clean_keyword(state)\n",
    "        \n",
    "        # Split the state into individual words and match each whole word\n",
    "        state_words = state.lower().split()\n",
    "        \n",
    "        for kw in keywords_to_match:\n",
    "            if any(re.fullmatch(rf'\\b{re.escape(kw)}\\b', word) for word in state_words):\n",
    "                matched_keywords.append((kw, 100))  # Exact match, score 100\n",
    "            \n",
    "    # Store the matching details in the results\n",
    "    if matched_keywords:\n",
    "        matching_entry = {\n",
    "            f'Original {column_to_match}': keyword,\n",
    "            f'Matched State': ', '.join([kw[0] for kw in matched_keywords]),\n",
    "            f'State Match Scores': ', '.join([str(kw[1]) for kw in matched_keywords]),\n",
    "            'A': row['A']  # Assuming 'A' is a column in your Excel data\n",
    "        }\n",
    "        \n",
    "        matching_results.append(matching_entry)\n",
    "\n",
    "# Create a new DataFrame to store the results\n",
    "matching_df = pd.DataFrame(matching_results)\n",
    "\n",
    "# Save the matching results to a CSV file\n",
    "matching_df.to_csv('matching_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01913505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rapidfuzz import fuzz\n",
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# ... (same code as before to prepare Excel data) ...\n",
    "\n",
    "# Set the threshold for the match score\n",
    "threshold_score = 60\n",
    "\n",
    "# Define the column to match (e.g., \"Description\" from the first Excel data)\n",
    "column_to_match = \"Description\"\n",
    "\n",
    "# Load the second Excel file and extract the \"State\" column\n",
    "second_excel_path = \"path/to/second_excel.xlsx\"  # Update with the actual path\n",
    "second_excel_data = pd.read_excel(second_excel_path)\n",
    "state_column = second_excel_data[\"State\"]\n",
    "\n",
    "# Words to remove\n",
    "words_to_remove = [\"risk\", \"tech\"]  # Add more words to remove as needed\n",
    "\n",
    "# Initialize the Porter Stemmer\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "for index, row in excel_data.iterrows():\n",
    "    keyword = row[column_to_match]\n",
    "    keyword = keyword.strip()\n",
    "    \n",
    "    # Remove specific words\n",
    "    for word in words_to_remove:\n",
    "        keyword = keyword.replace(word, '')\n",
    "    \n",
    "    # Perform stemming\n",
    "    keyword = ' '.join(porter_stemmer.stem(word) for word in keyword.lower().split())\n",
    "    \n",
    "    matched_keywords = []\n",
    "    \n",
    "    # Split the keyword into individual words and match each whole word\n",
    "    keywords_to_match = keyword.lower().split()\n",
    "    \n",
    "    for state in state_column:\n",
    "        state = str(state).strip()\n",
    "        \n",
    "        # Remove specific words\n",
    "        for word in words_to_remove:\n",
    "            state = state.replace(word, '')\n",
    "        \n",
    "        # Perform stemming\n",
    "        state = ' '.join(porter_stemmer.stem(word) for word in state.lower().split())\n",
    "        \n",
    "        # Split the state into individual words and match each whole word\n",
    "        state_words = state.lower().split()\n",
    "        \n",
    "        for kw in keywords_to_match:\n",
    "            if len(kw) >= 3 and any(re.fullmatch(rf'\\b{re.escape(kw)}\\b', word) for word in state_words):\n",
    "                matched_keywords.append((kw, 100))  # Exact match, score 100\n",
    "            \n",
    "    # Store the matching details in the results\n",
    "    if matched_keywords:\n",
    "        matching_entry = {\n",
    "            f'Original {column_to_match}': keyword,\n",
    "            f'Matched State': ', '.join([kw[0] for kw in matched_keywords]),\n",
    "            f'State Match Scores': ', '.join([str(kw[1]) for kw in matched_keywords]),\n",
    "            'A': row['A']  # Assuming 'A' is a column in your Excel data\n",
    "        }\n",
    "        \n",
    "        matching_results.append(matching_entry)\n",
    "\n",
    "# Create a new DataFrame to store the results\n",
    "matching_df = pd.DataFrame(matching_results)\n",
    "\n",
    "# Save the matching results to a CSV file\n",
    "matching_df.to_csv('matching_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74d7162",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550242f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bdd4df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7da628",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f077bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e599b8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4306e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# ... (same code as before to extract PDF data) ...\n",
    "\n",
    "# Load your dataset (assuming it's in a DataFrame named 'dataset')\n",
    "# Adjust the path and column names accordingly\n",
    "dataset_path = \"path/to/dataset.xlsx\"\n",
    "dataset = pd.read_excel(dataset_path)\n",
    "keywords_column = \"keywords\"\n",
    "name_column = \"name\"\n",
    "address_column = \"address\"\n",
    "\n",
    "matched_entries = []\n",
    "\n",
    "for index, row in dataset.iterrows():\n",
    "    name = row[name_column]\n",
    "    address = row[address_column]\n",
    "    keywords = row[keywords_column]\n",
    "    \n",
    "    # Convert keywords to lowercase and split into words\n",
    "    keywords_to_match = [word.lower() for word in re.findall(r'\\b\\w+\\b', keywords) if len(word) >= 3]\n",
    "    \n",
    "    # Check if any of the keywords match the PDF data\n",
    "    matched_keywords = [kw for kw in keywords_to_match if kw in ' '.join(pdf_data.values()).lower()]\n",
    "    \n",
    "    if matched_keywords:\n",
    "        matching_entry = {\n",
    "            'Name': name,\n",
    "            'Address': address,\n",
    "            'Matched Keywords': ', '.join(matched_keywords)\n",
    "        }\n",
    "        matched_entries.append(matching_entry)\n",
    "\n",
    "# Create a new DataFrame to store the matched entries\n",
    "matched_df = pd.DataFrame(matched_entries)\n",
    "\n",
    "# Save the matching results to a CSV file\n",
    "matched_df.to_csv('matched_entries.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f47fc4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3868928e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2edebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# ... (same code as before to extract PDF data) ...\n",
    "\n",
    "# Load your dataset (assuming it's in a DataFrame named 'dataset')\n",
    "# Adjust the path and column names accordingly\n",
    "dataset_path = \"path/to/dataset.xlsx\"\n",
    "dataset = pd.read_excel(dataset_path)\n",
    "keywords_column = \"keywords\"\n",
    "name_column = \"name\"\n",
    "address_column = \"address\"\n",
    "\n",
    "matched_entries = []\n",
    "\n",
    "for index, row in dataset.iterrows():\n",
    "    name = row[name_column]\n",
    "    address = row[address_column]\n",
    "    keywords = row[keywords_column]\n",
    "    \n",
    "    # Convert keywords to lowercase and split into words\n",
    "    keywords_to_match = set(word.lower() for word in re.findall(r'\\b\\w+\\b', keywords) if len(word) >= 3)\n",
    "    \n",
    "    # Check if all keywords are present in the PDF data (exact match)\n",
    "    all_keywords_present = all(any(re.search(rf'\\b{kw}\\b', page_text, re.IGNORECASE) for page_text in pdf_data.values()) for kw in keywords_to_match)\n",
    "    \n",
    "    if all_keywords_present:\n",
    "        matching_entry = {\n",
    "            'Name': name,\n",
    "            'Address': address,\n",
    "            'Matched Keywords': ', '.join(keywords_to_match)\n",
    "        }\n",
    "        matched_entries.append(matching_entry)\n",
    "\n",
    "# Create a new DataFrame to store the matched entries\n",
    "matched_df = pd.DataFrame(matched_entries)\n",
    "\n",
    "# Save the matching results to a CSV file\n",
    "matched_df.to_csv('matched_entries.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9ede40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fafdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# ... (same code as before to extract PDF data) ...\n",
    "\n",
    "# Load your dataset (assuming it's in a DataFrame named 'dataset')\n",
    "# Adjust the path and column names accordingly\n",
    "#dataset_path = \"path/to/dataset.xlsx\"\n",
    "#dataset = pd.read_excel(dataset_path)\n",
    "keywords_column = \"keywords\"\n",
    "name_column = \"name\"\n",
    "address_column = \"address\"\n",
    "\n",
    "matched_entries = []\n",
    "\n",
    "for index, row in dataset.iterrows():\n",
    "    name = row[name_column]\n",
    "    address = row[address_column]\n",
    "    keywords = row[keywords_column]\n",
    "    \n",
    "    # Convert keywords to lowercase and split into words\n",
    "    keywords_to_match = set(word.lower() for word in re.findall(r'\\b\\w+\\b', keywords) if len(word) >= 3)\n",
    "    \n",
    "    # Check if all keywords are present in the PDF data (exact match)\n",
    "    all_keywords_present = all(any(re.search(rf'\\b{kw}\\b', page_text, re.IGNORECASE) for page_text in pdf_data.values()) for kw in keywords_to_match)\n",
    "    \n",
    "    if all_keywords_present:\n",
    "        matching_entry = {\n",
    "            'Name': name,\n",
    "            'Address': address,\n",
    "            'Matched Keywords': ', '.join(keywords_to_match)\n",
    "        }\n",
    "        matched_entries.append(matching_entry)\n",
    "\n",
    "# Create a new DataFrame to store the matched entries\n",
    "matched_df = pd.DataFrame(matched_entries)\n",
    "\n",
    "# Save the matching results to a CSV file\n",
    "#matched_df.to_csv('matched_entries.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1b219c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d68f7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# ... (same code as before to extract PDF data) ...\n",
    "\n",
    "# Load your dataset (assuming it's in a DataFrame named 'dataset')\n",
    "# Adjust the path and column names accordingly\n",
    "dataset_path = \"path/to/dataset.xlsx\"\n",
    "dataset = pd.read_excel(dataset_path)\n",
    "keywords_column = \"keywords\"\n",
    "name_column = \"name\"\n",
    "address_column = \"address\"\n",
    "\n",
    "matched_entries = []\n",
    "\n",
    "for index, row in dataset.iterrows():\n",
    "    name = row[name_column]\n",
    "    address = row[address_column]\n",
    "    keywords = row[keywords_column]\n",
    "    \n",
    "    # Convert keywords to lowercase and split into words\n",
    "    keywords_to_match = set(word.lower() for word in re.findall(r'\\b\\w+\\b', keywords) if len(word) >= 3)\n",
    "    \n",
    "    # Check if all keywords are present in the PDF data (exact match)\n",
    "    all_keywords_present = all(any(re.search(rf'\\b{kw}\\b', page_text, re.IGNORECASE) for page_text in pdf_data.values()) for kw in keywords_to_match)\n",
    "    \n",
    "    if all_keywords_present:\n",
    "        matching_entry = {\n",
    "            'Name': name,\n",
    "            'Address': address,\n",
    "            'Matched Keywords': ', '.join(keywords_to_match)\n",
    "        }\n",
    "        matched_entries.append(matching_entry)\n",
    "    else:\n",
    "        # If no keywords match, store the entry without matched keywords\n",
    "        matching_entry = {\n",
    "            'Name': name,\n",
    "            'Address': address,\n",
    "            'Matched Keywords': 'No keywords matched'\n",
    "        }\n",
    "        matched_entries.append(matching_entry)\n",
    "\n",
    "# Create a new DataFrame to store the matched entries\n",
    "matched_df = pd.DataFrame(matched_entries)\n",
    "\n",
    "# Save the matching results to a CSV file\n",
    "matched_df.to_csv('matched_entries.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb20d96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935f0b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rapidfuzz import fuzz\n",
    "import re\n",
    "\n",
    "# ... (same code as before to prepare Excel data) ...\n",
    "\n",
    "# Set the threshold for the match score\n",
    "threshold_score = 100  # Exact match, so setting to 100\n",
    "\n",
    "# Define the columns to match (\"name\" and \"address\")\n",
    "columns_to_match = [\"name\", \"address\"]\n",
    "\n",
    "for index, row in excel_data.iterrows():\n",
    "    # Extract keywords for each row\n",
    "    keywords_to_match = set(row[\"keywords\"].split())  # Assuming keywords are space-separated\n",
    "    \n",
    "    matched_keywords = []\n",
    "    \n",
    "    for state in state_column:\n",
    "        state = str(state).strip()\n",
    "        \n",
    "        # Split the state into individual words\n",
    "        state_words = set(re.findall(r'\\b\\w+\\b', state))\n",
    "        \n",
    "        # Check for exact matches\n",
    "        if keywords_to_match.issubset(state_words):\n",
    "            matched_keywords.append((state, 100))  # Exact match, score 100\n",
    "            \n",
    "    # Store the matching details in the results\n",
    "    if matched_keywords:\n",
    "        matching_entry = {\n",
    "            'Original Name': row['name'],\n",
    "            'Original Address': row['address'],\n",
    "            'Matched State': ', '.join([kw[0] for kw in matched_keywords]),\n",
    "            'State Match Scores': ', '.join([str(kw[1]) for kw in matched_keywords])\n",
    "        }\n",
    "        \n",
    "        matching_results.append(matching_entry)\n",
    "\n",
    "# Create a new DataFrame to store the results\n",
    "matching_df = pd.DataFrame(matching_results)\n",
    "\n",
    "# Save the matching results to a CSV file\n",
    "matching_df.to_csv('matching_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5467de85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# ... (same code as before to prepare Excel data) ...\n",
    "\n",
    "# Set the threshold for the match score\n",
    "threshold_score = 100  # Exact match, so setting to 100\n",
    "\n",
    "# Define the columns to match (\"name\" and \"address\")\n",
    "columns_to_match = [\"name\", \"address\"]\n",
    "\n",
    "for index, row in excel_data.iterrows():\n",
    "    # Extract keywords for each row\n",
    "    keywords_to_match = set(row[\"keywords\"].split())  # Assuming keywords are space-separated\n",
    "    \n",
    "    matched_keywords = []\n",
    "    \n",
    "    for state in state_column:\n",
    "        state = str(state).strip()\n",
    "        \n",
    "        # Split the state into individual words\n",
    "        state_words = set(re.findall(r'\\b\\w+\\b', state))\n",
    "        \n",
    "        # Check for exact matches\n",
    "        if keywords_to_match.issubset(state_words):\n",
    "            matched_keywords.append((state, 100))  # Exact match, score 100\n",
    "            \n",
    "    # Print intermediate results for debugging\n",
    "    print(\"Row:\", index)\n",
    "    print(\"Keywords to match:\", keywords_to_match)\n",
    "    print(\"Matched keywords:\", [kw[0] for kw in matched_keywords])\n",
    "    print(\"-------------\")\n",
    "    \n",
    "    # Store the matching details in the results\n",
    "    if matched_keywords:\n",
    "        matching_entry = {\n",
    "            'Original Name': row['name'],\n",
    "            'Original Address': row['address'],\n",
    "            'Matched State': ', '.join([kw[0] for kw in matched_keywords]),\n",
    "            'State Match Scores': ', '.join([str(kw[1]) for kw in matched_keywords])\n",
    "        }\n",
    "        \n",
    "        matching_results.append(matching_entry)\n",
    "\n",
    "# Create a new DataFrame to store the results\n",
    "matching_df = pd.DataFrame(matching_results)\n",
    "\n",
    "# Save the matching results to a CSV file\n",
    "matching_df.to_csv('matching_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e5aff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# ... (same code as before to prepare Excel data) ...\n",
    "\n",
    "# Assuming you have extracted the data from the PDF and stored it in extracted_pdf_data\n",
    "\n",
    "# Set the threshold for the match score\n",
    "threshold_score = 100  # Exact match, so setting to 100\n",
    "\n",
    "# Define the columns to match (\"name\" and \"address\")\n",
    "columns_to_match = [\"name\", \"address\"]\n",
    "\n",
    "for index, row in excel_data.iterrows():\n",
    "    # Extract keywords for each row\n",
    "    keywords_to_match = set(row[\"keywords\"].split())  # Assuming keywords are space-separated\n",
    "    \n",
    "    matched_keywords = []\n",
    "    \n",
    "    for state in extracted_pdf_data:\n",
    "        state = str(state).strip()\n",
    "        \n",
    "        # Split the state into individual words\n",
    "        state_words = set(re.findall(r'\\b\\w+\\b', state))\n",
    "        \n",
    "        # Check for exact matches\n",
    "        if keywords_to_match.issubset(state_words):\n",
    "            matched_keywords.append((state, 100))  # Exact match, score 100\n",
    "            \n",
    "    # Print intermediate results for debugging\n",
    "    print(\"Row:\", index)\n",
    "    print(\"Keywords to match:\", keywords_to_match)\n",
    "    print(\"Matched keywords:\", [kw[0] for kw in matched_keywords])\n",
    "    print(\"-------------\")\n",
    "    \n",
    "    # Store the matching details in the results\n",
    "    if matched_keywords:\n",
    "        matching_entry = {\n",
    "            'Original Name': row['name'],\n",
    "            'Original Address': row['address'],\n",
    "            'Matched State': ', '.join([kw[0] for kw in matched_keywords]),\n",
    "            'State Match Scores': ', '.join([str(kw[1]) for kw in matched_keywords])\n",
    "        }\n",
    "        \n",
    "        matching_results.append(matching_entry)\n",
    "\n",
    "# Create a new DataFrame to store the results\n",
    "matching_df = pd.DataFrame(matching_results)\n",
    "\n",
    "# Save the matching results to a CSV file\n",
    "matching_df.to_csv('matching_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28d2348",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f19280",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import pandas as pd\n",
    "\n",
    "# Function to extract text from PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    pdf_text = ''\n",
    "    with open(pdf_path, 'rb') as pdf_file:\n",
    "        pdf_reader = PyPDF2.PdfFileReader(pdf_file)\n",
    "        for page_num in range(pdf_reader.numPages):\n",
    "            page = pdf_reader.getPage(page_num)\n",
    "            pdf_text += page.extract_text()\n",
    "    return pdf_text\n",
    "\n",
    "# Load your dataset (assuming it's in a CSV file)\n",
    "data = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "# Load the PDF file and extract text\n",
    "pdf_path = 'path_to_your_pdf_file.pdf'\n",
    "pdf_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "# Iterate through the dataset and match keywords\n",
    "for index, row in data.iterrows():\n",
    "    keywords = row['keywords'].split()  # Assuming keywords are separated by space\n",
    "    name = row['name']\n",
    "    address = row['address']\n",
    "    \n",
    "    # Check if any keyword matches in the PDF text\n",
    "    for keyword in keywords:\n",
    "        if keyword.strip().lower() in pdf_text.lower():\n",
    "            print('Match found for:', name, address)\n",
    "            # You can choose to store or process the matched data further as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f972a63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319b6dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rapidfuzz import fuzz\n",
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# ... (same code as before to extract data from PDF) ...\n",
    "\n",
    "# Set the threshold for the match score\n",
    "threshold_score = 60\n",
    "\n",
    "# Load the Excel data\n",
    "excel_data_path = \"path/to/your_excel_file.xlsx\"  # Update with the actual path\n",
    "excel_data = pd.read_excel(excel_data_path)\n",
    "\n",
    "# Words to remove\n",
    "words_to_remove = [\"risk\", \"tech\"]  # Add more words to remove as needed\n",
    "\n",
    "# Initialize the Porter Stemmer and stopwords\n",
    "porter_stemmer = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Initialize a list to store the matching results\n",
    "matching_results = []\n",
    "\n",
    "# Iterate over the rows in the Excel data\n",
    "for index, row in excel_data.iterrows():\n",
    "    name = row[\"name\"]\n",
    "    address = row[\"address\"]\n",
    "    keywords = row[\"keywords\"]\n",
    "    \n",
    "    # Remove specific words from keywords\n",
    "    for word in words_to_remove:\n",
    "        keywords = keywords.replace(word, '')\n",
    "    \n",
    "    # Convert to lowercase and split into words\n",
    "    keywords_to_match = [porter_stemmer.stem(word.lower()) for word in re.findall(r'\\b\\w+\\b', keywords) if word.lower() not in stop_words and len(word) >= 3]\n",
    "    \n",
    "    matched_keywords = []\n",
    "    \n",
    "    for kw in keywords_to_match:\n",
    "        # Check if the keyword is in the extracted data from the PDF\n",
    "        if any(re.fullmatch(rf'\\b{re.escape(kw)}\\b', word) for word in extracted_data_words):\n",
    "            matched_keywords.append(kw)\n",
    "    \n",
    "    # If there are matched keywords, store the name and address\n",
    "    if matched_keywords:\n",
    "        matching_entry = {\n",
    "            'Name': name,\n",
    "            'Address': address,\n",
    "            'Matched Keywords': ', '.join(matched_keywords)\n",
    "        }\n",
    "        matching_results.append(matching_entry)\n",
    "\n",
    "# Create a new DataFrame to store the matching results\n",
    "matching_df = pd.DataFrame(matching_results)\n",
    "\n",
    "# Save the matching results to a CSV file\n",
    "matching_df.to_csv('matching_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525facc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pdfminer.high_level import extract_text\n",
    "from rapidfuzz import fuzz\n",
    "\n",
    "# Load the PDF and extract paragraphs\n",
    "def extract_paragraphs_from_pdf(pdf_path):\n",
    "    text = extract_text(pdf_path)\n",
    "    # Split text into paragraphs (you may need a different approach based on how the PDF is structured)\n",
    "    paragraphs = text.split('\\n\\n')  \n",
    "    return paragraphs\n",
    "\n",
    "# Load and prepare Excel data\n",
    "excel_data_path = \"path/to/your/excel_file.xlsx\"\n",
    "df = pd.read_excel(excel_data_path)\n",
    "keywords = df['Keyword'].tolist()\n",
    "names = df['name'].tolist()\n",
    "addresses = df['address'].tolist()\n",
    "\n",
    "# Load and extract paragraphs from the PDF\n",
    "pdf_path = \"path/to/your/pdf_file.pdf\"\n",
    "paragraphs = extract_paragraphs_from_pdf(pdf_path)\n",
    "\n",
    "# Initialize a dictionary to store the results\n",
    "results = []\n",
    "\n",
    "# Match keywords against paragraphs and store results\n",
    "for i, keyword in enumerate(keywords):\n",
    "    matched_paragraphs = []\n",
    "    for j, paragraph in enumerate(paragraphs):\n",
    "        if fuzz.ratio(keyword.lower(), paragraph.lower()) > threshold_score:\n",
    "            matched_paragraphs.append(paragraph)\n",
    "    if matched_paragraphs:\n",
    "        results.append({\n",
    "            'name': names[i],\n",
    "            'address': addresses[i],\n",
    "            'keyword': keyword,\n",
    "            'matched_paragraphs': matched_paragraphs\n",
    "        })\n",
    "\n",
    "# Display the results\n",
    "for result in results:\n",
    "    print(f\"Name: {result['name']}\")\n",
    "    print(f\"Address: {result['address']}\")\n",
    "    print(f\"Keyword: {result['keyword']}\")\n",
    "    print(\"Matched Paragraphs:\")\n",
    "    for i, matched_paragraph in enumerate(result['matched_paragraphs'], start=1):\n",
    "        print(f\"Original Paragraph {i}: {matched_paragraph}\")\n",
    "    print(\"=\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c69191",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635409c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import pandas as pd\n",
    "\n",
    "# Function to extract text from PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    pdf_text = ''\n",
    "    with open(pdf_path, 'rb') as pdf_file:\n",
    "        pdf_reader = PyPDF2.PdfFileReader(pdf_file)\n",
    "        for page_num in range(pdf_reader.numPages):\n",
    "            page = pdf_reader.getPage(page_num)\n",
    "            pdf_text += page.extract_text()\n",
    "    return pdf_text\n",
    "\n",
    "# Load your dataset (assuming it's in a CSV file)\n",
    "data = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "# Load the PDF file and extract text\n",
    "pdf_path = 'path_to_your_pdf_file.pdf'\n",
    "pdf_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "# Iterate through the dataset and match keywords\n",
    "for index, row in data.iterrows():\n",
    "    keywords = row['keywords'].split()  # Assuming keywords are separated by space\n",
    "    name = row['name']\n",
    "    address = row['address']\n",
    "    \n",
    "    # Check if any keyword matches in the PDF text\n",
    "    for keyword in keywords:\n",
    "        if keyword.strip().lower() in pdf_text.lower():\n",
    "            print('Match found for:', name, address)\n",
    "            # You can choose to store or process the matched data further as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccb3c55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2b7fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import pandas as pd\n",
    "\n",
    "# Function to extract text from PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    pdf_text = ''\n",
    "    with open(pdf_path, 'rb') as pdf_file:\n",
    "        pdf_reader = PyPDF2.PdfFileReader(pdf_file)\n",
    "        for page_num in range(pdf_reader.numPages):\n",
    "            page = pdf_reader.getPage(page_num)\n",
    "            pdf_text += page.extract_text()\n",
    "    return pdf_text\n",
    "\n",
    "# Load your dataset (assuming it's in a CSV file)\n",
    "data = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "# Load the PDF file and extract text\n",
    "pdf_path = 'path_to_your_pdf_file.pdf'\n",
    "pdf_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "# Initialize an empty list to store the matched data\n",
    "matched_data = []\n",
    "\n",
    "# Iterate through the dataset and match keywords\n",
    "for index, row in data.iterrows():\n",
    "    keywords = row['keywords'].split()  # Assuming keywords are separated by space\n",
    "    name = row['name']\n",
    "    address = row['address']\n",
    "    \n",
    "    # Check if any keyword matches in the PDF text\n",
    "    for keyword in keywords:\n",
    "        if keyword.strip().lower() in pdf_text.lower():\n",
    "            # Extract the paragraph from the PDF for the matched name and address\n",
    "            # Assuming paragraph is the text from the PDF corresponding to name and address\n",
    "            # Modify this part based on your actual way of extracting the paragraph from PDF\n",
    "            paragraph = \"Sample paragraph from PDF\"\n",
    "            \n",
    "            # Append the matched data to the list\n",
    "            matched_data.append({'name': name, 'address': address, 'keywords': row['keywords'], 'paragraph': paragraph})\n",
    "\n",
    "# Create a DataFrame from the matched data\n",
    "matched_df = pd.DataFrame(matched_data)\n",
    "\n",
    "# Display the DataFrame with matched data\n",
    "print(matched_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b759be9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c81e979",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

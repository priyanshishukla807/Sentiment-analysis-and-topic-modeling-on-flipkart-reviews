{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb23f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming your DataFrame is named 'df' and contains 'issue_due_date' and 'remediation_date' columns\n",
    "# Convert 'issue_due_date' and 'remediation_date' to datetime if not already in datetime format\n",
    "df['issue_due_date'] = pd.to_datetime(df['issue_due_date'])\n",
    "df['remediation_date'] = pd.to_datetime(df['remediation_date'])\n",
    "\n",
    "# Calculate the difference between 'issue_due_date' and 'remediation_date' in days and convert to whole numbers\n",
    "df['days_difference'] = (df['issue_due_date'] - df['remediation_date']).dt.days.astype('Int64')\n",
    "\n",
    "# Define conditions and corresponding buckets\n",
    "conditions = [\n",
    "    (df['days_difference'] < -365),\n",
    "    (df['days_difference'] >= -365) & (df['days_difference'] <= -100),\n",
    "    (df['days_difference'] >= -99) & (df['days_difference'] <= -29),\n",
    "    (df['days_difference'] >= -28) & (df['days_difference'] <= -22),\n",
    "    (df['days_difference'] >= -21) & (df['days_difference'] <= -15),\n",
    "    (df['days_difference'] >= -14) & (df['days_difference'] <= -8),\n",
    "    (df['days_difference'] >= -7) & (df['days_difference'] <= -1),\n",
    "    (df['days_difference'] == 0),\n",
    "    (df['days_difference'] >= 1) & (df['days_difference'] <= 7),\n",
    "    (df['days_difference'] >= 8) & (df['days_difference'] <= 14),\n",
    "    (df['days_difference'] >= 15) & (df['days_difference'] <= 21),\n",
    "    (df['days_difference'] >= 22) & (df['days_difference'] <= 28),\n",
    "    (df['days_difference'] >= 29) & (df['days_difference'] <= 99),\n",
    "    (df['days_difference'] >= 100) & (df['days_difference'] <= 365),\n",
    "    (df['days_difference'] > 365)\n",
    "]\n",
    "\n",
    "# Corresponding bucket labels\n",
    "buckets = [\n",
    "    \"<-365 days before\",\n",
    "    \">365 days before\",\n",
    "    \"100-365 days before\",\n",
    "    \"29-99 days before\",\n",
    "    \"22-28 days before\",\n",
    "    \"15-21 days before\",\n",
    "    \"8-14 days before\",\n",
    "    \"1-7 days before\",\n",
    "    \"On the due date\",\n",
    "    \"1-7 days after\",\n",
    "    \"8-14 days after\",\n",
    "    \"15-21 days after\",\n",
    "    \"22-28 days after\",\n",
    "    \"29-99 days after\",\n",
    "    \"100-365 days after\",\n",
    "    \">365 days after\"\n",
    "]\n",
    "\n",
    "# Create a new column 'bucket' based on the conditions\n",
    "df['bucket'] = pd.Series(np.select(conditions, buckets, default=''), dtype='str')\n",
    "\n",
    "# Drop the temporary column 'days_difference' if not needed\n",
    "df.drop('days_difference', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fbfff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remediation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming your DataFrame is named 'df' and contains 'issue_due_date' and 'remediation_date' columns\n",
    "# Convert 'issue_due_date' and 'remediation_date' to datetime if not already in datetime format\n",
    "df['issue_due_date'] = pd.to_datetime(df['issue_due_date'])\n",
    "df['remediation_date'] = pd.to_datetime(df['remediation_date'])\n",
    "\n",
    "# Calculate the difference between 'issue_due_date' and 'remediation_date' in days and convert to whole numbers\n",
    "df['days_difference'] = (df['issue_due_date'] - df['remediation_date']).dt.days.astype('Int64')\n",
    "\n",
    "# Define conditions and corresponding buckets\n",
    "conditions = [\n",
    "    (df['days_difference'] < -365),\n",
    "    (df['days_difference'] >= -365) & (df['days_difference'] <= -100),\n",
    "    (df['days_difference'] >= -99) & (df['days_difference'] <= -29),\n",
    "    (df['days_difference'] >= -28) & (df['days_difference'] <= -22),\n",
    "    (df['days_difference'] >= -21) & (df['days_difference'] <= -15),\n",
    "    (df['days_difference'] >= -14) & (df['days_difference'] <= -8),\n",
    "    (df['days_difference'] >= -7) & (df['days_difference'] <= -1),\n",
    "    (df['days_difference'] == 0),\n",
    "    (df['days_difference'] >= 1) & (df['days_difference'] <= 7),\n",
    "    (df['days_difference'] >= 8) & (df['days_difference'] <= 14),\n",
    "    (df['days_difference'] >= 15) & (df['days_difference'] <= 21),\n",
    "    (df['days_difference'] >= 22) & (df['days_difference'] <= 28),\n",
    "    (df['days_difference'] >= 29) & (df['days_difference'] <= 99),\n",
    "    (df['days_difference'] >= 100) & (df['days_difference'] <= 365),\n",
    "    (df['days_difference'] > 365)\n",
    "]\n",
    "\n",
    "# Corresponding bucket labels\n",
    "buckets = [\n",
    "    \"<-365 days before\",\n",
    "    \">365 days before\",\n",
    "    \"100-365 days before\",\n",
    "    \"29-99 days before\",\n",
    "    \"22-28 days before\",\n",
    "    \"15-21 days before\",\n",
    "    \"8-14 days before\",\n",
    "    \"1-7 days before\",\n",
    "    \"On the due date\",\n",
    "    \"1-7 days after\",\n",
    "    \"8-14 days after\",\n",
    "    \"15-21 days after\",\n",
    "    \"22-28 days after\",\n",
    "    \"29-99 days after\",\n",
    "    \"100-365 days after\",\n",
    "    \">365 days after\"\n",
    "]\n",
    "\n",
    "# Create a new column 'bucket' based on the conditions\n",
    "df['bucket'] = pd.Series(np.select(conditions, buckets, default=''), dtype='str')\n",
    "\n",
    "# Drop the temporary column 'days_difference' if not needed\n",
    "df.drop('days_difference', axis=1, inplace=True)\n",
    "\n",
    "# Save the DataFrame to a new sheet named \"Remediation\" in the same Excel workbook\n",
    "with pd.ExcelWriter('your_workbook.xlsx', engine='openpyxl') as writer:\n",
    "    writer.book = writer.sheets['Remediation']\n",
    "    df.to_excel(writer, sheet_name='Remediation', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfd9d29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2f0c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#At Risk \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming your DataFrame is named 'df' and contains 'marked_at_risk_date', 'due_date', and 'status' columns\n",
    "# Convert 'marked_at_risk_date' and 'due_date' to datetime if not already in datetime format\n",
    "df['marked_at_risk_date'] = pd.to_datetime(df['marked_at_risk_date'])\n",
    "df['due_date'] = pd.to_datetime(df['due_date'])\n",
    "\n",
    "# Create a condition to filter rows where status was ever marked as \"risk\" for each ID\n",
    "condition_risk = df.groupby('ID')['status'].transform(lambda x: 'risk' in x.values)\n",
    "\n",
    "# Filter the DataFrame for entries where the ID was ever marked at risk\n",
    "df_at_risk = df[condition_risk]\n",
    "\n",
    "# Calculate the difference between 'marked_at_risk_date' and 'due_date' in days and convert to whole numbers\n",
    "df_at_risk['days_difference_risk'] = (df_at_risk['marked_at_risk_date'] - df_at_risk['due_date']).dt.days.astype('Int64')\n",
    "\n",
    "# Define conditions and corresponding buckets for \"At risk\"\n",
    "conditions_risk = [\n",
    "    (df_at_risk['days_difference_risk'] < -365),\n",
    "    (df_at_risk['days_difference_risk'] >= -365) & (df_at_risk['days_difference_risk'] <= -100),\n",
    "    (df_at_risk['days_difference_risk'] >= -99) & (df_at_risk['days_difference_risk'] <= -29),\n",
    "    (df_at_risk['days_difference_risk'] >= -28) & (df_at_risk['days_difference_risk'] <= -22),\n",
    "    (df_at_risk['days_difference_risk'] >= -21) & (df_at_risk['days_difference_risk'] <= -15),\n",
    "    (df_at_risk['days_difference_risk'] >= -14) & (df_at_risk['days_difference_risk'] <= -8),\n",
    "    (df_at_risk['days_difference_risk'] >= -7) & (df_at_risk['days_difference_risk'] <= -1),\n",
    "    (df_at_risk['days_difference_risk'] == 0),\n",
    "    (df_at_risk['days_difference_risk'] >= 1) & (df_at_risk['days_difference_risk'] <= 7),\n",
    "    (df_at_risk['days_difference_risk'] >= 8) & (df_at_risk['days_difference_risk'] <= 14),\n",
    "    (df_at_risk['days_difference_risk'] >= 15) & (df_at_risk['days_difference_risk'] <= 21),\n",
    "    (df_at_risk['days_difference_risk'] >= 22) & (df_at_risk['days_difference_risk'] <= 28),\n",
    "    (df_at_risk['days_difference_risk'] >= 29) & (df_at_risk['days_difference_risk'] <= 99),\n",
    "    (df_at_risk['days_difference_risk'] >= 100) & (df_at_risk['days_difference_risk'] <= 365),\n",
    "    (df_at_risk['days_difference_risk'] > 365)\n",
    "]\n",
    "\n",
    "# Corresponding bucket labels for \"At risk\"\n",
    "buckets_risk = [\n",
    "    \"<-365 days before\",\n",
    "    \">365 days before\",\n",
    "    \"100-365 days before\",\n",
    "    \"29-99 days before\",\n",
    "    \"22-28 days before\",\n",
    "    \"15-21 days before\",\n",
    "    \"8-14 days before\",\n",
    "    \"1-7 days before\",\n",
    "    \"On the due date\",\n",
    "    \"1-7 days after\",\n",
    "    \"8-14 days after\",\n",
    "    \"15-21 days after\",\n",
    "    \"22-28 days after\",\n",
    "    \"29-99 days after\",\n",
    "    \"100-365 days after\",\n",
    "    \">365 days after\"\n",
    "]\n",
    "\n",
    "# Create a new column 'bucket_risk' based on the conditions for \"At risk\"\n",
    "df_at_risk['bucket_risk'] = pd.Series(np.select(conditions_risk, buckets_risk, default=''), dtype='str')\n",
    "\n",
    "# Save the DataFrame to a new sheet named \"At risk\" in the same Excel workbook\n",
    "with pd.ExcelWriter('your_workbook.xlsx', engine='openpyxl', mode='a') as writer:\n",
    "    df_at_risk.to_excel(writer, sheet_name='At risk', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60fcfe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f804c7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#over vs marked risk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming your DataFrame is named 'df' and contains 'marked_at_risk_date', 'due_date', and 'status' columns\n",
    "# Convert 'marked_at_risk_date', 'due_date', and 'remediation_date' to datetime if not already in datetime format\n",
    "df['marked_at_risk_date'] = pd.to_datetime(df['marked_at_risk_date'])\n",
    "df['due_date'] = pd.to_datetime(df['due_date'])\n",
    "df['remediation_date'] = pd.to_datetime(df['remediation_date'])\n",
    "\n",
    "# Create a condition to filter rows where status was ever marked as \"risk\" for each ID\n",
    "condition_risk = df.groupby('ID')['status'].transform(lambda x: 'risk' in x.values)\n",
    "\n",
    "# Filter the DataFrame for entries where the ID was ever marked at risk and \"Due date\" < \"Remediation date\"\n",
    "df_overdue_at_risk = df[condition_risk & (df['due_date'] < df['remediation_date'])]\n",
    "\n",
    "# Calculate the difference between 'due_date' and 'marked_at_risk_date' in days and convert to whole numbers\n",
    "df_overdue_at_risk['days_difference_overdue_at_risk'] = (df_overdue_at_risk['due_date'] - df_overdue_at_risk['marked_at_risk_date']).dt.days.astype('Int64')\n",
    "\n",
    "# Define conditions and corresponding buckets for \"Overdue and at risk\"\n",
    "conditions_overdue_at_risk = [\n",
    "    (df_overdue_at_risk['days_difference_overdue_at_risk'] < -365),\n",
    "    (df_overdue_at_risk['days_difference_overdue_at_risk'] >= -365) & (df_overdue_at_risk['days_difference_overdue_at_risk'] <= -100),\n",
    "    (df_overdue_at_risk['days_difference_overdue_at_risk'] >= -99) & (df_overdue_at_risk['days_difference_overdue_at_risk'] <= -29),\n",
    "    (df_overdue_at_risk['days_difference_overdue_at_risk'] >= -28) & (df_overdue_at_risk['days_difference_overdue_at_risk'] <= -22),\n",
    "    (df_overdue_at_risk['days_difference_overdue_at_risk'] >= -21) & (df_overdue_at_risk['days_difference_overdue_at_risk'] <= -15),\n",
    "    (df_overdue_at_risk['days_difference_overdue_at_risk'] >= -14) & (df_overdue_at_risk['days_difference_overdue_at_risk'] <= -8),\n",
    "    (df_overdue_at_risk['days_difference_overdue_at_risk'] >= -7) & (df_overdue_at_risk['days_difference_overdue_at_risk'] <= -1),\n",
    "    (df_overdue_at_risk['days_difference_overdue_at_risk'] == 0),\n",
    "    (df_overdue_at_risk['days_difference_overdue_at_risk'] >= 1) & (df_overdue_at_risk['days_difference_overdue_at_risk'] <= 7),\n",
    "    (df_overdue_at_risk['days_difference_overdue_at_risk'] >= 8) & (df_overdue_at_risk['days_difference_overdue_at_risk'] <= 14),\n",
    "    (df_overdue_at_risk['days_difference_overdue_at_risk'] >= 15) & (df_overdue_at_risk['days_difference_overdue_at_risk'] <= 21),\n",
    "    (df_overdue_at_risk['days_difference_overdue_at_risk'] >= 22) & (df_overdue_at_risk['days_difference_overdue_at_risk'] <= 28),\n",
    "    (df_overdue_at_risk['days_difference_overdue_at_risk'] >= 29) & (df_overdue_at_risk['days_difference_overdue_at_risk'] <= 99),\n",
    "    (df_overdue_at_risk['days_difference_overdue_at_risk'] >= 100) & (df_overdue_at_risk['days_difference_overdue_at_risk'] <= 365),\n",
    "    (df_overdue_at_risk['days_difference_overdue_at_risk'] > 365)\n",
    "]\n",
    "\n",
    "# Corresponding bucket labels for \"Overdue and at risk\"\n",
    "buckets_overdue_at_risk = [\n",
    "    \"<-365 days before\",\n",
    "    \">365 days before\",\n",
    "    \"100-365 days before\",\n",
    "    \"29-99 days before\",\n",
    "    \"22-28 days before\",\n",
    "    \"15-21 days before\",\n",
    "    \"8-14 days before\",\n",
    "    \"1-7 days before\",\n",
    "    \"On the due date\",\n",
    "    \"1-7 days after\",\n",
    "    \"8-14 days after\",\n",
    "    \"15-21 days after\",\n",
    "    \"22-28 days after\",\n",
    "    \"29-99 days after\",\n",
    "    \"100-365 days after\",\n",
    "    \">365 days after\"\n",
    "]\n",
    "\n",
    "# Create a new column 'bucket_overdue_at_risk' based on the conditions for \"Overdue and at risk\"\n",
    "df_overdue_at_risk['bucket_overdue_at_risk'] = pd.Series(np.select(conditions_overdue_at_risk, buckets_overdue_at_risk, default=''), dtype='str')\n",
    "\n",
    "# Save the DataFrame to a new sheet named \"Overdue and at risk\" in the same Excel workbook\n",
    "with pd.ExcelWriter('your_workbook.xlsx', engine='openpyxl', mode='a') as writer:\n",
    "    df_overdue_at_risk.to_excel(writer, sheet_name='Overdue and at risk', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341dcae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data from each sheet in different workbooks\n",
    "df_data = pd.read_excel('workbook_data.xlsx', sheet_name='Data')\n",
    "df_remediation = pd.read_excel('workbook_remediation.xlsx', sheet_name='Remediation')\n",
    "df_at_risk = pd.read_excel('workbook_at_risk.xlsx', sheet_name='At risk')\n",
    "df_overdue_at_risk = pd.read_excel('workbook_overdue_at_risk.xlsx', sheet_name='Overdue and at risk')\n",
    "\n",
    "# Concatenate DataFrames along the rows\n",
    "df_master = pd.concat([df_data, df_remediation, df_at_risk, df_overdue_at_risk], ignore_index=True)\n",
    "\n",
    "# Save the master DataFrame to a new sheet in the master workbook\n",
    "with pd.ExcelWriter('master_workbook.xlsx', engine='openpyxl') as writer:\n",
    "    df_master.to_excel(writer, sheet_name='Master', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3af55bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your DataFrame is named 'df'\n",
    "\n",
    "# Find the second-top change_date for each group\n",
    "second_top_dates = (\n",
    "    df.groupby('ID')['change_date']\n",
    "    .agg(lambda x: x.nlargest(2).iloc[-1] if len(x) > 1 else x.min())\n",
    "    .reset_index(name='second_top_date')\n",
    ")\n",
    "\n",
    "# Merge the second-top dates back into the original DataFrame\n",
    "df = pd.merge(df, second_top_dates, on='ID', how='left')\n",
    "\n",
    "# Create a new column with the minimum change_date for each group\n",
    "df['min_change_date'] = df.groupby('ID')['change_date'].transform('min')\n",
    "\n",
    "# Fill NaN values in 'second_top_date' with the respective minimum change_date\n",
    "df['second_top_date'].fillna(df['min_change_date'], inplace=True)\n",
    "\n",
    "# Drop the temporary columns if not needed\n",
    "df.drop(['min_change_date'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e60986",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Group the DataFrame by 'ID' and find the second maximum date for each group\n",
    "second_max_dates = df.groupby('ID')['date'].nlargest(2).reset_index(level=1, drop=True).groupby('ID').min()\n",
    "\n",
    "# Merge the second maximum dates back to the original DataFrame based on 'ID'\n",
    "result_df = df.merge(second_max_dates, left_on='ID', right_index=True, suffixes=('', '_second_max'))\n",
    "\n",
    "# Rename the column to 'second_max_date'\n",
    "result_df.rename(columns={'date': 'second_max_date'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4512b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tkinter import filedialog\n",
    "from IPython import get_ipython\n",
    "\n",
    "# Ensure Tkinter is properly initialized in IPython\n",
    "get_ipython().run_line_magic('gui', 'tk')\n",
    "\n",
    "# Ask the user to select a CSV file\n",
    "file_path = filedialog.askopenfilename(title=\"Select a CSV file\", filetypes=[(\"CSV files\", \"*.csv\")])\n",
    "\n",
    "# Check if a file was selected\n",
    "if file_path:\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Display the DataFrame or perform further operations\n",
    "    print(\"DataFrame from selected file:\")\n",
    "    print(df)\n",
    "else:\n",
    "    print(\"No file selected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6330a9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tkinter import filedialog\n",
    "from IPython import get_ipython\n",
    "\n",
    "# Ensure Tkinter is properly initialized in IPython\n",
    "get_ipython().run_line_magic('gui', 'tk')\n",
    "\n",
    "# Ask the user to select a CSV or Excel file\n",
    "file_path = filedialog.askopenfilename(\n",
    "    title=\"Select a file\",\n",
    "    filetypes=[(\"CSV files\", \"*.csv\"), (\"Excel files\", \"*.xlsx\")]\n",
    ")\n",
    "\n",
    "# Check if a file was selected\n",
    "if file_path:\n",
    "    # Determine the file type and read into a DataFrame accordingly\n",
    "    if file_path.lower().endswith('.csv'):\n",
    "        df = pd.read_csv(file_path)\n",
    "    elif file_path.lower().endswith('.xlsx'):\n",
    "        df = pd.read_excel(file_path)\n",
    "    else:\n",
    "        print(\"Unsupported file format. Please select a CSV or Excel file.\")\n",
    "        df = None\n",
    "\n",
    "    # Display the DataFrame or perform further operations\n",
    "    if df is not None:\n",
    "        print(\"DataFrame from selected file:\")\n",
    "        print(df)\n",
    "else:\n",
    "    print(\"No file selected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce2f230",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ask the user to enter the file path\n",
    "file_path = input(\"Enter the full path of the CSV or Excel file: \")\n",
    "\n",
    "# Check if a file path was provided\n",
    "if file_path:\n",
    "    # Determine the file type and read into a DataFrame accordingly\n",
    "    if file_path.lower().endswith('.csv'):\n",
    "        df = pd.read_csv(file_path)\n",
    "    elif file_path.lower().endswith('.xlsx'):\n",
    "        df = pd.read_excel(file_path)\n",
    "    else:\n",
    "        print(\"Unsupported file format. Please provide a path to a CSV or Excel file.\")\n",
    "        df = None\n",
    "\n",
    "    # Display the DataFrame or perform further operations\n",
    "    if df is not None:\n",
    "        print(\"DataFrame from selected file:\")\n",
    "        print(df)\n",
    "else:\n",
    "    print(\"No file path provided.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e930ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f6aa04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad7e30f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

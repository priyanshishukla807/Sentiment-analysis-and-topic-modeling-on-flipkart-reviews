{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb23f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming your DataFrame is named 'df' and contains 'issue_due_date' and 'remediation_date' columns\n",
    "# Convert 'issue_due_date' and 'remediation_date' to datetime if not already in datetime format\n",
    "df['issue_due_date'] = pd.to_datetime(df['issue_due_date'])\n",
    "df['remediation_date'] = pd.to_datetime(df['remediation_date'])\n",
    "\n",
    "# Calculate the difference between 'issue_due_date' and 'remediation_date' in days and convert to whole numbers\n",
    "df['days_difference'] = (df['issue_due_date'] - df['remediation_date']).dt.days.astype('Int64')\n",
    "\n",
    "# Define conditions and corresponding buckets\n",
    "conditions = [\n",
    "    (df['days_difference'] < -365),\n",
    "    (df['days_difference'] >= -365) & (df['days_difference'] <= -100),\n",
    "    (df['days_difference'] >= -99) & (df['days_difference'] <= -29),\n",
    "    (df['days_difference'] >= -28) & (df['days_difference'] <= -22),\n",
    "    (df['days_difference'] >= -21) & (df['days_difference'] <= -15),\n",
    "    (df['days_difference'] >= -14) & (df['days_difference'] <= -8),\n",
    "    (df['days_difference'] >= -7) & (df['days_difference'] <= -1),\n",
    "    (df['days_difference'] == 0),\n",
    "    (df['days_difference'] >= 1) & (df['days_difference'] <= 7),\n",
    "    (df['days_difference'] >= 8) & (df['days_difference'] <= 14),\n",
    "    (df['days_difference'] >= 15) & (df['days_difference'] <= 21),\n",
    "    (df['days_difference'] >= 22) & (df['days_difference'] <= 28),\n",
    "    (df['days_difference'] >= 29) & (df['days_difference'] <= 99),\n",
    "    (df['days_difference'] >= 100) & (df['days_difference'] <= 365),\n",
    "    (df['days_difference'] > 365)\n",
    "]\n",
    "\n",
    "# Corresponding bucket labels\n",
    "buckets = [\n",
    "    \"<-365 days before\",\n",
    "    \">365 days before\",\n",
    "    \"100-365 days before\",\n",
    "    \"29-99 days before\",\n",
    "    \"22-28 days before\",\n",
    "    \"15-21 days before\",\n",
    "    \"8-14 days before\",\n",
    "    \"1-7 days before\",\n",
    "    \"On the due date\",\n",
    "    \"1-7 days after\",\n",
    "    \"8-14 days after\",\n",
    "    \"15-21 days after\",\n",
    "    \"22-28 days after\",\n",
    "    \"29-99 days after\",\n",
    "    \"100-365 days after\",\n",
    "    \">365 days after\"\n",
    "]\n",
    "\n",
    "# Create a new column 'bucket' based on the conditions\n",
    "df['bucket'] = pd.Series(np.select(conditions, buckets, default=''), dtype='str')\n",
    "\n",
    "# Drop the temporary column 'days_difference' if not needed\n",
    "df.drop('days_difference', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fbfff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remediation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming your DataFrame is named 'df' and contains 'issue_due_date' and 'remediation_date' columns\n",
    "# Convert 'issue_due_date' and 'remediation_date' to datetime if not already in datetime format\n",
    "df['issue_due_date'] = pd.to_datetime(df['issue_due_date'])\n",
    "df['remediation_date'] = pd.to_datetime(df['remediation_date'])\n",
    "\n",
    "# Calculate the difference between 'issue_due_date' and 'remediation_date' in days and convert to whole numbers\n",
    "df['days_difference'] = (df['issue_due_date'] - df['remediation_date']).dt.days.astype('Int64')\n",
    "\n",
    "# Define conditions and corresponding buckets\n",
    "conditions = [\n",
    "    (df['days_difference'] < -365),\n",
    "    (df['days_difference'] >= -365) & (df['days_difference'] <= -100),\n",
    "    (df['days_difference'] >= -99) & (df['days_difference'] <= -29),\n",
    "    (df['days_difference'] >= -28) & (df['days_difference'] <= -22),\n",
    "    (df['days_difference'] >= -21) & (df['days_difference'] <= -15),\n",
    "    (df['days_difference'] >= -14) & (df['days_difference'] <= -8),\n",
    "    (df['days_difference'] >= -7) & (df['days_difference'] <= -1),\n",
    "    (df['days_difference'] == 0),\n",
    "    (df['days_difference'] >= 1) & (df['days_difference'] <= 7),\n",
    "    (df['days_difference'] >= 8) & (df['days_difference'] <= 14),\n",
    "    (df['days_difference'] >= 15) & (df['days_difference'] <= 21),\n",
    "    (df['days_difference'] >= 22) & (df['days_difference'] <= 28),\n",
    "    (df['days_difference'] >= 29) & (df['days_difference'] <= 99),\n",
    "    (df['days_difference'] >= 100) & (df['days_difference'] <= 365),\n",
    "    (df['days_difference'] > 365)\n",
    "]\n",
    "\n",
    "# Corresponding bucket labels\n",
    "buckets = [\n",
    "    \"<-365 days before\",\n",
    "    \">365 days before\",\n",
    "    \"100-365 days before\",\n",
    "    \"29-99 days before\",\n",
    "    \"22-28 days before\",\n",
    "    \"15-21 days before\",\n",
    "    \"8-14 days before\",\n",
    "    \"1-7 days before\",\n",
    "    \"On the due date\",\n",
    "    \"1-7 days after\",\n",
    "    \"8-14 days after\",\n",
    "    \"15-21 days after\",\n",
    "    \"22-28 days after\",\n",
    "    \"29-99 days after\",\n",
    "    \"100-365 days after\",\n",
    "    \">365 days after\"\n",
    "]\n",
    "\n",
    "# Create a new column 'bucket' based on the conditions\n",
    "df['bucket'] = pd.Series(np.select(conditions, buckets, default=''), dtype='str')\n",
    "\n",
    "# Drop the temporary column 'days_difference' if not needed\n",
    "df.drop('days_difference', axis=1, inplace=True)\n",
    "\n",
    "# Save the DataFrame to a new sheet named \"Remediation\" in the same Excel workbook\n",
    "with pd.ExcelWriter('your_workbook.xlsx', engine='openpyxl') as writer:\n",
    "    writer.book = writer.sheets['Remediation']\n",
    "    df.to_excel(writer, sheet_name='Remediation', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfd9d29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2f0c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#At Risk \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming your DataFrame is named 'df' and contains 'marked_at_risk_date', 'due_date', and 'status' columns\n",
    "# Convert 'marked_at_risk_date' and 'due_date' to datetime if not already in datetime format\n",
    "df['marked_at_risk_date'] = pd.to_datetime(df['marked_at_risk_date'])\n",
    "df['due_date'] = pd.to_datetime(df['due_date'])\n",
    "\n",
    "# Create a condition to filter rows where status was ever marked as \"risk\" for each ID\n",
    "condition_risk = df.groupby('ID')['status'].transform(lambda x: 'risk' in x.values)\n",
    "\n",
    "# Filter the DataFrame for entries where the ID was ever marked at risk\n",
    "df_at_risk = df[condition_risk]\n",
    "\n",
    "# Calculate the difference between 'marked_at_risk_date' and 'due_date' in days and convert to whole numbers\n",
    "df_at_risk['days_difference_risk'] = (df_at_risk['marked_at_risk_date'] - df_at_risk['due_date']).dt.days.astype('Int64')\n",
    "\n",
    "# Define conditions and corresponding buckets for \"At risk\"\n",
    "conditions_risk = [\n",
    "    (df_at_risk['days_difference_risk'] < -365),\n",
    "    (df_at_risk['days_difference_risk'] >= -365) & (df_at_risk['days_difference_risk'] <= -100),\n",
    "    (df_at_risk['days_difference_risk'] >= -99) & (df_at_risk['days_difference_risk'] <= -29),\n",
    "    (df_at_risk['days_difference_risk'] >= -28) & (df_at_risk['days_difference_risk'] <= -22),\n",
    "    (df_at_risk['days_difference_risk'] >= -21) & (df_at_risk['days_difference_risk'] <= -15),\n",
    "    (df_at_risk['days_difference_risk'] >= -14) & (df_at_risk['days_difference_risk'] <= -8),\n",
    "    (df_at_risk['days_difference_risk'] >= -7) & (df_at_risk['days_difference_risk'] <= -1),\n",
    "    (df_at_risk['days_difference_risk'] == 0),\n",
    "    (df_at_risk['days_difference_risk'] >= 1) & (df_at_risk['days_difference_risk'] <= 7),\n",
    "    (df_at_risk['days_difference_risk'] >= 8) & (df_at_risk['days_difference_risk'] <= 14),\n",
    "    (df_at_risk['days_difference_risk'] >= 15) & (df_at_risk['days_difference_risk'] <= 21),\n",
    "    (df_at_risk['days_difference_risk'] >= 22) & (df_at_risk['days_difference_risk'] <= 28),\n",
    "    (df_at_risk['days_difference_risk'] >= 29) & (df_at_risk['days_difference_risk'] <= 99),\n",
    "    (df_at_risk['days_difference_risk'] >= 100) & (df_at_risk['days_difference_risk'] <= 365),\n",
    "    (df_at_risk['days_difference_risk'] > 365)\n",
    "]\n",
    "\n",
    "# Corresponding bucket labels for \"At risk\"\n",
    "buckets_risk = [\n",
    "    \"<-365 days before\",\n",
    "    \">365 days before\",\n",
    "    \"100-365 days before\",\n",
    "    \"29-99 days before\",\n",
    "    \"22-28 days before\",\n",
    "    \"15-21 days before\",\n",
    "    \"8-14 days before\",\n",
    "    \"1-7 days before\",\n",
    "    \"On the due date\",\n",
    "    \"1-7 days after\",\n",
    "    \"8-14 days after\",\n",
    "    \"15-21 days after\",\n",
    "    \"22-28 days after\",\n",
    "    \"29-99 days after\",\n",
    "    \"100-365 days after\",\n",
    "    \">365 days after\"\n",
    "]\n",
    "\n",
    "# Create a new column 'bucket_risk' based on the conditions for \"At risk\"\n",
    "df_at_risk['bucket_risk'] = pd.Series(np.select(conditions_risk, buckets_risk, default=''), dtype='str')\n",
    "\n",
    "# Save the DataFrame to a new sheet named \"At risk\" in the same Excel workbook\n",
    "with pd.ExcelWriter('your_workbook.xlsx', engine='openpyxl', mode='a') as writer:\n",
    "    df_at_risk.to_excel(writer, sheet_name='At risk', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60fcfe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f804c7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#over vs marked risk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming your DataFrame is named 'df' and contains 'marked_at_risk_date', 'due_date', and 'status' columns\n",
    "# Convert 'marked_at_risk_date', 'due_date', and 'remediation_date' to datetime if not already in datetime format\n",
    "df['marked_at_risk_date'] = pd.to_datetime(df['marked_at_risk_date'])\n",
    "df['due_date'] = pd.to_datetime(df['due_date'])\n",
    "df['remediation_date'] = pd.to_datetime(df['remediation_date'])\n",
    "\n",
    "# Create a condition to filter rows where status was ever marked as \"risk\" for each ID\n",
    "condition_risk = df.groupby('ID')['status'].transform(lambda x: 'risk' in x.values)\n",
    "\n",
    "# Filter the DataFrame for entries where the ID was ever marked at risk and \"Due date\" < \"Remediation date\"\n",
    "df_overdue_at_risk = df[condition_risk & (df['due_date'] < df['remediation_date'])]\n",
    "\n",
    "# Calculate the difference between 'due_date' and 'marked_at_risk_date' in days and convert to whole numbers\n",
    "df_overdue_at_risk['days_difference_overdue_at_risk'] = (df_overdue_at_risk['due_date'] - df_overdue_at_risk['marked_at_risk_date']).dt.days.astype('Int64')\n",
    "\n",
    "# Define conditions and corresponding buckets for \"Overdue and at risk\"\n",
    "conditions_overdue_at_risk = [\n",
    "    (df_overdue_at_risk['days_difference_overdue_at_risk'] < -365),\n",
    "    (df_overdue_at_risk['days_difference_overdue_at_risk'] >= -365) & (df_overdue_at_risk['days_difference_overdue_at_risk'] <= -100),\n",
    "    (df_overdue_at_risk['days_difference_overdue_at_risk'] >= -99) & (df_overdue_at_risk['days_difference_overdue_at_risk'] <= -29),\n",
    "    (df_overdue_at_risk['days_difference_overdue_at_risk'] >= -28) & (df_overdue_at_risk['days_difference_overdue_at_risk'] <= -22),\n",
    "    (df_overdue_at_risk['days_difference_overdue_at_risk'] >= -21) & (df_overdue_at_risk['days_difference_overdue_at_risk'] <= -15),\n",
    "    (df_overdue_at_risk['days_difference_overdue_at_risk'] >= -14) & (df_overdue_at_risk['days_difference_overdue_at_risk'] <= -8),\n",
    "    (df_overdue_at_risk['days_difference_overdue_at_risk'] >= -7) & (df_overdue_at_risk['days_difference_overdue_at_risk'] <= -1),\n",
    "    (df_overdue_at_risk['days_difference_overdue_at_risk'] == 0),\n",
    "    (df_overdue_at_risk['days_difference_overdue_at_risk'] >= 1) & (df_overdue_at_risk['days_difference_overdue_at_risk'] <= 7),\n",
    "    (df_overdue_at_risk['days_difference_overdue_at_risk'] >= 8) & (df_overdue_at_risk['days_difference_overdue_at_risk'] <= 14),\n",
    "    (df_overdue_at_risk['days_difference_overdue_at_risk'] >= 15) & (df_overdue_at_risk['days_difference_overdue_at_risk'] <= 21),\n",
    "    (df_overdue_at_risk['days_difference_overdue_at_risk'] >= 22) & (df_overdue_at_risk['days_difference_overdue_at_risk'] <= 28),\n",
    "    (df_overdue_at_risk['days_difference_overdue_at_risk'] >= 29) & (df_overdue_at_risk['days_difference_overdue_at_risk'] <= 99),\n",
    "    (df_overdue_at_risk['days_difference_overdue_at_risk'] >= 100) & (df_overdue_at_risk['days_difference_overdue_at_risk'] <= 365),\n",
    "    (df_overdue_at_risk['days_difference_overdue_at_risk'] > 365)\n",
    "]\n",
    "\n",
    "# Corresponding bucket labels for \"Overdue and at risk\"\n",
    "buckets_overdue_at_risk = [\n",
    "    \"<-365 days before\",\n",
    "    \">365 days before\",\n",
    "    \"100-365 days before\",\n",
    "    \"29-99 days before\",\n",
    "    \"22-28 days before\",\n",
    "    \"15-21 days before\",\n",
    "    \"8-14 days before\",\n",
    "    \"1-7 days before\",\n",
    "    \"On the due date\",\n",
    "    \"1-7 days after\",\n",
    "    \"8-14 days after\",\n",
    "    \"15-21 days after\",\n",
    "    \"22-28 days after\",\n",
    "    \"29-99 days after\",\n",
    "    \"100-365 days after\",\n",
    "    \">365 days after\"\n",
    "]\n",
    "\n",
    "# Create a new column 'bucket_overdue_at_risk' based on the conditions for \"Overdue and at risk\"\n",
    "df_overdue_at_risk['bucket_overdue_at_risk'] = pd.Series(np.select(conditions_overdue_at_risk, buckets_overdue_at_risk, default=''), dtype='str')\n",
    "\n",
    "# Save the DataFrame to a new sheet named \"Overdue and at risk\" in the same Excel workbook\n",
    "with pd.ExcelWriter('your_workbook.xlsx', engine='openpyxl', mode='a') as writer:\n",
    "    df_overdue_at_risk.to_excel(writer, sheet_name='Overdue and at risk', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341dcae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data from each sheet in different workbooks\n",
    "df_data = pd.read_excel('workbook_data.xlsx', sheet_name='Data')\n",
    "df_remediation = pd.read_excel('workbook_remediation.xlsx', sheet_name='Remediation')\n",
    "df_at_risk = pd.read_excel('workbook_at_risk.xlsx', sheet_name='At risk')\n",
    "df_overdue_at_risk = pd.read_excel('workbook_overdue_at_risk.xlsx', sheet_name='Overdue and at risk')\n",
    "\n",
    "# Concatenate DataFrames along the rows\n",
    "df_master = pd.concat([df_data, df_remediation, df_at_risk, df_overdue_at_risk], ignore_index=True)\n",
    "\n",
    "# Save the master DataFrame to a new sheet in the master workbook\n",
    "with pd.ExcelWriter('master_workbook.xlsx', engine='openpyxl') as writer:\n",
    "    df_master.to_excel(writer, sheet_name='Master', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3af55bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your DataFrame is named 'df'\n",
    "\n",
    "# Find the second-top change_date for each group\n",
    "second_top_dates = (\n",
    "    df.groupby('ID')['change_date']\n",
    "    .agg(lambda x: x.nlargest(2).iloc[-1] if len(x) > 1 else x.min())\n",
    "    .reset_index(name='second_top_date')\n",
    ")\n",
    "\n",
    "# Merge the second-top dates back into the original DataFrame\n",
    "df = pd.merge(df, second_top_dates, on='ID', how='left')\n",
    "\n",
    "# Create a new column with the minimum change_date for each group\n",
    "df['min_change_date'] = df.groupby('ID')['change_date'].transform('min')\n",
    "\n",
    "# Fill NaN values in 'second_top_date' with the respective minimum change_date\n",
    "df['second_top_date'].fillna(df['min_change_date'], inplace=True)\n",
    "\n",
    "# Drop the temporary columns if not needed\n",
    "df.drop(['min_change_date'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e60986",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Group the DataFrame by 'ID' and find the second maximum date for each group\n",
    "second_max_dates = df.groupby('ID')['date'].nlargest(2).reset_index(level=1, drop=True).groupby('ID').min()\n",
    "\n",
    "# Merge the second maximum dates back to the original DataFrame based on 'ID'\n",
    "result_df = df.merge(second_max_dates, left_on='ID', right_index=True, suffixes=('', '_second_max'))\n",
    "\n",
    "# Rename the column to 'second_max_date'\n",
    "result_df.rename(columns={'date': 'second_max_date'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4512b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tkinter import filedialog\n",
    "from IPython import get_ipython\n",
    "\n",
    "# Ensure Tkinter is properly initialized in IPython\n",
    "get_ipython().run_line_magic('gui', 'tk')\n",
    "\n",
    "# Ask the user to select a CSV file\n",
    "file_path = filedialog.askopenfilename(title=\"Select a CSV file\", filetypes=[(\"CSV files\", \"*.csv\")])\n",
    "\n",
    "# Check if a file was selected\n",
    "if file_path:\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Display the DataFrame or perform further operations\n",
    "    print(\"DataFrame from selected file:\")\n",
    "    print(df)\n",
    "else:\n",
    "    print(\"No file selected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5246e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tkinter import filedialog\n",
    "from IPython import get_ipython\n",
    "\n",
    "# Ensure Tkinter is properly initialized in IPython\n",
    "get_ipython().run_line_magic('gui', 'tk')\n",
    "\n",
    "# Ask the user to select a CSV or Excel file\n",
    "file_path = filedialog.askopenfilename(\n",
    "    title=\"Select a file\",\n",
    "    filetypes=[(\"CSV files\", \"*.csv\"), (\"Excel files\", \"*.xlsx\")]\n",
    ")\n",
    "\n",
    "# Check if a file was selected\n",
    "if file_path:\n",
    "    # Determine the file type and read into a DataFrame accordingly\n",
    "    if file_path.lower().endswith('.csv'):\n",
    "        df = pd.read_csv(file_path)\n",
    "    elif file_path.lower().endswith('.xlsx'):\n",
    "        df = pd.read_excel(file_path)\n",
    "    else:\n",
    "        print(\"Unsupported file format. Please select a CSV or Excel file.\")\n",
    "        df = None\n",
    "\n",
    "    # Display the DataFrame or perform further operations\n",
    "    if df is not None:\n",
    "        print(\"DataFrame from selected file:\")\n",
    "        print(df)\n",
    "else:\n",
    "    print(\"No file selected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a781d430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ask the user to enter the file path\n",
    "file_path = input(\"Enter the full path of the CSV or Excel file: \")\n",
    "\n",
    "# Check if a file path was provided\n",
    "if file_path:\n",
    "    # Determine the file type and read into a DataFrame accordingly\n",
    "    if file_path.lower().endswith('.csv'):\n",
    "        df = pd.read_csv(file_path)\n",
    "    elif file_path.lower().endswith('.xlsx'):\n",
    "        df = pd.read_excel(file_path)\n",
    "    else:\n",
    "        print(\"Unsupported file format. Please provide a path to a CSV or Excel file.\")\n",
    "        df = None\n",
    "\n",
    "    # Display the DataFrame or perform further operations\n",
    "    if df is not None:\n",
    "        print(\"DataFrame from selected file:\")\n",
    "        print(df)\n",
    "else:\n",
    "    print(\"No file path provided.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27946376",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ask the user to enter the file path\n",
    "file_path = input(\"Enter the full path of the CSV or Excel file: \")\n",
    "\n",
    "# Check if a file path was provided\n",
    "if file_path:\n",
    "    # Determine the file type and read into a DataFrame accordingly\n",
    "    if file_path.lower().endswith('.csv'):\n",
    "        try:\n",
    "            # Try reading with UTF-8 first\n",
    "            df = pd.read_csv(file_path, encoding='utf-8')\n",
    "        except UnicodeDecodeError:\n",
    "            # If UTF-8 fails, try a different encoding (e.g., 'latin-1' or 'ISO-8859-1')\n",
    "            df = pd.read_csv(file_path, encoding='latin-1')\n",
    "    elif file_path.lower().endswith('.xlsx'):\n",
    "        df = pd.read_excel(file_path)\n",
    "    else:\n",
    "        print(\"Unsupported file format. Please provide a path to a CSV or Excel file.\")\n",
    "        df = None\n",
    "\n",
    "    # Display the DataFrame or perform further operations\n",
    "    if df is not None:\n",
    "        print(\"DataFrame from selected file:\")\n",
    "        print(df)\n",
    "else:\n",
    "    print(\"No file path provided.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a5474e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Function to handle file upload and processing\n",
    "def handle_upload(change):\n",
    "    uploaded_file = upload_button.value\n",
    "    if uploaded_file:\n",
    "        # Read the file into a DataFrame\n",
    "        content = uploaded_file['content']\n",
    "        file_extension = uploaded_file['metadata']['name'].split('.')[-1]\n",
    "\n",
    "        if file_extension.lower() == 'csv':\n",
    "            df = pd.read_csv(io.BytesIO(content))\n",
    "        elif file_extension.lower() in ['xls', 'xlsx']:\n",
    "            df = pd.read_excel(io.BytesIO(content))\n",
    "        else:\n",
    "            print(\"Unsupported file format. Please upload a CSV or Excel file.\")\n",
    "            return\n",
    "\n",
    "        # Display the DataFrame or perform further operations\n",
    "        print(\"DataFrame from uploaded file:\")\n",
    "        display(df)\n",
    "\n",
    "# Create a FileUpload widget\n",
    "upload_button = widgets.FileUpload(accept='.csv, .xlsx', multiple=False)\n",
    "upload_button.observe(handle_upload, names='value')\n",
    "\n",
    "# Display the FileUpload widget\n",
    "display(upload_button)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61217fe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4734e5d0db8343b1b46c9ac4058c43d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value={}, accept='.csv, .xlsx', description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'content'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipywidgets\\widgets\\widget.py:676\u001b[0m, in \u001b[0;36mWidget._handle_msg\u001b[1;34m(self, msg)\u001b[0m\n\u001b[0;32m    674\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbuffer_paths\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[0;32m    675\u001b[0m             _put_buffers(state, data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbuffer_paths\u001b[39m\u001b[38;5;124m'\u001b[39m], msg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbuffers\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m--> 676\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[38;5;66;03m# Handle a state request.\u001b[39;00m\n\u001b[0;32m    679\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrequest_state\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipywidgets\\widgets\\widget.py:545\u001b[0m, in \u001b[0;36mWidget.set_state\u001b[1;34m(self, sync_data)\u001b[0m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeys:\n\u001b[0;32m    543\u001b[0m     from_json \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrait_metadata(name, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrom_json\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    544\u001b[0m                                     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trait_from_json)\n\u001b[1;32m--> 545\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_trait(name, from_json(sync_data[name], \u001b[38;5;28mself\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\contextlib.py:126\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 126\u001b[0m         \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    128\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\traitlets\\traitlets.py:1216\u001b[0m, in \u001b[0;36mHasTraits.hold_trait_notifications\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m changes \u001b[38;5;129;01min\u001b[39;00m cache\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[0;32m   1215\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m change \u001b[38;5;129;01min\u001b[39;00m changes:\n\u001b[1;32m-> 1216\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnotify_change\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchange\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipywidgets\\widgets\\widget.py:606\u001b[0m, in \u001b[0;36mWidget.notify_change\u001b[1;34m(self, change)\u001b[0m\n\u001b[0;32m    603\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeys \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_send_property(name, \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)):\n\u001b[0;32m    604\u001b[0m         \u001b[38;5;66;03m# Send new state to front-end\u001b[39;00m\n\u001b[0;32m    605\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend_state(key\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m--> 606\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mWidget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnotify_change\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchange\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\traitlets\\traitlets.py:1229\u001b[0m, in \u001b[0;36mHasTraits.notify_change\u001b[1;34m(self, change)\u001b[0m\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnotify_change\u001b[39m(\u001b[38;5;28mself\u001b[39m, change):\n\u001b[0;32m   1228\u001b[0m     \u001b[38;5;124;03m\"\"\"Notify observers of a change event\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1229\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_notify_observers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchange\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\traitlets\\traitlets.py:1266\u001b[0m, in \u001b[0;36mHasTraits._notify_observers\u001b[1;34m(self, event)\u001b[0m\n\u001b[0;32m   1263\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(c, EventHandler) \u001b[38;5;129;01mand\u001b[39;00m c\u001b[38;5;241m.\u001b[39mname \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1264\u001b[0m     c \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, c\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m-> 1266\u001b[0m \u001b[43mc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevent\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipywidgets\\widgets\\widget_upload.py:64\u001b[0m, in \u001b[0;36mFileUpload.on_incr_counter\u001b[1;34m(self, change)\u001b[0m\n\u001b[0;32m     62\u001b[0m     name \u001b[38;5;241m=\u001b[39m metadata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     63\u001b[0m     res[name] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m'\u001b[39m: metadata, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m: content}\n\u001b[1;32m---> 64\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_trait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mres\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\traitlets\\traitlets.py:1438\u001b[0m, in \u001b[0;36mHasTraits.set_trait\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   1435\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m TraitError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClass \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m does not have a trait named \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1436\u001b[0m                         (\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n\u001b[0;32m   1437\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1438\u001b[0m     \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\traitlets\\traitlets.py:595\u001b[0m, in \u001b[0;36mTraitType.set\u001b[1;34m(self, obj, value)\u001b[0m\n\u001b[0;32m    591\u001b[0m     silent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    592\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m silent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    593\u001b[0m     \u001b[38;5;66;03m# we explicitly compare silent to True just in case the equality\u001b[39;00m\n\u001b[0;32m    594\u001b[0m     \u001b[38;5;66;03m# comparison above returns something other than True/False\u001b[39;00m\n\u001b[1;32m--> 595\u001b[0m     \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_notify_trait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mold_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_value\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\traitlets\\traitlets.py:1219\u001b[0m, in \u001b[0;36mHasTraits._notify_trait\u001b[1;34m(self, name, old_value, new_value)\u001b[0m\n\u001b[0;32m   1218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_notify_trait\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, old_value, new_value):\n\u001b[1;32m-> 1219\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnotify_change\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBunch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mold_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnew\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[43m        \u001b[49m\u001b[43mowner\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mchange\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipywidgets\\widgets\\widget.py:606\u001b[0m, in \u001b[0;36mWidget.notify_change\u001b[1;34m(self, change)\u001b[0m\n\u001b[0;32m    603\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeys \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_send_property(name, \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)):\n\u001b[0;32m    604\u001b[0m         \u001b[38;5;66;03m# Send new state to front-end\u001b[39;00m\n\u001b[0;32m    605\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend_state(key\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m--> 606\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mWidget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnotify_change\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchange\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\traitlets\\traitlets.py:1229\u001b[0m, in \u001b[0;36mHasTraits.notify_change\u001b[1;34m(self, change)\u001b[0m\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnotify_change\u001b[39m(\u001b[38;5;28mself\u001b[39m, change):\n\u001b[0;32m   1228\u001b[0m     \u001b[38;5;124;03m\"\"\"Notify observers of a change event\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1229\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_notify_observers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchange\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\traitlets\\traitlets.py:1266\u001b[0m, in \u001b[0;36mHasTraits._notify_observers\u001b[1;34m(self, event)\u001b[0m\n\u001b[0;32m   1263\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(c, EventHandler) \u001b[38;5;129;01mand\u001b[39;00m c\u001b[38;5;241m.\u001b[39mname \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1264\u001b[0m     c \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, c\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m-> 1266\u001b[0m \u001b[43mc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevent\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36mhandle_upload\u001b[1;34m(change)\u001b[0m\n\u001b[0;32m      8\u001b[0m uploaded_file \u001b[38;5;241m=\u001b[39m upload_button\u001b[38;5;241m.\u001b[39mvalue\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m uploaded_file:\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# Read the file into a DataFrame\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m     content \u001b[38;5;241m=\u001b[39m \u001b[43muploaded_file\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     12\u001b[0m     file_extension \u001b[38;5;241m=\u001b[39m uploaded_file[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m file_extension\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcsv\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'content'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Function to handle file upload and processing\n",
    "def handle_upload(change):\n",
    "    uploaded_file = upload_button.value\n",
    "    if uploaded_file:\n",
    "        # Read the file into a DataFrame\n",
    "        content = uploaded_file['content']\n",
    "        file_extension = uploaded_file['metadata']['name'].split('.')[-1]\n",
    "\n",
    "        if file_extension.lower() == 'csv':\n",
    "            df = pd.read_csv(io.BytesIO(content))\n",
    "        elif file_extension.lower() in ['xls', 'xlsx']:\n",
    "            df = pd.read_excel(io.BytesIO(content))\n",
    "        else:\n",
    "            print(\"Unsupported file format. Please upload a CSV or Excel file.\")\n",
    "            return\n",
    "\n",
    "        # Display the DataFrame or perform further operations\n",
    "        print(\"DataFrame from uploaded file:\")\n",
    "        display(df)\n",
    "\n",
    "# Create a FileUpload widget\n",
    "upload_button = widgets.FileUpload(accept='.csv, .xlsx', multiple=False)\n",
    "upload_button.observe(handle_upload, names='value')\n",
    "\n",
    "# Display the FileUpload widget\n",
    "display(upload_button)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd86d297",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, FileLink\n",
    "import ipywidgets as widgets\n",
    "from io import BytesIO\n",
    "\n",
    "# Function to handle file upload and processing\n",
    "def handle_upload(change):\n",
    "    uploaded_file = file_upload.value\n",
    "    if uploaded_file:\n",
    "        # Read the file into a DataFrame\n",
    "        content = uploaded_file['content']\n",
    "        file_extension = uploaded_file['metadata']['name'].split('.')[-1]\n",
    "\n",
    "        if file_extension.lower() == 'csv':\n",
    "            df = pd.read_csv(BytesIO(content))\n",
    "        elif file_extension.lower() in ['xls', 'xlsx']:\n",
    "            df = pd.read_excel(BytesIO(content))\n",
    "        else:\n",
    "            print(\"Unsupported file format. Please upload a CSV or Excel file.\")\n",
    "            return\n",
    "\n",
    "        # Display the DataFrame or perform further operations\n",
    "        print(\"DataFrame from uploaded file:\")\n",
    "        display(df)\n",
    "\n",
    "# Create a FileUpload widget\n",
    "file_upload = widgets.FileUpload(accept='.csv, .xlsx', multiple=False)\n",
    "file_upload.observe(handle_upload, names='value')\n",
    "\n",
    "# Display the FileUpload widget\n",
    "display(file_upload)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3bacbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from io import BytesIO\n",
    "\n",
    "# Function to read and display a DataFrame from a file\n",
    "def read_and_display_file(file_path):\n",
    "    file_extension = file_path.split('.')[-1]\n",
    "\n",
    "    if file_extension.lower() == 'csv':\n",
    "        df = pd.read_csv(file_path)\n",
    "    elif file_extension.lower() in ['xls', 'xlsx']:\n",
    "        df = pd.read_excel(file_path)\n",
    "    else:\n",
    "        print(\"Unsupported file format. Please provide a CSV or Excel file.\")\n",
    "        return\n",
    "\n",
    "    # Display the DataFrame or perform further operations\n",
    "    print(\"DataFrame from selected file:\")\n",
    "    display(df)\n",
    "\n",
    "# Ask the user to input the file path\n",
    "file_path = input(\"Please enter the full path of the CSV or Excel file: \")\n",
    "\n",
    "# Call the function to read and display the DataFrame\n",
    "read_and_display_file(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b72401",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import tkinter as tk from tkinter import filedialog\n",
    "\n",
    "#Get the directory of the current script\n",
    "\n",
    "base_dir = os.path.dirname(os.path.realpath(file))\n",
    "\n",
    "#Create a Tkinter root window root = tk.Tk()\n",
    "\n",
    "root.withdraw() # Hide the root window\n",
    "\n",
    "#Open a file dialog for the user to select a file\n",
    "\n",
    "file_path = filedialog.askopenfilename(initialdir=os.path.expanduser(\"~/Desktop\"), title=\"Select a file\")\n",
    "\n",
    "#Check if a file was selected\n",
    "\n",
    "if file path: print(\"Selected file:\", file_path)\n",
    "\n",
    "#Specify the directory where you want to save the uploaded file upload_dir = os.path.join(base_dir, \"uploaded_files\")\n",
    "\n",
    "#Create the directory if it doesn't exist os.makedirs(upload_dir, exist_ok=True)\n",
    "\n",
    "#Extract the file name from the selected file path file name os.path.basename(file path)\n",
    "\n",
    "Specify the path to save the uplsaded file upload_path= os.path.join(upload dir, file_name)\n",
    "\n",
    "Move the selected file to the upload directory os.rename(file path, upload path)\n",
    "\n",
    "print(\"File saved to:\", upload path) else: print(\"No file selected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7c8b80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a94ffe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f40a287",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d298ea9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a139d31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cad12f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

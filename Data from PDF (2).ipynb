{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fddf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import PyPDF2\n",
    "\n",
    "# Function to extract text from a PDF file, split it into paragraphs, and return page numbers\n",
    "def extract_pdf_text_with_page_numbers(pdf_path, skip_first_lines=1, skip_last_lines=1, skip_first_pages=5):\n",
    "    pdf_text = ''\n",
    "    page_numbers = []\n",
    "    \n",
    "    with open(pdf_path, 'rb') as pdf_file:\n",
    "        pdf_reader = PyPDF2.PdfFileReader(pdf_file)\n",
    "        for page_num in range(skip_first_pages, pdf_reader.numPages):\n",
    "            page = pdf_reader.getPage(page_num)\n",
    "            page_text = page.extract_text()\n",
    "            page_lines = page_text.split('\\n')\n",
    "            \n",
    "            # Skip the specified number of lines from the beginning and end\n",
    "            page_lines = page_lines[skip_first_lines:-skip_last_lines]\n",
    "            \n",
    "            pdf_text += '\\n'.join(page_lines) + '\\n'  # Separate pages by newlines\n",
    "            \n",
    "            # Store page numbers for each paragraph on this page\n",
    "            page_numbers.extend([page_num] * len(page_lines))\n",
    "    \n",
    "    return pdf_text, page_numbers\n",
    "\n",
    "# Function to split lines into paragraphs\n",
    "def split_into_paragraphs(lines):\n",
    "    paragraphs = []\n",
    "    current_paragraph = []\n",
    "    for line in lines:\n",
    "        if line.strip():\n",
    "            current_paragraph.append(line)\n",
    "        else:\n",
    "            if current_paragraph:\n",
    "                paragraphs.append('\\n'.join(current_paragraph))\n",
    "                current_paragraph = []\n",
    "    if current_paragraph:\n",
    "        paragraphs.append('\\n'.join(current_paragraph))\n",
    "    return paragraphs\n",
    "\n",
    "# Function to calculate match scores and matched keywords while excluding stopwords\n",
    "def calculate_match_scores_and_matched_keywords(keywords, text, stopwords):\n",
    "    # Convert both keywords and text to lowercase for case-insensitive matching\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Initialize a list to store match scores for each keyword\n",
    "    match_scores = []\n",
    "    \n",
    "    # Initialize a list to store matched keywords\n",
    "    matched_keywords_list = []\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        keyword_parts = keyword.lower().split()\n",
    "        total_parts = len(keyword_parts)\n",
    "        \n",
    "        # Filter out stopwords\n",
    "        keyword_parts = [part for part in keyword_parts if part not in stopwords]\n",
    "        \n",
    "        matched_parts = sum(keyword_part in text_lower for keyword_part in keyword_parts)\n",
    "        match_score = matched_parts / total_parts if total_parts > 0 else 0.0\n",
    "        match_scores.append(match_score)\n",
    "        \n",
    "        # Store the matched keyword (excluding stopwords)\n",
    "        matched_keywords = [keyword_part for keyword_part in keyword_parts if keyword_part in text_lower]\n",
    "        matched_keywords_list.append(\" \".join(matched_keywords))\n",
    "    \n",
    "    return match_scores, matched_keywords_list\n",
    "\n",
    "# Define a list of stopwords to exclude\n",
    "stopwords = [\"is\", \"and\", \"are\"]\n",
    "\n",
    "# Load the dataset with keywords (assuming it's in a separate Excel file)\n",
    "keywords_excel_path = 'path_to_keywords_excel_file.xlsx'\n",
    "keywords_data = pd.read_excel(keywords_excel_path)\n",
    "\n",
    "# Specify the columns for keywords and text\n",
    "keyword_column = 'keywords'  # Column containing keywords in the keywords Excel file\n",
    "\n",
    "# Extract text from the PDF file, including page numbers, and skip the first 5 pages and the first and last lines of each page\n",
    "pdf_path = 'path_to_your_pdf_file.pdf'\n",
    "pdf_text, page_numbers = extract_pdf_text_with_page_numbers(pdf_path, skip_first_lines=1, skip_last_lines=1, skip_first_pages=5)\n",
    "\n",
    "# Save the extracted text to a file\n",
    "with open('extracted_text.txt', 'w', encoding='utf-8') as text_file:\n",
    "    text_file.write(pdf_text)\n",
    "\n",
    "# Split the extracted text into paragraphs\n",
    "pdf_paragraphs = split_into_paragraphs(pdf_text.split('\\n'))\n",
    "\n",
    "# Initialize an empty list to store the matched data\n",
    "matched_data = []\n",
    "\n",
    "# Iterate through both datasets and match keywords with text\n",
    "for keywords_index, keywords_row in keywords_data.iterrows():\n",
    "    name = keywords_row['name']  # Assuming 'name' is a column in the keywords Excel file\n",
    "    address = keywords_row['address']  # Assuming 'address' is a column in the keywords Excel file\n",
    "    keywords = keywords_row[keyword_column].split()  # Assuming keywords are separated by space\n",
    "    \n",
    "    print(f\"Matching keywords for {name} - {address}: {keywords}\")\n",
    "    \n",
    "    for page_num, paragraph in enumerate(pdf_paragraphs, 1):\n",
    "        if isinstance(paragraph, str):  # Check if the paragraph is a string\n",
    "            # Calculate match scores and matched keywords (excluding stopwords)\n",
    "            match_scores, matched_keywords_list = calculate_match_scores_and_matched_keywords(keywords, paragraph, stopwords)\n",
    "            \n",
    "            # Calculate the match score percentage and convert it to an integer\n",
    "            match_score_percentage = int(sum(match_scores) / len(keywords) * 100)\n",
    "            \n",
    "            # Append the matched data to the list\n",
    "            matched_data.append({\n",
    "                'name': name,\n",
    "                'address': address,\n",
    "                'keywords': keywords_row[keyword_column],\n",
    "                'original_paragraph': paragraph,\n",
    "                'matched_keywords': ','.join(matched_keywords_list),\n",
    "                'match_scores': ','.join([f'{score:.2f}' for score in match_scores]),\n",
    "                'match_score %': match_score_percentage,  # Convert to int\n",
    "                'page_number': page_num  # Add the page number to the output\n",
    "            })\n",
    "\n",
    "# Create a DataFrame from the matched data\n",
    "matched_df = pd.DataFrame(matched_data)\n",
    "\n",
    "# Display the DataFrame with matched data\n",
    "print(matched_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1eff9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import PyPDF2\n",
    "\n",
    "# Function to extract text from a PDF file, split it into paragraphs, and return page numbers\n",
    "def extract_pdf_text_with_page_numbers(pdf_path, skip_first_lines=1, skip_last_lines=1, skip_first_pages=5):\n",
    "    pdf_text = ''\n",
    "    page_numbers = []\n",
    "    \n",
    "    with open(pdf_path, 'rb') as pdf_file:\n",
    "        pdf_reader = PyPDF2.PdfFileReader(pdf_file)\n",
    "        for page_num in range(skip_first_pages, pdf_reader.numPages):\n",
    "            page = pdf_reader.getPage(page_num)\n",
    "            page_text = page.extract_text()\n",
    "            page_lines = page_text.split('\\n')\n",
    "            \n",
    "            # Skip the specified number of lines from the beginning and end\n",
    "            page_lines = page_lines[skip_first_lines:-skip_last_lines]\n",
    "            \n",
    "            pdf_text += '\\n'.join(page_lines) + '\\n'  # Separate pages by newlines\n",
    "            \n",
    "            # Store page numbers for each paragraph on this page\n",
    "            page_numbers.extend([page_num] * len(page_lines))\n",
    "    \n",
    "    return pdf_text, page_numbers\n",
    "\n",
    "# Function to split lines into paragraphs\n",
    "def split_into_paragraphs(lines):\n",
    "    paragraphs = []\n",
    "    current_paragraph = []\n",
    "    for line in lines:\n",
    "        if line.strip():\n",
    "            current_paragraph.append(line)\n",
    "        else:\n",
    "            if current_paragraph:\n",
    "                paragraphs.append('\\n'.join(current_paragraph))\n",
    "                current_paragraph = []\n",
    "    if current_paragraph:\n",
    "        paragraphs.append('\\n'.join(current_paragraph))\n",
    "    return paragraphs\n",
    "\n",
    "# Replace 'path_to_your_pdf_file.pdf' with the actual path to your PDF file\n",
    "pdf_path = 'path_to_your_pdf_file.pdf'\n",
    "\n",
    "# Extract text from the PDF file, including page numbers, and skip the first 5 pages and the first and last lines of each page\n",
    "pdf_text, page_numbers = extract_pdf_text_with_page_numbers(pdf_path, skip_first_lines=1, skip_last_lines=1, skip_first_pages=5)\n",
    "\n",
    "# Split the extracted text into paragraphs\n",
    "pdf_paragraphs = split_into_paragraphs(pdf_text.split('\\n'))\n",
    "\n",
    "# Create a DataFrame to store the extracted PDF data\n",
    "pdf_data = pd.DataFrame({\n",
    "    'Original Paragraph': pdf_paragraphs,\n",
    "    'Page Number': page_numbers\n",
    "})\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "pdf_data.to_excel('extracted_pdf_data.xlsx', index=False)\n",
    "\n",
    "# Display a message indicating that the data has been saved\n",
    "print(\"Extracted PDF data has been saved to 'extracted_pdf_data.xlsx'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7113345a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2a3cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import PyPDF2\n",
    "\n",
    "# Function to split lines into paragraphs\n",
    "def split_into_paragraphs(lines):\n",
    "    paragraphs = []\n",
    "    current_paragraph = []\n",
    "    for line in lines:\n",
    "        if line.strip():\n",
    "            current_paragraph.append(line)\n",
    "        else:\n",
    "            if current_paragraph:\n",
    "                paragraphs.append('\\n'.join(current_paragraph))\n",
    "                current_paragraph = []\n",
    "    if current_paragraph:\n",
    "        paragraphs.append('\\n'.join(current_paragraph))\n",
    "    return paragraphs\n",
    "\n",
    "# Function to calculate match scores and matched keywords while excluding stopwords\n",
    "def calculate_match_scores_and_matched_keywords(keywords, text, stopwords):\n",
    "    # Convert both keywords and text to lowercase for case-insensitive matching\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Initialize a list to store match scores for each keyword\n",
    "    match_scores = []\n",
    "    \n",
    "    # Initialize a list to store matched keywords\n",
    "    matched_keywords_list = []\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        keyword_parts = keyword.lower().split()\n",
    "        total_parts = len(keyword_parts)\n",
    "        \n",
    "        # Filter out stopwords\n",
    "        keyword_parts = [part for part in keyword_parts if part not in stopwords]\n",
    "        \n",
    "        matched_parts = sum(keyword_part in text_lower for keyword_part in keyword_parts)\n",
    "        match_score = matched_parts / total_parts if total_parts > 0 else 0.0\n",
    "        match_scores.append(match_score)\n",
    "        \n",
    "        # Store the matched keyword (excluding stopwords)\n",
    "        matched_keywords = [keyword_part for keyword_part in keyword_parts if keyword_part in text_lower]\n",
    "        matched_keywords_list.append(\" \".join(matched_keywords))\n",
    "    \n",
    "    return match_scores, matched_keywords_list\n",
    "\n",
    "# Define a list of stopwords to exclude\n",
    "stopwords = [\"is\", \"and\", \"are\"]\n",
    "\n",
    "# Load the dataset with keywords (assuming it's in a separate Excel file)\n",
    "keywords_excel_path = 'path_to_keywords_excel_file.xlsx'\n",
    "keywords_data = pd.read_excel(keywords_excel_path)\n",
    "\n",
    "# Specify the columns for keywords and text\n",
    "keyword_column = 'keywords'  # Column containing keywords in the keywords Excel file\n",
    "\n",
    "# Replace 'path_to_your_pdf_file.pdf' with the actual path to your PDF file\n",
    "pdf_path = 'path_to_your_pdf_file.pdf'\n",
    "\n",
    "# Open the PDF file\n",
    "with open(pdf_path, 'rb') as pdf_file:\n",
    "    \n",
    "    # Iterate through sheets in the Excel file with multiple sheets\n",
    "    for sheet_name in pd.ExcelFile(pdf_path).sheet_names:\n",
    "        \n",
    "        # Read the data from the current sheet\n",
    "        sheet_data = pd.read_excel(pdf_path, sheet_name)\n",
    "        \n",
    "        # Extract text from the PDF file, including page numbers\n",
    "        pdf_text, page_numbers = extract_pdf_text_with_page_numbers(pdf_file, skip_first_lines=1, skip_last_lines=1, skip_first_pages=5)\n",
    "        \n",
    "        # Split the extracted text into paragraphs\n",
    "        pdf_paragraphs = split_into_paragraphs(pdf_text.split('\\n'))\n",
    "        \n",
    "        # Initialize an empty list to store the matched data\n",
    "        matched_data = []\n",
    "        \n",
    "        # Iterate through both datasets and match keywords with text\n",
    "        for keywords_index, keywords_row in keywords_data.iterrows():\n",
    "            name = keywords_row['name']  # Assuming 'name' is a column in the keywords Excel file\n",
    "            address = keywords_row['address']  # Assuming 'address' is a column in the keywords Excel file\n",
    "            keywords = keywords_row[keyword_column].split()  # Assuming keywords are separated by space\n",
    "            \n",
    "            print(f\"Matching keywords for {name} - {address} in sheet '{sheet_name}': {keywords}\")\n",
    "            \n",
    "            for page_num, paragraph in enumerate(pdf_paragraphs, 1):\n",
    "                if isinstance(paragraph, str):  # Check if the paragraph is a string\n",
    "                    # Calculate match scores and matched keywords (excluding stopwords)\n",
    "                    match_scores, matched_keywords_list = calculate_match_scores_and_matched_keywords(keywords, paragraph, stopwords)\n",
    "                    \n",
    "                    # Calculate the match score percentage and convert it to an integer\n",
    "                    match_score_percentage = int(sum(match_scores) / len(keywords) * 100)\n",
    "                    \n",
    "                    # Append the matched data to the list\n",
    "                    matched_data.append({\n",
    "                        'name': name,\n",
    "                        'address': address,\n",
    "                        'keywords': keywords_row[keyword_column],\n",
    "                        'original_paragraph': paragraph,\n",
    "                        'matched_keywords': ','.join(matched_keywords_list),\n",
    "                        'match_scores': ','.join([f'{score:.2f}' for score in match_scores]),\n",
    "                        'match_score %': match_score_percentage,  # Convert to int\n",
    "                        'page_number': page_num  # Add the page number to the output\n",
    "                    })\n",
    "        \n",
    "        # Create a DataFrame from the matched data\n",
    "        matched_df = pd.DataFrame(matched_data)\n",
    "        \n",
    "        # Save the DataFrame to an Excel file for the current sheet\n",
    "        output_file_path = f'matched_output_{sheet_name}.xlsx'\n",
    "        matched_df.to_excel(output_file_path, index=False)\n",
    "        \n",
    "        # Display a message indicating that the data has been saved\n",
    "        print(f\"Matched data for sheet '{sheet_name}' has been saved to '{output_file_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9f803e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da6e941",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to calculate match scores and matched keywords while excluding stopwords\n",
    "def calculate_match_scores_and_matched_keywords(keywords, text, stopwords):\n",
    "    # Convert both keywords and text to lowercase for case-insensitive matching\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Initialize a list to store match scores for each keyword\n",
    "    match_scores = []\n",
    "    \n",
    "    # Initialize a list to store matched keywords\n",
    "    matched_keywords_list = []\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        keyword_parts = keyword.lower().split()\n",
    "        total_parts = len(keyword_parts)\n",
    "        \n",
    "        # Filter out stopwords\n",
    "        keyword_parts = [part for part in keyword_parts if part not in stopwords]\n",
    "        \n",
    "        matched_parts = sum(keyword_part in text_lower for keyword_part in keyword_parts)\n",
    "        match_score = matched_parts / total_parts if total_parts > 0 else 0.0\n",
    "        match_scores.append(match_score)\n",
    "        \n",
    "        # Store the matched keyword (excluding stopwords)\n",
    "        matched_keywords = [keyword_part for keyword_part in keyword_parts if keyword_part in text_lower]\n",
    "        matched_keywords_list.append(\" \".join(matched_keywords))\n",
    "    \n",
    "    return match_scores, matched_keywords_list\n",
    "\n",
    "# Define a list of stopwords to exclude\n",
    "stopwords = [\"is\", \"and\", \"are\"]\n",
    "\n",
    "# Load the dataset with keywords (assuming it's in a separate Excel file)\n",
    "keywords_excel_path = 'path_to_keywords_excel_file.xlsx'\n",
    "keywords_data = pd.read_excel(keywords_excel_path)\n",
    "\n",
    "# Replace 'path_to_your_excel_file.xlsx' with the actual path to your Excel file with multiple sheets\n",
    "excel_file_path = 'path_to_your_excel_file.xlsx'\n",
    "\n",
    "# Iterate through sheets in the Excel file with multiple sheets\n",
    "for sheet_name in pd.ExcelFile(excel_file_path).sheet_names:\n",
    "    \n",
    "    # Read the data from the current sheet\n",
    "    sheet_data = pd.read_excel(excel_file_path, sheet_name)\n",
    "    \n",
    "    # Initialize an empty list to store the matched data\n",
    "    matched_data = []\n",
    "    \n",
    "    # Iterate through both datasets and match keywords with text\n",
    "    for keywords_index, keywords_row in keywords_data.iterrows():\n",
    "        name = keywords_row['name']  # Assuming 'name' is a column in the keywords Excel file\n",
    "        address = keywords_row['address']  # Assuming 'address' is a column in the keywords Excel file\n",
    "        keywords = keywords_row['keywords'].split()  # Assuming keywords are separated by space\n",
    "        \n",
    "        print(f\"Matching keywords for {name} - {address} in sheet '{sheet_name}': {keywords}\")\n",
    "        \n",
    "        for row_index, row in sheet_data.iterrows():\n",
    "            text_column = 'text_column'  # Replace with the actual column name containing text in your Excel file\n",
    "            text = row[text_column] if text_column in row else ''\n",
    "            \n",
    "            # Calculate match scores and matched keywords (excluding stopwords)\n",
    "            match_scores, matched_keywords_list = calculate_match_scores_and_matched_keywords(keywords, text, stopwords)\n",
    "            \n",
    "            # Calculate the match score percentage and convert it to an integer\n",
    "            match_score_percentage = int(sum(match_scores) / len(keywords) * 100)\n",
    "            \n",
    "            # Append the matched data to the list\n",
    "            matched_data.append({\n",
    "                'name': name,\n",
    "                'address': address,\n",
    "                'keywords': keywords_row['keywords'],\n",
    "                'matched_keywords': ','.join(matched_keywords_list),\n",
    "                'match_scores': ','.join([f'{score:.2f}' for score in match_scores]),\n",
    "                'match_score %': match_score_percentage,  # Convert to int\n",
    "            })\n",
    "    \n",
    "    # Create a DataFrame from the matched data\n",
    "    matched_df = pd.DataFrame(matched_data)\n",
    "    \n",
    "    # Save the DataFrame to an Excel file for the current sheet\n",
    "    output_file_path = f'matched_output_{sheet_name}.xlsx'\n",
    "    matched_df.to_excel(output_file_path, index=False)\n",
    "    \n",
    "    # Display a message indicating that the data has been saved\n",
    "    print(f\"Matched data for sheet '{sheet_name}' has been saved to '{output_file_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249c1c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to calculate match scores and matched keywords while excluding stopwords\n",
    "def calculate_match_scores_and_matched_keywords(keywords, text, stopwords):\n",
    "    # Convert both keywords and text to lowercase for case-insensitive matching\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Initialize a list to store match scores for each keyword\n",
    "    match_scores = []\n",
    "    \n",
    "    # Initialize a list to store matched keywords\n",
    "    matched_keywords_list = []\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        keyword_parts = keyword.lower().split()\n",
    "        total_parts = len(keyword_parts)\n",
    "        \n",
    "        # Filter out stopwords\n",
    "        keyword_parts = [part for part in keyword_parts if part not in stopwords]\n",
    "        \n",
    "        matched_parts = sum(keyword_part in text_lower for keyword_part in keyword_parts)\n",
    "        match_score = matched_parts / total_parts if total_parts > 0 else 0.0\n",
    "        match_scores.append(match_score)\n",
    "        \n",
    "        # Store the matched keyword (excluding stopwords)\n",
    "        matched_keywords = [keyword_part for keyword_part in keyword_parts if keyword_part in text_lower]\n",
    "        matched_keywords_list.append(\" \".join(matched_keywords))\n",
    "    \n",
    "    return match_scores, matched_keywords_list\n",
    "\n",
    "# Define a list of stopwords to exclude\n",
    "stopwords = [\"is\", \"and\", \"are\"]\n",
    "\n",
    "# Load the dataset with keywords (assuming it's in a separate Excel file)\n",
    "keywords_excel_path = 'path_to_keywords_excel_file.xlsx'\n",
    "keywords_data = pd.read_excel(keywords_excel_path)\n",
    "\n",
    "# Replace 'path_to_your_excel_file.xlsx' with the actual path to your Excel file with multiple sheets\n",
    "excel_file_path = 'path_to_your_excel_file.xlsx'\n",
    "\n",
    "# Iterate through sheets in the Excel file with multiple sheets\n",
    "for sheet_name in pd.ExcelFile(excel_file_path).sheet_names:\n",
    "    \n",
    "    # Read the data from the current sheet\n",
    "    sheet_data = pd.read_excel(excel_file_path, sheet_name)\n",
    "    \n",
    "    # Initialize an empty list to store the matched data\n",
    "    matched_data = []\n",
    "    \n",
    "    # Iterate through both datasets and match keywords with text\n",
    "    for keywords_index, keywords_row in keywords_data.iterrows():\n",
    "        name = keywords_row['name']  # Assuming 'name' is a column in the keywords Excel file\n",
    "        address = keywords_row['address']  # Assuming 'address' is a column in the keywords Excel file\n",
    "        keywords = keywords_row['keywords'].split()  # Assuming keywords are separated by space\n",
    "        \n",
    "        print(f\"Matching keywords for {name} - {address} in sheet '{sheet_name}': {keywords}\")\n",
    "        \n",
    "        for row_index, row in sheet_data.iterrows():\n",
    "            text_column = 'text_column'  # Replace with the actual column name containing text in your Excel file\n",
    "            text = row[text_column] if text_column in row else ''\n",
    "            \n",
    "            # Calculate match scores and matched keywords (excluding stopwords)\n",
    "            match_scores, matched_keywords_list = calculate_match_scores_and_matched_keywords(keywords, text, stopwords)\n",
    "            \n",
    "            # Calculate the match score percentage and convert it to an integer\n",
    "            match_score_percentage = int(sum(match_scores) / len(keywords) * 100)\n",
    "            \n",
    "            # Append the matched data to the list\n",
    "            matched_data.append({\n",
    "                'name': name,\n",
    "                'address': address,\n",
    "                'keywords': keywords_row['keywords'],\n",
    "                'matched_keywords': ','.join(matched_keywords_list),\n",
    "                'match_scores': ','.join([f'{score:.2f}' for score in match_scores]),\n",
    "                'match_score %': match_score_percentage,  # Convert to int\n",
    "            })\n",
    "    \n",
    "    # Create a DataFrame from the matched data\n",
    "    matched_df = pd.DataFrame(matched_data)\n",
    "    \n",
    "    # Save the DataFrame to an Excel file for the current sheet\n",
    "    output_file_path = f'matched_output_{sheet_name}.xlsx'\n",
    "    matched_df.to_excel(output_file_path, index=False)\n",
    "    \n",
    "    # Display a message indicating that the data has been saved\n",
    "    print(f\"Matched data for sheet '{sheet_name}' has been saved to '{output_file_path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cc11a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3764a6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to calculate match scores and matched keywords while excluding stopwords\n",
    "def calculate_match_scores_and_matched_keywords(keywords, text, stopwords):\n",
    "    if not isinstance(text, str):\n",
    "        return [], []  # Return empty lists if the text is not a string\n",
    "    \n",
    "    # Convert both keywords and text to lowercase for case-insensitive matching\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Initialize a list to store match scores for each keyword\n",
    "    match_scores = []\n",
    "    \n",
    "    # Initialize a list to store matched keywords\n",
    "    matched_keywords_list = []\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        keyword_parts = keyword.lower().split()\n",
    "        total_parts = len(keyword_parts)\n",
    "        \n",
    "        # Filter out stopwords\n",
    "        keyword_parts = [part for part in keyword_parts if part not in stopwords]\n",
    "        \n",
    "        matched_parts = sum(keyword_part in text_lower for keyword_part in keyword_parts)\n",
    "        match_score = matched_parts / total_parts if total_parts > 0 else 0.0\n",
    "        match_scores.append(match_score)\n",
    "        \n",
    "        # Store the matched keyword (excluding stopwords)\n",
    "        matched_keywords = [keyword_part for keyword_part in keyword_parts if keyword_part in text_lower]\n",
    "        matched_keywords_list.append(\" \".join(matched_keywords))\n",
    "    \n",
    "    return match_scores, matched_keywords_list\n",
    "\n",
    "# Define a list of stopwords to exclude\n",
    "stopwords = [\"is\", \"and\", \"are\"]\n",
    "\n",
    "# Load the dataset with keywords (assuming it's in a separate Excel file)\n",
    "keywords_excel_path = 'path_to_keywords_excel_file.xlsx'\n",
    "keywords_data = pd.read_excel(keywords_excel_path)\n",
    "\n",
    "# Replace 'path_to_your_excel_file.xlsx' with the actual path to your Excel file with multiple sheets\n",
    "excel_file_path = 'path_to_your_excel_file.xlsx'\n",
    "\n",
    "# Create an Excel writer to save the matched data for each sheet in a separate sheet\n",
    "output_excel_path = 'matched_output.xlsx'\n",
    "with pd.ExcelWriter(output_excel_path, engine='xlsxwriter') as writer:\n",
    "    # Iterate through sheets in the Excel file with multiple sheets\n",
    "    for sheet_name in pd.ExcelFile(excel_file_path).sheet_names:\n",
    "        # Read the data from the current sheet\n",
    "        sheet_data = pd.read_excel(excel_file_path, sheet_name)\n",
    "        \n",
    "        # Initialize an empty list to store the matched data\n",
    "        matched_data = []\n",
    "        \n",
    "        # Iterate through both datasets and match keywords with text\n",
    "        for keywords_index, keywords_row in keywords_data.iterrows():\n",
    "            name = keywords_row['name']  # Assuming 'name' is a column in the keywords Excel file\n",
    "            address = keywords_row['address']  # Assuming 'address' is a column in the keywords Excel file\n",
    "            keywords = keywords_row['keywords'].split()  # Assuming keywords are separated by space\n",
    "            \n",
    "            print(f\"Matching keywords for {name} - {address} in sheet '{sheet_name}': {keywords}\")\n",
    "            \n",
    "            for row_index, row in sheet_data.iterrows():\n",
    "                text_column = 'text_column'  # Replace with the actual column name containing text in your Excel file\n",
    "                text = row[text_column]\n",
    "                \n",
    "                # Calculate match scores and matched keywords (excluding stopwords)\n",
    "                match_scores, matched_keywords_list = calculate_match_scores_and_matched_keywords(keywords, text, stopwords)\n",
    "                \n",
    "                # Calculate the match score percentage and convert it to an integer\n",
    "                match_score_percentage = int(sum(match_scores) / len(keywords) * 100)\n",
    "                \n",
    "                # Append the matched data to the list\n",
    "                matched_data.append({\n",
    "                    'name': name,\n",
    "                    'address': address,\n",
    "                    'keywords': keywords_row['keywords'],\n",
    "                    'original_text': text,\n",
    "                    'matched_keywords': ','.join(matched_keywords_list),\n",
    "                    'match_scores': ','.join([f'{score:.2f}' for score in match_scores]),\n",
    "                    'match_score %': match_score_percentage,  # Convert to int\n",
    "                })\n",
    "        \n",
    "        # Create a DataFrame from the matched data\n",
    "        matched_df = pd.DataFrame(matched_data)\n",
    "        \n",
    "        # Save the DataFrame to an Excel sheet for the current sheet\n",
    "        matched_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "        \n",
    "        # Display a message indicating that the data has been saved\n",
    "        print(f\"Matched data for sheet '{sheet_name}' has been saved to '{output_excel_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9f14f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to calculate match scores and matched keywords while excluding stopwords\n",
    "def calculate_match_scores_and_matched_keywords(keywords, text, stopwords):\n",
    "    if not isinstance(text, str):\n",
    "        return [], []  # Return empty lists if the text is not a string\n",
    "    \n",
    "    # Convert both keywords and text to lowercase for case-insensitive matching\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Initialize a list to store match scores for each keyword\n",
    "    match_scores = []\n",
    "    \n",
    "    # Initialize a list to store matched keywords\n",
    "    matched_keywords_list = []\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        keyword_parts = keyword.lower().split()\n",
    "        total_parts = len(keyword_parts)\n",
    "        \n",
    "        # Filter out stopwords\n",
    "        keyword_parts = [part for part in keyword_parts if part not in stopwords]\n",
    "        \n",
    "        matched_parts = sum(keyword_part in text_lower for keyword_part in keyword_parts)\n",
    "        match_score = matched_parts / total_parts if total_parts > 0 else 0.0\n",
    "        match_scores.append(match_score)\n",
    "        \n",
    "        # Store the matched keyword (excluding stopwords)\n",
    "        matched_keywords = [keyword_part for keyword_part in keyword_parts if keyword_part in text_lower]\n",
    "        matched_keywords_list.append(\" \".join(matched_keywords))\n",
    "    \n",
    "    return match_scores, matched_keywords_list\n",
    "\n",
    "# Define a list of stopwords to exclude\n",
    "stopwords = [\"is\", \"and\", \"are\"]\n",
    "\n",
    "# Load the dataset with keywords (assuming it's in a separate Excel file)\n",
    "keywords_excel_path = 'path_to_keywords_excel_file.xlsx'\n",
    "keywords_data = pd.read_excel(keywords_excel_path)\n",
    "\n",
    "# Replace 'path_to_your_excel_file.xlsx' with the actual path to your Excel file with multiple sheets\n",
    "excel_file_path = 'path_to_your_excel_file.xlsx'\n",
    "\n",
    "# Create an Excel writer to save the matched data for each sheet in a separate sheet\n",
    "output_excel_path = 'matched_output.xlsx'\n",
    "with pd.ExcelWriter(output_excel_path, engine='xlsxwriter') as writer:\n",
    "    # Iterate through sheets in the Excel file with multiple sheets\n",
    "    for sheet_name in pd.ExcelFile(excel_file_path).sheet_names:\n",
    "        # Read the data from the current sheet\n",
    "        sheet_data = pd.read_excel(excel_file_path, sheet_name)\n",
    "        \n",
    "        # Initialize an empty list to store the matched data\n",
    "        matched_data = []\n",
    "        \n",
    "        # Iterate through both datasets and match keywords with text\n",
    "        for keywords_index, keywords_row in keywords_data.iterrows():\n",
    "            name = keywords_row['name']  # Assuming 'name' is a column in the keywords Excel file\n",
    "            address = keywords_row['address']  # Assuming 'address' is a column in the keywords Excel file\n",
    "            keywords = keywords_row['keywords'].split()  # Assuming keywords are separated by space\n",
    "            \n",
    "            print(f\"Matching keywords for {name} - {address} in sheet '{sheet_name}': {keywords}\")\n",
    "            \n",
    "            for row_index, row in sheet_data.iterrows():\n",
    "                text_column = 'text_column'  # Replace with the actual column name containing text in your Excel file\n",
    "                text = row[text_column]\n",
    "                \n",
    "                # Calculate match scores and matched keywords (excluding stopwords)\n",
    "                match_scores, matched_keywords_list = calculate_match_scores_and_matched_keywords(keywords, text, stopwords)\n",
    "                \n",
    "                # Calculate the match score percentage and convert it to an integer\n",
    "                match_score_percentage = int(sum(match_scores) / len(keywords) * 100)\n",
    "                \n",
    "                # Append the matched data to the list\n",
    "                matched_data.append({\n",
    "                    'name': name,\n",
    "                    'address': address,\n",
    "                    'keywords': keywords_row['keywords'],\n",
    "                    'original_text': text,\n",
    "                    'matched_keywords': ','.join(matched_keywords_list),\n",
    "                    'match_scores': ','.join([f'{score:.2f}' for score in match_scores]),\n",
    "                    'match_score %': match_score_percentage,  # Convert to int\n",
    "                })\n",
    "        \n",
    "        # Create a DataFrame from the matched data\n",
    "        matched_df = pd.DataFrame(matched_data)\n",
    "        \n",
    "        # Save the DataFrame to an Excel sheet for the current sheet\n",
    "        matched_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "        \n",
    "        # Display a message indicating that the data has been saved\n",
    "        print(f\"Matched data for sheet '{sheet_name}' has been saved to '{output_excel_path}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

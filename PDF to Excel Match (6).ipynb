{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac3df8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import PyPDF2\n",
    "import re\n",
    "\n",
    "# Function to extract text from a PDF file and split it into paragraphs\n",
    "def extract_pdf_text(pdf_path, start_page=6):\n",
    "    pdf_text = ''\n",
    "    with open(pdf_path, 'rb') as pdf_file:\n",
    "        pdf_reader = PyPDF2.PdfFileReader(pdf_file)\n",
    "        num_pages = pdf_reader.numPages\n",
    "        \n",
    "        for page_num in range(start_page - 1, num_pages):\n",
    "            page = pdf_reader.getPage(page_num)\n",
    "            page_text = page.extract_text()\n",
    "            pdf_text += page_text + '\\n'  # Separate pages by newlines\n",
    "    return pdf_text\n",
    "\n",
    "# Function to split text into paragraphs\n",
    "def split_into_paragraphs(text):\n",
    "    return re.split(r'\\n\\s*\\n', text)\n",
    "\n",
    "# Function to calculate match scores and matched keywords while excluding stopwords\n",
    "def calculate_match_scores_and_matched_keywords(keywords, text, stopwords):\n",
    "    # Convert both keywords and text to lowercase for case-insensitive matching\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Initialize a list to store match scores for each keyword\n",
    "    match_scores = []\n",
    "    \n",
    "    # Initialize a list to store matched keywords\n",
    "    matched_keywords_list = []\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        keyword_parts = keyword.lower().split()\n",
    "        total_parts = len(keyword_parts)\n",
    "        \n",
    "        # Filter out stopwords\n",
    "        keyword_parts = [part for part in keyword_parts if part not in stopwords]\n",
    "        \n",
    "        matched_parts = sum(keyword_part in text_lower for keyword_part in keyword_parts)\n",
    "        match_score = matched_parts / total_parts if total_parts > 0 else 0.0\n",
    "        match_scores.append(match_score)\n",
    "        \n",
    "        # Store the matched keyword (excluding stopwords)\n",
    "        matched_keywords = [keyword_part for keyword_part in keyword_parts if keyword_part in text_lower]\n",
    "        matched_keywords_list.append(\" \".join(matched_keywords))\n",
    "    \n",
    "    return match_scores, matched_keywords_list\n",
    "\n",
    "# Define a list of stopwords to exclude\n",
    "stopwords = [\"is\", \"and\", \"are\"]\n",
    "\n",
    "# Load the dataset with keywords (assuming it's in a separate Excel file)\n",
    "keywords_excel_path = 'path_to_keywords_excel_file.xlsx'\n",
    "keywords_data = pd.read_excel(keywords_excel_path)\n",
    "\n",
    "# Specify the columns for keywords and text\n",
    "keyword_column = 'keywords'  # Column containing keywords in the keywords Excel file\n",
    "\n",
    "# Extract text from the PDF file, starting from the 6th page\n",
    "pdf_path = 'path_to_your_pdf_file.pdf'\n",
    "pdf_text = extract_pdf_text(pdf_path)\n",
    "\n",
    "# Split the extracted text into paragraphs\n",
    "pdf_paragraphs = split_into_paragraphs(pdf_text)\n",
    "\n",
    "# Initialize an empty list to store the matched data\n",
    "matched_data = []\n",
    "\n",
    "# Iterate through all paragraphs and all keywords\n",
    "for paragraph in pdf_paragraphs:\n",
    "    for keywords_index, keywords_row in keywords_data.iterrows():\n",
    "        name = keywords_row['name']  # Assuming 'name' is a column in the keywords Excel file\n",
    "        address = keywords_row['address']  # Assuming 'address' is a column in the keywords Excel file\n",
    "        keywords = keywords_row[keyword_column].split()  # Assuming keywords are separated by space\n",
    "    \n",
    "        # Calculate match scores and matched keywords (excluding stopwords)\n",
    "        match_scores, matched_keywords_list = calculate_match_scores_and_matched_keywords(keywords, paragraph, stopwords)\n",
    "        \n",
    "        # Calculate the match score %\n",
    "        match_score_percentage = sum(match_scores) / len(keywords)\n",
    "        \n",
    "        # Append the matched data to the list\n",
    "        matched_data.append({\n",
    "            'name': name,\n",
    "            'address': address,\n",
    "            'keywords': keywords_row[keyword_column],\n",
    "            'original_paragraph': paragraph,\n",
    "            'matched_keywords': ','.join(matched_keywords_list),\n",
    "            'match_scores': ','.join([f'{score:.2f}' for score in match_scores]),\n",
    "            'match_score %': f'{match_score_percentage * 100:.2f}%'\n",
    "        })\n",
    "\n",
    "# Create a DataFrame from the matched data\n",
    "matched_df = pd.DataFrame(matched_data)\n",
    "\n",
    "# Display the DataFrame with matched data\n",
    "print(matched_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b890c65",
   "metadata": {},
   "source": [
    "### Excluding headers and footers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb53cd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pdfplumber\n",
    "import re\n",
    "\n",
    "# Function to extract text from a PDF file and split it into paragraphs\n",
    "def extract_pdf_text(pdf_path, start_page=6):\n",
    "    pdf_text = ''\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        num_pages = len(pdf.pages)\n",
    "\n",
    "        for page_num in range(start_page - 1, num_pages):\n",
    "            page = pdf.pages[page_num]\n",
    "\n",
    "            # Specify regions to exclude (e.g., headers and footers)\n",
    "            exclude_regions = [\n",
    "                page.crop((0, 0, page.width, 50)),  # Adjust the height as needed\n",
    "                page.crop((0, page.height - 50, page.width, page.height)),  # Adjust the height as needed\n",
    "            ]\n",
    "\n",
    "            page_text = page.extract_text(x_tolerance=2, y_tolerance=2, boxes_exclude=exclude_regions)\n",
    "            pdf_text += page_text + '\\n'  # Separate pages by newlines\n",
    "\n",
    "    return pdf_text\n",
    "\n",
    "# Function to split text into paragraphs\n",
    "def split_into_paragraphs(text):\n",
    "    return re.split(r'\\n\\s*\\n', text)\n",
    "\n",
    "# Function to calculate match scores and matched keywords while excluding stopwords\n",
    "def calculate_match_scores_and_matched_keywords(keywords, text, stopwords):\n",
    "    # Convert both keywords and text to lowercase for case-insensitive matching\n",
    "    text_lower = text.lower()\n",
    "\n",
    "    # Initialize a list to store match scores for each keyword\n",
    "    match_scores = []\n",
    "\n",
    "    # Initialize a list to store matched keywords\n",
    "    matched_keywords_list = []\n",
    "\n",
    "    for keyword in keywords:\n",
    "        keyword_parts = keyword.lower().split()\n",
    "        total parts = len(keyword_parts)\n",
    "\n",
    "        # Filter out stopwords\n",
    "        keyword_parts = [part for part in keyword_parts if part not in stopwords]\n",
    "\n",
    "        matched_parts = sum(keyword_part in text_lower for keyword_part in keyword_parts)\n",
    "        match_score = matched_parts / total_parts if total_parts > 0 else 0.0\n",
    "        match_scores.append(match_score)\n",
    "\n",
    "        # Store the matched keyword (excluding stopwords)\n",
    "        matched_keywords = [keyword_part for keyword_part in keyword_parts if keyword_part in text_lower]\n",
    "        matched_keywords_list.append(\" \".join(matched_keywords))\n",
    "\n",
    "    return match_scores, matched_keywords_list\n",
    "\n",
    "# Define a list of stopwords to exclude\n",
    "stopwords = [\"is\", \"and\", \"are\"]\n",
    "\n",
    "# Load the dataset with keywords (assuming it's in a separate Excel file)\n",
    "keywords_excel_path = 'path_to_keywords_excel_file.xlsx'\n",
    "keywords_data = pd.read_excel(keywords_excel_path)\n",
    "\n",
    "# Specify the columns for keywords and text\n",
    "keyword_column = 'keywords'  # Column containing keywords in the keywords Excel file\n",
    "\n",
    "# Extract text from the PDF file, starting from the 6th page\n",
    "pdf_path = 'path_to_your_pdf_file.pdf'\n",
    "pdf_text = extract_pdf_text(pdf_path)\n",
    "\n",
    "# Split the extracted text into paragraphs\n",
    "pdf_paragraphs = split_into_paragraphs(pdf_text)\n",
    "\n",
    "# Initialize an empty list to store the matched data\n",
    "matched_data = []\n",
    "\n",
    "# Iterate through all paragraphs and all keywords\n",
    "for paragraph in pdf_paragraphs:\n",
    "    for keywords_index, keywords_row in keywords_data.iterrows():\n",
    "        name = keywords_row['name']  # Assuming 'name' is a column in the keywords Excel file\n",
    "        address = keywords_row['address']  # Assuming 'address' is a column in the keywords Excel file\n",
    "        keywords = keywords_row[keyword_column].split()  # Assuming keywords are separated by space\n",
    "\n",
    "        # Calculate match scores and matched keywords (excluding stopwords)\n",
    "        match_scores, matched_keywords_list = calculate_match_scores_and_matched_keywords(keywords, paragraph, stopwords)\n",
    "\n",
    "        # Calculate the match score %\n",
    "        match_score_percentage = sum(match_scores) / len(keywords)\n",
    "\n",
    "        # Append the matched data to the list\n",
    "        matched_data.append({\n",
    "            'name': name,\n",
    "            'address': address,\n",
    "            'keywords': keywords_row[keyword_column],\n",
    "            'original_paragraph': paragraph,\n",
    "            'matched_keywords': ','.join(matched_keywords_list),\n",
    "            'match_scores': ','.join([f'{score:.2f}' for score in match_scores]),\n",
    "            'match_score %': f'{match_score_percentage * 100:.2f}%'\n",
    "        })\n",
    "\n",
    "# Create a DataFrame from the matched data\n",
    "matched_df = pd.DataFrame(matched_data)\n",
    "\n",
    "# Display the DataFrame with matched data\n",
    "print(matched_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c69d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "# Function to extract text from a PDF file while excluding header and footer\n",
    "def extract_pdf_text(pdf_path):\n",
    "    pdf_text = ''\n",
    "    doc = fitz.open(pdf_path)\n",
    "\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc.load_page(page_num)\n",
    "        # Define the page area to exclude (e.g., header and footer coordinates)\n",
    "        exclude_area = fitz.Rect(0, 0, page.rect.width, 50)  # Excluding top 50 pixels\n",
    "\n",
    "        # Get text in the page, excluding the defined area\n",
    "        page_text = page.get_text(\"text\", clip=exclude_area)\n",
    "\n",
    "        pdf_text += page_text\n",
    "\n",
    "    return pdf_text\n",
    "\n",
    "# Function to calculate match scores and matched keywords while excluding stopwords\n",
    "def calculate_match_scores_and_matched_keywords(keywords, text, stopwords):\n",
    "    # Convert both keywords and text to lowercase for case-insensitive matching\n",
    "    text_lower = text.lower()\n",
    "\n",
    "    # Initialize a list to store match scores for each keyword\n",
    "    match_scores = []\n",
    "\n",
    "    # Initialize a list to store matched keywords\n",
    "    matched_keywords_list = []\n",
    "\n",
    "    for keyword in keywords:\n",
    "        keyword_parts = keyword.lower().split()\n",
    "        total_parts = len(keyword_parts\n",
    "\n",
    "        # Filter out stopwords\n",
    "        keyword_parts = [part for part in keyword_parts if part not in stopwords]\n",
    "\n",
    "        matched_parts = sum(keyword_part in text_lower for keyword_part in keyword_parts)\n",
    "        match_score = matched_parts / total_parts if total_parts > 0 else 0.0\n",
    "        match_scores.append(match_score)\n",
    "\n",
    "        # Store the matched keyword (excluding stopwords)\n",
    "        matched_keywords = [keyword_part for keyword_part in keyword_parts if keyword_part in text_lower]\n",
    "        matched_keywords_list.append(\" \".join(matched_keywords))\n",
    "\n",
    "    return match_scores, matched_keywords_list\n",
    "\n",
    "# Define a list of stopwords to exclude\n",
    "stopwords = [\"is\", \"and\", \"are\"]\n",
    "\n",
    "# Load the dataset with keywords (assuming it's in a separate Excel file)\n",
    "keywords_excel_path = 'path_to_keywords_excel_file.xlsx'\n",
    "keywords_data = pd.read_excel(keywords_excel_path)\n",
    "\n",
    "# Specify the columns for keywords and text\n",
    "keyword_column = 'keywords'  # Column containing keywords in the keywords Excel file\n",
    "\n",
    "# Extract text from the PDF file (excluding header and footer)\n",
    "pdf_path = 'path_to_your_pdf_file.pdf'\n",
    "pdf_text = extract_pdf_text(pdf_path)\n",
    "\n",
    "# Initialize an empty list to store the matched data\n",
    "matched_data = []\n",
    "\n",
    "# Iterate through both datasets and match keywords with text\n",
    "for keywords_index, keywords_row in keywords_data.iterrows():\n",
    "    name = keywords_row['name']  # Assuming 'name' is a column in the keywords Excel file\n",
    "    address = keywords_row['address']  # Assuming 'address' is a column in the keywords Excel file\n",
    "    keywords = keywords_row[keyword_column].split()  # Assuming keywords are separated by space\n",
    "\n",
    "    print(f\"Matching keywords for {name} - {address}: {keywords}\")\n",
    "\n",
    "    # Split the extracted text into paragraphs by newline while preserving sequence numbers\n",
    "    paragraphs = [p.strip() for p in pdf_text.split('\\n')]\n",
    "\n",
    "    for paragraph in paragraphs:\n",
    "        # Calculate match scores and matched keywords (excluding stopwords)\n",
    "        match_scores, matched_keywords_list = calculate_match_scores_and_matched_keywords(keywords, paragraph, stopwords)\n",
    "\n",
    "        # Calculate the match score %\n",
    "        match_score_percentage = sum(match_scores) / len(keywords)\n",
    "\n",
    "        # Append the matched data to the list\n",
    "        matched_data.append({\n",
    "            'name': name,\n",
    "            'address': address,\n",
    "            'keywords': keywords_row[keyword_column],\n",
    "            'original_paragraph': paragraph,\n",
    "            'matched_keywords': ','.join(matched_keywords_list),\n",
    "            'match_scores': ','.join([f'{score:.2f}' for score in match_scores]),\n",
    "            'match_score %': f'{match_score_percentage * 100:.2f}%'\n",
    "        })\n",
    "\n",
    "# Create a DataFrame from the matched data\n",
    "matched_df = pd.DataFrame(matched_data)\n",
    "\n",
    "# Display the DataFrame with matched data\n",
    "print(matched_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216880a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "# Function to extract text from a PDF file while excluding header and footer\n",
    "def extract_pdf_text(pdf_path):\n",
    "    pdf_text = ''\n",
    "    doc = fitz.open(pdf_path)\n",
    "\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc.load_page(page_num)\n",
    "\n",
    "        # Define the page height and width\n",
    "        page_height = page.rect.height\n",
    "        page_width = page.rect.width\n",
    "\n",
    "        # Define the regions to exclude (you need to specify the coordinates)\n",
    "        top_margin = 50  # Exclude top 50 pixels as header\n",
    "        bottom_margin = 50  # Exclude bottom 50 pixels as footer\n",
    "\n",
    "        # Get text in the page, excluding the header and footer\n",
    "        page_text = page.get_text(\"text\", clip=(0, top_margin, page_width, page_height - bottom_margin))\n",
    "\n",
    "        pdf_text += page_text\n",
    "\n",
    "    return pdf_text\n",
    "\n",
    "# Rest of the code (matching keywords) remains the same\n",
    "\n",
    "# Define a list of stopwords to exclude\n",
    "stopwords = [\"is\", \"and\", \"are\"]\n",
    "\n",
    "# Load the dataset with keywords (assuming it's in a separate Excel file)\n",
    "keywords_excel_path = 'path_to_keywords_excel_file.xlsx'\n",
    "keywords_data = pd.read_excel(keywords_excel_path)\n",
    "\n",
    "# Specify the columns for keywords and text\n",
    "keyword_column = 'keywords'  # Column containing keywords in the keywords Excel file\n",
    "\n",
    "# Extract text from the PDF file (excluding header and footer)\n",
    "pdf_path = 'path_to_your_pdf_file.pdf'\n",
    "pdf_text = extract_pdf_text(pdf_path)\n",
    "\n",
    "# Initialize an empty list to store the matched data\n",
    "matched_data = []\n",
    "\n",
    "# Iterate through both datasets and match keywords with text\n",
    "for keywords_index, keywords_row in keywords_data.iterrows():\n",
    "    name = keywords_row['name']  # Assuming 'name' is a column in the keywords Excel file\n",
    "    address = keywords_row['address']  # Assuming 'address' is a column in the keywords Excel file\n",
    "    keywords = keywords_row[keyword_column].split()  # Assuming keywords are separated by space\n",
    "\n",
    "    print(f\"Matching keywords for {name} - {address}: {keywords}\")\n",
    "\n",
    "    # Split the extracted text into paragraphs by newline while preserving sequence numbers\n",
    "    paragraphs = [p.strip() for p in pdf_text.split('\\n')]\n",
    "\n",
    "    for paragraph in paragraphs:\n",
    "        # Calculate match scores and matched keywords (excluding stopwords)\n",
    "        match_scores, matched_keywords_list = calculate_match_scores_and_matched_keywords(keywords, paragraph, stopwords)\n",
    "\n",
    "        # Calculate the match score %\n",
    "        match_score_percentage = sum(match_scores) / len(keywords)\n",
    "\n",
    "        # Append the matched data to the list\n",
    "        matched_data.append({\n",
    "            'name': name,\n",
    "            'address': address,\n",
    "            'keywords': keywords_row[keyword_column],\n",
    "            'original_paragraph': paragraph,\n",
    "            'matched_keywords': ','.join(matched_keywords_list),\n",
    "            'match_scores': ','.join([f'{score:.2f}' for score in match_scores]),\n",
    "            'match_score %': f'{match_score_percentage * 100:.2f}%'\n",
    "        })\n",
    "\n",
    "# Create a DataFrame from the matched data\n",
    "matched_df = pd.DataFrame(matched_data)\n",
    "\n",
    "# Display the DataFrame with matched data\n",
    "print(matched_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e6c9bd",
   "metadata": {},
   "source": [
    "## To skip first line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913060af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import PyPDF2\n",
    "import re\n",
    "\n",
    "# Function to extract text from a PDF file and split it into paragraphs\n",
    "def extract_pdf_text(pdf_path, skip_first_line=True):\n",
    "    pdf_text = ''\n",
    "    with open(pdf_path, 'rb') as pdf_file:\n",
    "        pdf_reader = PyPDF2.PdfFileReader(pdf_file)\n",
    "        for page_num in range(pdf_reader.numPages):\n",
    "            page = pdf_reader.getPage(page_num)\n",
    "            page_text = page.extract_text()\n",
    "            if skip_first_line:\n",
    "                # Split the text into lines and exclude the first line\n",
    "                lines = page_text.split('\\n')\n",
    "                page_text = '\\n'.join(lines[1:])\n",
    "            pdf_text += page_text + '\\n'  # Separate pages by newlines\n",
    "    return pdf_text\n",
    "\n",
    "# Function to split text into paragraphs\n",
    "def split_into_paragraphs(text):\n",
    "    return re.split(r'\\n\\s*\\n', text)\n",
    "\n",
    "# Function to calculate match scores and matched keywords while excluding stopwords\n",
    "def calculate_match_scores_and_matched_keywords(keywords, text, stopwords):\n",
    "    # Convert both keywords and text to lowercase for case-insensitive matching\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Initialize a list to store match scores for each keyword\n",
    "    match_scores = []\n",
    "    \n",
    "    # Initialize a list to store matched keywords\n",
    "    matched_keywords_list = []\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        keyword_parts = keyword.lower().split()\n",
    "        total_parts = len(keyword_parts)\n",
    "        \n",
    "        # Filter out stopwords\n",
    "        keyword_parts = [part for part in keyword_parts if part not in stopwords]\n",
    "        \n",
    "        matched_parts = sum(keyword_part in text_lower for keyword_part in keyword_parts)\n",
    "        match_score = matched_parts / total_parts if total_parts > 0 else 0.0\n",
    "        match_scores.append(match_score)\n",
    "        \n",
    "        # Store the matched keyword (excluding stopwords)\n",
    "        matched_keywords = [keyword_part for keyword_part in keyword_parts if keyword_part in text_lower]\n",
    "        matched_keywords_list.append(\" \".join(matched_keywords))\n",
    "    \n",
    "    return match_scores, matched_keywords_list\n",
    "\n",
    "# Define a list of stopwords to exclude\n",
    "stopwords = [\"is\", \"and\", \"are\"]\n",
    "\n",
    "# Load the dataset with keywords (assuming it's in a separate Excel file)\n",
    "keywords_excel_path = 'path_to_keywords_excel_file.xlsx'\n",
    "keywords_data = pd.read_excel(keywords_excel_path)\n",
    "\n",
    "# Specify the columns for keywords and text\n",
    "keyword_column = 'keywords'  # Column containing keywords in the keywords Excel file\n",
    "\n",
    "# Extract text from the PDF file, skipping the first line on each page\n",
    "pdf_path = 'path_to_your_pdf_file.pdf'\n",
    "pdf_text = extract_pdf_text(pdf_path, skip_first_line=True)\n",
    "\n",
    "# Split the extracted text into paragraphs\n",
    "pdf_paragraphs = split_into_paragraphs(pdf_text)\n",
    "\n",
    "# Initialize an empty list to store the matched data\n",
    "matched_data = []\n",
    "\n",
    "# Iterate through both datasets and match keywords with text\n",
    "for keywords_index, keywords_row in keywords_data.iterrows():\n",
    "    name = keywords_row['name']  # Assuming 'name' is a column in the keywords Excel file\n",
    "    address = keywords_row['address']  # Assuming 'address' is a column in the keywords Excel file\n",
    "    keywords = keywords_row[keyword_column].split()  # Assuming keywords are separated by space\n",
    "    \n",
    "    print(f\"Matching keywords for {name} - {address}: {keywords}\")\n",
    "    \n",
    "    for paragraph in pdf_paragraphs:\n",
    "        # Calculate match scores and matched keywords (excluding stopwords)\n",
    "        match_scores, matched_keywords_list = calculate_match_scores_and_matched_keywords(keywords, paragraph, stopwords)\n",
    "        \n",
    "        # Calculate the match score %\n",
    "        match_score_percentage = sum(match_scores) / len(keywords)\n",
    "        \n",
    "        # Append the matched data to the list\n",
    "        matched_data.append({\n",
    "            'name': name,\n",
    "            'address': address,\n",
    "            'keywords': keywords_row[keyword_column],\n",
    "            'original_paragraph': paragraph,\n",
    "            'matched_keywords': ','.join(matched_keywords_list),\n",
    "            'match_scores': ','.join([f'{score:.2f}' for score in match_scores]),\n",
    "            'match_score %': f'{match_score_percentage * 100:.2f}%'\n",
    "        })\n",
    "\n",
    "# Create a DataFrame from the matched data\n",
    "matched_df = pd.DataFrame(matched_data)\n",
    "\n",
    "# Display the DataFrame with matched data\n",
    "print(matched_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ea171e",
   "metadata": {},
   "source": [
    "## To skip last line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727694f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import PyPDF2\n",
    "import re\n",
    "\n",
    "# Function to extract text from a PDF file and split it into paragraphs, skipping the last line\n",
    "def extract_pdf_text(pdf_path, skip_last_line=True):\n",
    "    pdf_text = ''\n",
    "    with open(pdf_path, 'rb') as pdf_file:\n",
    "        pdf_reader = PyPDF2.PdfFileReader(pdf_file)\n",
    "        for page_num in range(pdf_reader.numPages):\n",
    "            page = pdf_reader.getPage(page_num)\n",
    "            page_text = page.extract_text()\n",
    "            if skip_last_line:\n",
    "                # Split the text into lines and exclude the last line\n",
    "                lines = page_text.split('\\n')\n",
    "                if lines:\n",
    "                    page_text = '\\n'.join(lines[:-1])\n",
    "                else:\n",
    "                    page_text = ''\n",
    "            pdf_text += page_text + '\\n'  # Separate pages by newlines\n",
    "    return pdf_text\n",
    "\n",
    "# Function to split text into paragraphs\n",
    "def split_into_paragraphs(text):\n",
    "    return re.split(r'\\n\\s*\\n', text)\n",
    "\n",
    "# Function to calculate match scores and matched keywords while excluding stopwords\n",
    "def calculate_match_scores_and_matched_keywords(keywords, text, stopwords):\n",
    "    # Convert both keywords and text to lowercase for case-insensitive matching\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Initialize a list to store match scores for each keyword\n",
    "    match_scores = []\n",
    "    \n",
    "    # Initialize a list to store matched keywords\n",
    "    matched_keywords_list = []\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        keyword_parts = keyword.lower().split()\n",
    "        total_parts = len(keyword_parts)\n",
    "        \n",
    "        # Filter out stopwords\n",
    "        keyword_parts = [part for part in keyword_parts if part not in stopwords]\n",
    "        \n",
    "        matched_parts = sum(keyword_part in text_lower for keyword_part in keyword_parts)\n",
    "        match_score = matched_parts / total_parts if total_parts > 0 else 0.0\n",
    "        match_scores.append(match_score)\n",
    "        \n",
    "        # Store the matched keyword (excluding stopwords)\n",
    "        matched_keywords = [keyword_part for keyword_part in keyword_parts if keyword_part in text_lower]\n",
    "        matched_keywords_list.append(\" \".join(matched_keywords))\n",
    "    \n",
    "    return match_scores, matched_keywords_list\n",
    "\n",
    "# Define a list of stopwords to exclude\n",
    "stopwords = [\"is\", \"and\", \"are\"]\n",
    "\n",
    "# Load the dataset with keywords (assuming it's in a separate Excel file)\n",
    "keywords_excel_path = 'path_to_keywords_excel_file.xlsx'\n",
    "keywords_data = pd.read_excel(keywords_excel_path)\n",
    "\n",
    "# Specify the columns for keywords and text\n",
    "keyword_column = 'keywords'  # Column containing keywords in the keywords Excel file\n",
    "\n",
    "# Extract text from the PDF file, skipping the last line on each page\n",
    "pdf_path = 'path_to_your_pdf_file.pdf'\n",
    "pdf_text = extract_pdf_text(pdf_path, skip_last_line=True)\n",
    "\n",
    "# Split the extracted text into paragraphs\n",
    "pdf_paragraphs = split_into_paragraphs(pdf_text)\n",
    "\n",
    "# Initialize an empty list to store the matched data\n",
    "matched_data = []\n",
    "\n",
    "# Iterate through both datasets and match keywords with text\n",
    "for keywords_index, keywords_row in keywords_data.iterrows():\n",
    "    name = keywords_row['name']  # Assuming 'name' is a column in the keywords Excel file\n",
    "    address = keywords_row['address']  # Assuming 'address' is a column in the keywords Excel file\n",
    "    keywords = keywords_row[keyword_column].split()  # Assuming keywords are separated by space\n",
    "    \n",
    "    print(f\"Matching keywords for {name} - {address}: {keywords}\")\n",
    "    \n",
    "    for paragraph in pdf_paragraphs:\n",
    "        # Calculate match scores and matched keywords (excluding stopwords)\n",
    "        match_scores, matched_keywords_list = calculate_match_scores_and_matched_keywords(keywords, paragraph, stopwords)\n",
    "        \n",
    "        # Calculate the match score %\n",
    "        match_score_percentage = sum(match_scores) / len(keywords)\n",
    "        \n",
    "        # Append the matched data to the list\n",
    "        matched_data.append({\n",
    "            'name': name,\n",
    "            'address': address,\n",
    "            'keywords': keywords_row[keyword_column],\n",
    "            'original_paragraph': paragraph,\n",
    "            'matched_keywords': ','.join(matched_keywords_list),\n",
    "            'match_scores': ','.join([f'{score:.2f}' for score in match_scores]),\n",
    "            'match_score %': f'{match_score_percentage * 100:.2f}%'\n",
    "        })\n",
    "\n",
    "# Create a DataFrame from the matched data\n",
    "matched_df = pd.DataFrame(matched_data)\n",
    "\n",
    "# Display the DataFrame with matched data\n",
    "print(matched_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3175fa",
   "metadata": {},
   "source": [
    "## To skip first and last lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56af89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import PyPDF2\n",
    "import re\n",
    "\n",
    "# Function to extract text from a PDF file and split it into paragraphs\n",
    "def extract_pdf_text(pdf_path, skip_first_lines=1, skip_last_lines=1):\n",
    "    pdf_text = ''\n",
    "    with open(pdf_path, 'rb') as pdf_file:\n",
    "        pdf_reader = PyPDF2.PdfFileReader(pdf_file)\n",
    "        for page_num in range(pdf_reader.numPages):\n",
    "            page = pdf_reader.getPage(page_num)\n",
    "            page_text = page.extract_text()\n",
    "            page_lines = page_text.split('\\n')\n",
    "            \n",
    "            # Skip the specified number of lines from the beginning and end\n",
    "            page_lines = page_lines[skip_first_lines:-skip_last_lines]\n",
    "            \n",
    "            pdf_text += '\\n'.join(page_lines) + '\\n'  # Separate pages by newlines\n",
    "    return pdf_text\n",
    "\n",
    "# Function to split text into paragraphs\n",
    "def split_into_paragraphs(text):\n",
    "    return re.split(r'\\n\\s*\\n', text)\n",
    "\n",
    "# Function to calculate match scores and matched keywords while excluding stopwords\n",
    "def calculate_match_scores_and_matched_keywords(keywords, text, stopwords):\n",
    "    # Convert both keywords and text to lowercase for case-insensitive matching\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Initialize a list to store match scores for each keyword\n",
    "    match_scores = []\n",
    "    \n",
    "    # Initialize a list to store matched keywords\n",
    "    matched_keywords_list = []\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        keyword_parts = keyword.lower().split()\n",
    "        total_parts = len(keyword_parts)\n",
    "        \n",
    "        # Filter out stopwords\n",
    "        keyword_parts = [part for part in keyword_parts if part not in stopwords]\n",
    "        \n",
    "        matched_parts = sum(keyword_part in text_lower for keyword_part in keyword_parts)\n",
    "        match_score = matched_parts / total_parts if total_parts > 0 else 0.0\n",
    "        match_scores.append(match_score)\n",
    "        \n",
    "        # Store the matched keyword (excluding stopwords)\n",
    "        matched_keywords = [keyword_part for keyword_part in keyword_parts if keyword_part in text_lower]\n",
    "        matched_keywords_list.append(\" \".join(matched_keywords))\n",
    "    \n",
    "    return match_scores, matched_keywords_list\n",
    "\n",
    "# Define a list of stopwords to exclude\n",
    "stopwords = [\"is\", \"and\", \"are\"]\n",
    "\n",
    "# Load the dataset with keywords (assuming it's in a separate Excel file)\n",
    "keywords_excel_path = 'path_to_keywords_excel_file.xlsx'\n",
    "keywords_data = pd.read_excel(keywords_excel_path)\n",
    "\n",
    "# Specify the columns for keywords and text\n",
    "keyword_column = 'keywords'  # Column containing keywords in the keywords Excel file\n",
    "\n",
    "# Extract text from the PDF file, skipping the first and last lines of each page\n",
    "pdf_path = 'path_to_your_pdf_file.pdf'\n",
    "pdf_text = extract_pdf_text(pdf_path, skip_first_lines=1, skip_last_lines=1)\n",
    "\n",
    "# Split the extracted text into paragraphs\n",
    "pdf_paragraphs = split_into_paragraphs(pdf_text)\n",
    "\n",
    "# Initialize an empty list to store the matched data\n",
    "matched_data = []\n",
    "\n",
    "# Iterate through both datasets and match keywords with text\n",
    "for keywords_index, keywords_row in keywords_data.iterrows():\n",
    "    name = keywords_row['name']  # Assuming 'name' is a column in the keywords Excel file\n",
    "    address = keywords_row['address']  # Assuming 'address' is a column in the keywords Excel file\n",
    "    keywords = keywords_row[keyword_column].split()  # Assuming keywords are separated by space\n",
    "    \n",
    "    print(f\"Matching keywords for {name} - {address}: {keywords}\")\n",
    "    \n",
    "    for paragraph in pdf_paragraphs:\n",
    "        # Calculate match scores and matched keywords (excluding stopwords)\n",
    "        match_scores, matched_keywords_list = calculate_match_scores_and_matched_keywords(keywords, paragraph, stopwords)\n",
    "        \n",
    "        # Calculate the match score %\n",
    "        match_score_percentage = sum(match_scores) / len(keywords)\n",
    "        \n",
    "        # Append the matched data to the list\n",
    "        matched_data.append({\n",
    "            'name': name,\n",
    "            'address': address,\n",
    "            'keywords': keywords_row[keyword_column],\n",
    "            'original_paragraph': paragraph,\n",
    "            'matched_keywords': ','.join(matched_keywords_list),\n",
    "            'match_scores': ','.join([f'{score:.2f}' for score in match_scores]),\n",
    "            'match_score %': f'{match_score_percentage * 100:.2f}%'\n",
    "        })\n",
    "\n",
    "# Create a DataFrame from the matched data\n",
    "matched_df = pd.DataFrame(matched_data)\n",
    "\n",
    "# Display the DataFrame with matched data\n",
    "print(matched_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590423b8",
   "metadata": {},
   "source": [
    "## To skip first 5 pages and first and last line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d3d5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import PyPDF2\n",
    "import re\n",
    "\n",
    "# Function to extract text from a PDF file and split it into paragraphs, skipping the first and last line of each page\n",
    "def extract_pdf_text(pdf_path, skip_pages=5):\n",
    "    pdf_text = ''\n",
    "    with open(pdf_path, 'rb') as pdf_file:\n",
    "        pdf_reader = PyPDF2.PdfFileReader(pdf_file)\n",
    "        num_pages = pdf_reader.numPages\n",
    "        \n",
    "        for page_num in range(skip_pages, num_pages):\n",
    "            page = pdf_reader.getPage(page_num)\n",
    "            page_text = page.extract_text()\n",
    "            page_lines = page_text.split('\\n')\n",
    "            \n",
    "            # Skip the first and last line of each page\n",
    "            page_lines = page_lines[1:-1]\n",
    "            \n",
    "            pdf_text += '\\n'.join(page_lines) + '\\n'  # Separate pages by newlines\n",
    "    return pdf_text\n",
    "\n",
    "# Function to split text into paragraphs\n",
    "def split_into_paragraphs(text):\n",
    "    return re.split(r'\\n\\s*\\n', text)\n",
    "\n",
    "# Function to calculate match scores and matched keywords while excluding stopwords\n",
    "def calculate_match_scores_and_matched_keywords(keywords, text, stopwords):\n",
    "    # Convert both keywords and text to lowercase for case-insensitive matching\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Initialize a list to store match scores for each keyword\n",
    "    match_scores = []\n",
    "    \n",
    "    # Initialize a list to store matched keywords\n",
    "    matched_keywords_list = []\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        keyword_parts = keyword.lower().split()\n",
    "        total_parts = len(keyword_parts)\n",
    "        \n",
    "        # Filter out stopwords\n",
    "        keyword_parts = [part for part in keyword_parts if part not in stopwords]\n",
    "        \n",
    "        matched_parts = sum(keyword_part in text_lower for keyword_part in keyword_parts)\n",
    "        match_score = matched_parts / total_parts if total_parts > 0 else 0.0\n",
    "        match_scores.append(match_score)\n",
    "        \n",
    "        # Store the matched keyword (excluding stopwords)\n",
    "        matched_keywords = [keyword_part for keyword_part in keyword_parts if keyword_part in text_lower]\n",
    "        matched_keywords_list.append(\" \".join(matched_keywords))\n",
    "    \n",
    "    return match_scores, matched_keywords_list\n",
    "\n",
    "# Define a list of stopwords to exclude\n",
    "stopwords = [\"is\", \"and\", \"are\"]\n",
    "\n",
    "# Load the dataset with keywords (assuming it's in a separate Excel file)\n",
    "keywords_excel_path = 'path_to_keywords_excel_file.xlsx'\n",
    "keywords_data = pd.read_excel(keywords_excel_path)\n",
    "\n",
    "# Specify the columns for keywords and text\n",
    "keyword_column = 'keywords'  # Column containing keywords in the keywords Excel file\n",
    "\n",
    "# Extract text from the PDF file, skipping the first 5 pages and the first and last line of each page\n",
    "pdf_path = 'path_to_your_pdf_file.pdf'\n",
    "pdf_text = extract_pdf_text(pdf_path, skip_pages=5)\n",
    "\n",
    "# Split the extracted text into paragraphs\n",
    "pdf_paragraphs = split_into_paragraphs(pdf_text)\n",
    "\n",
    "# Initialize an empty list to store the matched data\n",
    "matched_data = []\n",
    "\n",
    "# Iterate through both datasets and match keywords with text\n",
    "for keywords_index, keywords_row in keywords_data.iterrows():\n",
    "    name = keywords_row['name']  # Assuming 'name' is a column in the keywords Excel file\n",
    "    address = keywords_row['address']  # Assuming 'address' is a column in the keywords Excel file\n",
    "    keywords = keywords_row[keyword_column].split()  # Assuming keywords are separated by space\n",
    "    \n",
    "    print(f\"Matching keywords for {name} - {address}: {keywords}\")\n",
    "    \n",
    "    for paragraph in pdf_paragraphs:\n",
    "        # Calculate match scores and matched keywords (excluding stopwords)\n",
    "        match_scores, matched_keywords_list = calculate_match_scores_and_matched_keywords(keywords, paragraph, stopwords)\n",
    "        \n",
    "        # Calculate the match score %\n",
    "        match_score_percentage = sum(match_scores) / len(keywords)\n",
    "        \n",
    "        # Append the matched data to the list\n",
    "        matched_data.append({\n",
    "            'name': name,\n",
    "            'address': address,\n",
    "            'keywords': keywords_row[keyword_column],\n",
    "            'original_paragraph': paragraph,\n",
    "            'matched_keywords': ','.join(matched_keywords_list),\n",
    "            'match_scores': ','.join([f'{score:.2f}' for score in match_scores]),\n",
    "            'match_score %': f'{match_score_percentage * 100:.2f}%'\n",
    "        })\n",
    "\n",
    "# Create a DataFrame from the matched data\n",
    "matched_df = pd.DataFrame(matched_data)\n",
    "\n",
    "# Display the DataFrame with matched data\n",
    "print(matched_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e2c94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split lines into paragraphs\n",
    "def split_into_paragraphs(lines):\n",
    "    paragraphs = []\n",
    "    current_paragraph = []\n",
    "    for line in lines:\n",
    "        if line.strip():\n",
    "            current_paragraph.append(line)\n",
    "        else:\n",
    "            if current_paragraph:\n",
    "                paragraphs.append('\\n'.join(current_paragraph))\n",
    "                current_paragraph = []\n",
    "    if current_paragraph:\n",
    "        paragraphs.append('\\n'.join(current_paragraph))\n",
    "    return paragraphs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

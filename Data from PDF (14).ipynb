{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fddf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import PyPDF2\n",
    "\n",
    "# Function to extract text from a PDF file, split it into paragraphs, and return page numbers\n",
    "def extract_pdf_text_with_page_numbers(pdf_path, skip_first_lines=1, skip_last_lines=1, skip_first_pages=5):\n",
    "    pdf_text = ''\n",
    "    page_numbers = []\n",
    "    \n",
    "    with open(pdf_path, 'rb') as pdf_file:\n",
    "        pdf_reader = PyPDF2.PdfFileReader(pdf_file)\n",
    "        for page_num in range(skip_first_pages, pdf_reader.numPages):\n",
    "            page = pdf_reader.getPage(page_num)\n",
    "            page_text = page.extract_text()\n",
    "            page_lines = page_text.split('\\n')\n",
    "            \n",
    "            # Skip the specified number of lines from the beginning and end\n",
    "            page_lines = page_lines[skip_first_lines:-skip_last_lines]\n",
    "            \n",
    "            pdf_text += '\\n'.join(page_lines) + '\\n'  # Separate pages by newlines\n",
    "            \n",
    "            # Store page numbers for each paragraph on this page\n",
    "            page_numbers.extend([page_num] * len(page_lines))\n",
    "    \n",
    "    return pdf_text, page_numbers\n",
    "\n",
    "# Function to split lines into paragraphs\n",
    "def split_into_paragraphs(lines):\n",
    "    paragraphs = []\n",
    "    current_paragraph = []\n",
    "    for line in lines:\n",
    "        if line.strip():\n",
    "            current_paragraph.append(line)\n",
    "        else:\n",
    "            if current_paragraph:\n",
    "                paragraphs.append('\\n'.join(current_paragraph))\n",
    "                current_paragraph = []\n",
    "    if current_paragraph:\n",
    "        paragraphs.append('\\n'.join(current_paragraph))\n",
    "    return paragraphs\n",
    "\n",
    "# Function to calculate match scores and matched keywords while excluding stopwords\n",
    "def calculate_match_scores_and_matched_keywords(keywords, text, stopwords):\n",
    "    # Convert both keywords and text to lowercase for case-insensitive matching\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Initialize a list to store match scores for each keyword\n",
    "    match_scores = []\n",
    "    \n",
    "    # Initialize a list to store matched keywords\n",
    "    matched_keywords_list = []\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        keyword_parts = keyword.lower().split()\n",
    "        total_parts = len(keyword_parts)\n",
    "        \n",
    "        # Filter out stopwords\n",
    "        keyword_parts = [part for part in keyword_parts if part not in stopwords]\n",
    "        \n",
    "        matched_parts = sum(keyword_part in text_lower for keyword_part in keyword_parts)\n",
    "        match_score = matched_parts / total_parts if total_parts > 0 else 0.0\n",
    "        match_scores.append(match_score)\n",
    "        \n",
    "        # Store the matched keyword (excluding stopwords)\n",
    "        matched_keywords = [keyword_part for keyword_part in keyword_parts if keyword_part in text_lower]\n",
    "        matched_keywords_list.append(\" \".join(matched_keywords))\n",
    "    \n",
    "    return match_scores, matched_keywords_list\n",
    "\n",
    "# Define a list of stopwords to exclude\n",
    "stopwords = [\"is\", \"and\", \"are\"]\n",
    "\n",
    "# Load the dataset with keywords (assuming it's in a separate Excel file)\n",
    "keywords_excel_path = 'path_to_keywords_excel_file.xlsx'\n",
    "keywords_data = pd.read_excel(keywords_excel_path)\n",
    "\n",
    "# Specify the columns for keywords and text\n",
    "keyword_column = 'keywords'  # Column containing keywords in the keywords Excel file\n",
    "\n",
    "# Extract text from the PDF file, including page numbers, and skip the first 5 pages and the first and last lines of each page\n",
    "pdf_path = 'path_to_your_pdf_file.pdf'\n",
    "pdf_text, page_numbers = extract_pdf_text_with_page_numbers(pdf_path, skip_first_lines=1, skip_last_lines=1, skip_first_pages=5)\n",
    "\n",
    "# Save the extracted text to a file\n",
    "with open('extracted_text.txt', 'w', encoding='utf-8') as text_file:\n",
    "    text_file.write(pdf_text)\n",
    "\n",
    "# Split the extracted text into paragraphs\n",
    "pdf_paragraphs = split_into_paragraphs(pdf_text.split('\\n'))\n",
    "\n",
    "# Initialize an empty list to store the matched data\n",
    "matched_data = []\n",
    "\n",
    "# Iterate through both datasets and match keywords with text\n",
    "for keywords_index, keywords_row in keywords_data.iterrows():\n",
    "    name = keywords_row['name']  # Assuming 'name' is a column in the keywords Excel file\n",
    "    address = keywords_row['address']  # Assuming 'address' is a column in the keywords Excel file\n",
    "    keywords = keywords_row[keyword_column].split()  # Assuming keywords are separated by space\n",
    "    \n",
    "    print(f\"Matching keywords for {name} - {address}: {keywords}\")\n",
    "    \n",
    "    for page_num, paragraph in enumerate(pdf_paragraphs, 1):\n",
    "        if isinstance(paragraph, str):  # Check if the paragraph is a string\n",
    "            # Calculate match scores and matched keywords (excluding stopwords)\n",
    "            match_scores, matched_keywords_list = calculate_match_scores_and_matched_keywords(keywords, paragraph, stopwords)\n",
    "            \n",
    "            # Calculate the match score percentage and convert it to an integer\n",
    "            match_score_percentage = int(sum(match_scores) / len(keywords) * 100)\n",
    "            \n",
    "            # Append the matched data to the list\n",
    "            matched_data.append({\n",
    "                'name': name,\n",
    "                'address': address,\n",
    "                'keywords': keywords_row[keyword_column],\n",
    "                'original_paragraph': paragraph,\n",
    "                'matched_keywords': ','.join(matched_keywords_list),\n",
    "                'match_scores': ','.join([f'{score:.2f}' for score in match_scores]),\n",
    "                'match_score %': match_score_percentage,  # Convert to int\n",
    "                'page_number': page_num  # Add the page number to the output\n",
    "            })\n",
    "\n",
    "# Create a DataFrame from the matched data\n",
    "matched_df = pd.DataFrame(matched_data)\n",
    "\n",
    "# Display the DataFrame with matched data\n",
    "print(matched_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1eff9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import PyPDF2\n",
    "\n",
    "# Function to extract text from a PDF file, split it into paragraphs, and return page numbers\n",
    "def extract_pdf_text_with_page_numbers(pdf_path, skip_first_lines=1, skip_last_lines=1, skip_first_pages=5):\n",
    "    pdf_text = ''\n",
    "    page_numbers = []\n",
    "    \n",
    "    with open(pdf_path, 'rb') as pdf_file:\n",
    "        pdf_reader = PyPDF2.PdfFileReader(pdf_file)\n",
    "        for page_num in range(skip_first_pages, pdf_reader.numPages):\n",
    "            page = pdf_reader.getPage(page_num)\n",
    "            page_text = page.extract_text()\n",
    "            page_lines = page_text.split('\\n')\n",
    "            \n",
    "            # Skip the specified number of lines from the beginning and end\n",
    "            page_lines = page_lines[skip_first_lines:-skip_last_lines]\n",
    "            \n",
    "            pdf_text += '\\n'.join(page_lines) + '\\n'  # Separate pages by newlines\n",
    "            \n",
    "            # Store page numbers for each paragraph on this page\n",
    "            page_numbers.extend([page_num] * len(page_lines))\n",
    "    \n",
    "    return pdf_text, page_numbers\n",
    "\n",
    "# Function to split lines into paragraphs\n",
    "def split_into_paragraphs(lines):\n",
    "    paragraphs = []\n",
    "    current_paragraph = []\n",
    "    for line in lines:\n",
    "        if line.strip():\n",
    "            current_paragraph.append(line)\n",
    "        else:\n",
    "            if current_paragraph:\n",
    "                paragraphs.append('\\n'.join(current_paragraph))\n",
    "                current_paragraph = []\n",
    "    if current_paragraph:\n",
    "        paragraphs.append('\\n'.join(current_paragraph))\n",
    "    return paragraphs\n",
    "\n",
    "# Replace 'path_to_your_pdf_file.pdf' with the actual path to your PDF file\n",
    "pdf_path = 'path_to_your_pdf_file.pdf'\n",
    "\n",
    "# Extract text from the PDF file, including page numbers, and skip the first 5 pages and the first and last lines of each page\n",
    "pdf_text, page_numbers = extract_pdf_text_with_page_numbers(pdf_path, skip_first_lines=1, skip_last_lines=1, skip_first_pages=5)\n",
    "\n",
    "# Split the extracted text into paragraphs\n",
    "pdf_paragraphs = split_into_paragraphs(pdf_text.split('\\n'))\n",
    "\n",
    "# Create a DataFrame to store the extracted PDF data\n",
    "pdf_data = pd.DataFrame({\n",
    "    'Original Paragraph': pdf_paragraphs,\n",
    "    'Page Number': page_numbers\n",
    "})\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "pdf_data.to_excel('extracted_pdf_data.xlsx', index=False)\n",
    "\n",
    "# Display a message indicating that the data has been saved\n",
    "print(\"Extracted PDF data has been saved to 'extracted_pdf_data.xlsx'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fb75db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcb4154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import PyPDF2\n",
    "\n",
    "# Function to split lines into paragraphs\n",
    "def split_into_paragraphs(lines):\n",
    "    paragraphs = []\n",
    "    current_paragraph = []\n",
    "    for line in lines:\n",
    "        if line.strip():\n",
    "            current_paragraph.append(line)\n",
    "        else:\n",
    "            if current_paragraph:\n",
    "                paragraphs.append('\\n'.join(current_paragraph))\n",
    "                current_paragraph = []\n",
    "    if current_paragraph:\n",
    "        paragraphs.append('\\n'.join(current_paragraph))\n",
    "    return paragraphs\n",
    "\n",
    "# Function to calculate match scores and matched keywords while excluding stopwords\n",
    "def calculate_match_scores_and_matched_keywords(keywords, text, stopwords):\n",
    "    # Convert both keywords and text to lowercase for case-insensitive matching\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Initialize a list to store match scores for each keyword\n",
    "    match_scores = []\n",
    "    \n",
    "    # Initialize a list to store matched keywords\n",
    "    matched_keywords_list = []\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        keyword_parts = keyword.lower().split()\n",
    "        total_parts = len(keyword_parts)\n",
    "        \n",
    "        # Filter out stopwords\n",
    "        keyword_parts = [part for part in keyword_parts if part not in stopwords]\n",
    "        \n",
    "        matched_parts = sum(keyword_part in text_lower for keyword_part in keyword_parts)\n",
    "        match_score = matched_parts / total_parts if total_parts > 0 else 0.0\n",
    "        match_scores.append(match_score)\n",
    "        \n",
    "        # Store the matched keyword (excluding stopwords)\n",
    "        matched_keywords = [keyword_part for keyword_part in keyword_parts if keyword_part in text_lower]\n",
    "        matched_keywords_list.append(\" \".join(matched_keywords))\n",
    "    \n",
    "    return match_scores, matched_keywords_list\n",
    "\n",
    "# Define a list of stopwords to exclude\n",
    "stopwords = [\"is\", \"and\", \"are\"]\n",
    "\n",
    "# Load the dataset with keywords (assuming it's in a separate Excel file)\n",
    "keywords_excel_path = 'path_to_keywords_excel_file.xlsx'\n",
    "keywords_data = pd.read_excel(keywords_excel_path)\n",
    "\n",
    "# Specify the columns for keywords and text\n",
    "keyword_column = 'keywords'  # Column containing keywords in the keywords Excel file\n",
    "\n",
    "# Replace 'path_to_your_pdf_file.pdf' with the actual path to your PDF file\n",
    "pdf_path = 'path_to_your_pdf_file.pdf'\n",
    "\n",
    "# Open the PDF file\n",
    "with open(pdf_path, 'rb') as pdf_file:\n",
    "    \n",
    "    # Iterate through sheets in the Excel file with multiple sheets\n",
    "    for sheet_name in pd.ExcelFile(pdf_path).sheet_names:\n",
    "        \n",
    "        # Read the data from the current sheet\n",
    "        sheet_data = pd.read_excel(pdf_path, sheet_name)\n",
    "        \n",
    "        # Extract text from the PDF file, including page numbers\n",
    "        pdf_text, page_numbers = extract_pdf_text_with_page_numbers(pdf_file, skip_first_lines=1, skip_last_lines=1, skip_first_pages=5)\n",
    "        \n",
    "        # Split the extracted text into paragraphs\n",
    "        pdf_paragraphs = split_into_paragraphs(pdf_text.split('\\n'))\n",
    "        \n",
    "        # Initialize an empty list to store the matched data\n",
    "        matched_data = []\n",
    "        \n",
    "        # Iterate through both datasets and match keywords with text\n",
    "        for keywords_index, keywords_row in keywords_data.iterrows():\n",
    "            name = keywords_row['name']  # Assuming 'name' is a column in the keywords Excel file\n",
    "            address = keywords_row['address']  # Assuming 'address' is a column in the keywords Excel file\n",
    "            keywords = keywords_row[keyword_column].split()  # Assuming keywords are separated by space\n",
    "            \n",
    "            print(f\"Matching keywords for {name} - {address} in sheet '{sheet_name}': {keywords}\")\n",
    "            \n",
    "            for page_num, paragraph in enumerate(pdf_paragraphs, 1):\n",
    "                if isinstance(paragraph, str):  # Check if the paragraph is a string\n",
    "                    # Calculate match scores and matched keywords (excluding stopwords)\n",
    "                    match_scores, matched_keywords_list = calculate_match_scores_and_matched_keywords(keywords, paragraph, stopwords)\n",
    "                    \n",
    "                    # Calculate the match score percentage and convert it to an integer\n",
    "                    match_score_percentage = int(sum(match_scores) / len(keywords) * 100)\n",
    "                    \n",
    "                    # Append the matched data to the list\n",
    "                    matched_data.append({\n",
    "                        'name': name,\n",
    "                        'address': address,\n",
    "                        'keywords': keywords_row[keyword_column],\n",
    "                        'original_paragraph': paragraph,\n",
    "                        'matched_keywords': ','.join(matched_keywords_list),\n",
    "                        'match_scores': ','.join([f'{score:.2f}' for score in match_scores]),\n",
    "                        'match_score %': match_score_percentage,  # Convert to int\n",
    "                        'page_number': page_num  # Add the page number to the output\n",
    "                    })\n",
    "        \n",
    "        # Create a DataFrame from the matched data\n",
    "        matched_df = pd.DataFrame(matched_data)\n",
    "        \n",
    "        # Save the DataFrame to an Excel file for the current sheet\n",
    "        output_file_path = f'matched_output_{sheet_name}.xlsx'\n",
    "        matched_df.to_excel(output_file_path, index=False)\n",
    "        \n",
    "        # Display a message indicating that the data has been saved\n",
    "        print(f\"Matched data for sheet '{sheet_name}' has been saved to '{output_file_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e65bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe8f304",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to calculate match scores and matched keywords while excluding stopwords\n",
    "def calculate_match_scores_and_matched_keywords(keywords, text, stopwords):\n",
    "    # Convert both keywords and text to lowercase for case-insensitive matching\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Initialize a list to store match scores for each keyword\n",
    "    match_scores = []\n",
    "    \n",
    "    # Initialize a list to store matched keywords\n",
    "    matched_keywords_list = []\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        keyword_parts = keyword.lower().split()\n",
    "        total_parts = len(keyword_parts)\n",
    "        \n",
    "        # Filter out stopwords\n",
    "        keyword_parts = [part for part in keyword_parts if part not in stopwords]\n",
    "        \n",
    "        matched_parts = sum(keyword_part in text_lower for keyword_part in keyword_parts)\n",
    "        match_score = matched_parts / total_parts if total_parts > 0 else 0.0\n",
    "        match_scores.append(match_score)\n",
    "        \n",
    "        # Store the matched keyword (excluding stopwords)\n",
    "        matched_keywords = [keyword_part for keyword_part in keyword_parts if keyword_part in text_lower]\n",
    "        matched_keywords_list.append(\" \".join(matched_keywords))\n",
    "    \n",
    "    return match_scores, matched_keywords_list\n",
    "\n",
    "# Define a list of stopwords to exclude\n",
    "stopwords = [\"is\", \"and\", \"are\"]\n",
    "\n",
    "# Load the dataset with keywords (assuming it's in a separate Excel file)\n",
    "keywords_excel_path = 'path_to_keywords_excel_file.xlsx'\n",
    "keywords_data = pd.read_excel(keywords_excel_path)\n",
    "\n",
    "# Replace 'path_to_your_excel_file.xlsx' with the actual path to your Excel file with multiple sheets\n",
    "excel_file_path = 'path_to_your_excel_file.xlsx'\n",
    "\n",
    "# Iterate through sheets in the Excel file with multiple sheets\n",
    "for sheet_name in pd.ExcelFile(excel_file_path).sheet_names:\n",
    "    \n",
    "    # Read the data from the current sheet\n",
    "    sheet_data = pd.read_excel(excel_file_path, sheet_name)\n",
    "    \n",
    "    # Initialize an empty list to store the matched data\n",
    "    matched_data = []\n",
    "    \n",
    "    # Iterate through both datasets and match keywords with text\n",
    "    for keywords_index, keywords_row in keywords_data.iterrows():\n",
    "        name = keywords_row['name']  # Assuming 'name' is a column in the keywords Excel file\n",
    "        address = keywords_row['address']  # Assuming 'address' is a column in the keywords Excel file\n",
    "        keywords = keywords_row['keywords'].split()  # Assuming keywords are separated by space\n",
    "        \n",
    "        print(f\"Matching keywords for {name} - {address} in sheet '{sheet_name}': {keywords}\")\n",
    "        \n",
    "        for row_index, row in sheet_data.iterrows():\n",
    "            text_column = 'text_column'  # Replace with the actual column name containing text in your Excel file\n",
    "            text = row[text_column] if text_column in row else ''\n",
    "            \n",
    "            # Calculate match scores and matched keywords (excluding stopwords)\n",
    "            match_scores, matched_keywords_list = calculate_match_scores_and_matched_keywords(keywords, text, stopwords)\n",
    "            \n",
    "            # Calculate the match score percentage and convert it to an integer\n",
    "            match_score_percentage = int(sum(match_scores) / len(keywords) * 100)\n",
    "            \n",
    "            # Append the matched data to the list\n",
    "            matched_data.append({\n",
    "                'name': name,\n",
    "                'address': address,\n",
    "                'keywords': keywords_row['keywords'],\n",
    "                'matched_keywords': ','.join(matched_keywords_list),\n",
    "                'match_scores': ','.join([f'{score:.2f}' for score in match_scores]),\n",
    "                'match_score %': match_score_percentage,  # Convert to int\n",
    "            })\n",
    "    \n",
    "    # Create a DataFrame from the matched data\n",
    "    matched_df = pd.DataFrame(matched_data)\n",
    "    \n",
    "    # Save the DataFrame to an Excel file for the current sheet\n",
    "    output_file_path = f'matched_output_{sheet_name}.xlsx'\n",
    "    matched_df.to_excel(output_file_path, index=False)\n",
    "    \n",
    "    # Display a message indicating that the data has been saved\n",
    "    print(f\"Matched data for sheet '{sheet_name}' has been saved to '{output_file_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75da4dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to calculate match scores and matched keywords while excluding stopwords\n",
    "def calculate_match_scores_and_matched_keywords(keywords, text, stopwords):\n",
    "    # Convert both keywords and text to lowercase for case-insensitive matching\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Initialize a list to store match scores for each keyword\n",
    "    match_scores = []\n",
    "    \n",
    "    # Initialize a list to store matched keywords\n",
    "    matched_keywords_list = []\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        keyword_parts = keyword.lower().split()\n",
    "        total_parts = len(keyword_parts)\n",
    "        \n",
    "        # Filter out stopwords\n",
    "        keyword_parts = [part for part in keyword_parts if part not in stopwords]\n",
    "        \n",
    "        matched_parts = sum(keyword_part in text_lower for keyword_part in keyword_parts)\n",
    "        match_score = matched_parts / total_parts if total_parts > 0 else 0.0\n",
    "        match_scores.append(match_score)\n",
    "        \n",
    "        # Store the matched keyword (excluding stopwords)\n",
    "        matched_keywords = [keyword_part for keyword_part in keyword_parts if keyword_part in text_lower]\n",
    "        matched_keywords_list.append(\" \".join(matched_keywords))\n",
    "    \n",
    "    return match_scores, matched_keywords_list\n",
    "\n",
    "# Define a list of stopwords to exclude\n",
    "stopwords = [\"is\", \"and\", \"are\"]\n",
    "\n",
    "# Load the dataset with keywords (assuming it's in a separate Excel file)\n",
    "keywords_excel_path = 'path_to_keywords_excel_file.xlsx'\n",
    "keywords_data = pd.read_excel(keywords_excel_path)\n",
    "\n",
    "# Replace 'path_to_your_excel_file.xlsx' with the actual path to your Excel file with multiple sheets\n",
    "excel_file_path = 'path_to_your_excel_file.xlsx'\n",
    "\n",
    "# Iterate through sheets in the Excel file with multiple sheets\n",
    "for sheet_name in pd.ExcelFile(excel_file_path).sheet_names:\n",
    "    \n",
    "    # Read the data from the current sheet\n",
    "    sheet_data = pd.read_excel(excel_file_path, sheet_name)\n",
    "    \n",
    "    # Initialize an empty list to store the matched data\n",
    "    matched_data = []\n",
    "    \n",
    "    # Iterate through both datasets and match keywords with text\n",
    "    for keywords_index, keywords_row in keywords_data.iterrows():\n",
    "        name = keywords_row['name']  # Assuming 'name' is a column in the keywords Excel file\n",
    "        address = keywords_row['address']  # Assuming 'address' is a column in the keywords Excel file\n",
    "        keywords = keywords_row['keywords'].split()  # Assuming keywords are separated by space\n",
    "        \n",
    "        print(f\"Matching keywords for {name} - {address} in sheet '{sheet_name}': {keywords}\")\n",
    "        \n",
    "        for row_index, row in sheet_data.iterrows():\n",
    "            text_column = 'text_column'  # Replace with the actual column name containing text in your Excel file\n",
    "            text = row[text_column] if text_column in row else ''\n",
    "            \n",
    "            # Calculate match scores and matched keywords (excluding stopwords)\n",
    "            match_scores, matched_keywords_list = calculate_match_scores_and_matched_keywords(keywords, text, stopwords)\n",
    "            \n",
    "            # Calculate the match score percentage and convert it to an integer\n",
    "            match_score_percentage = int(sum(match_scores) / len(keywords) * 100)\n",
    "            \n",
    "            # Append the matched data to the list\n",
    "            matched_data.append({\n",
    "                'name': name,\n",
    "                'address': address,\n",
    "                'keywords': keywords_row['keywords'],\n",
    "                'matched_keywords': ','.join(matched_keywords_list),\n",
    "                'match_scores': ','.join([f'{score:.2f}' for score in match_scores]),\n",
    "                'match_score %': match_score_percentage,  # Convert to int\n",
    "            })\n",
    "    \n",
    "    # Create a DataFrame from the matched data\n",
    "    matched_df = pd.DataFrame(matched_data)\n",
    "    \n",
    "    # Save the DataFrame to an Excel file for the current sheet\n",
    "    output_file_path = f'matched_output_{sheet_name}.xlsx'\n",
    "    matched_df.to_excel(output_file_path, index=False)\n",
    "    \n",
    "    # Display a message indicating that the data has been saved\n",
    "    print(f\"Matched data for sheet '{sheet_name}' has been saved to '{output_file_path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1f2fa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39140479",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to calculate match scores and matched keywords while excluding stopwords\n",
    "def calculate_match_scores_and_matched_keywords(keywords, text, stopwords):\n",
    "    if not isinstance(text, str):\n",
    "        return [], []  # Return empty lists if the text is not a string\n",
    "    \n",
    "    # Convert both keywords and text to lowercase for case-insensitive matching\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Initialize a list to store match scores for each keyword\n",
    "    match_scores = []\n",
    "    \n",
    "    # Initialize a list to store matched keywords\n",
    "    matched_keywords_list = []\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        keyword_parts = keyword.lower().split()\n",
    "        total_parts = len(keyword_parts)\n",
    "        \n",
    "        # Filter out stopwords\n",
    "        keyword_parts = [part for part in keyword_parts if part not in stopwords]\n",
    "        \n",
    "        matched_parts = sum(keyword_part in text_lower for keyword_part in keyword_parts)\n",
    "        match_score = matched_parts / total_parts if total_parts > 0 else 0.0\n",
    "        match_scores.append(match_score)\n",
    "        \n",
    "        # Store the matched keyword (excluding stopwords)\n",
    "        matched_keywords = [keyword_part for keyword_part in keyword_parts if keyword_part in text_lower]\n",
    "        matched_keywords_list.append(\" \".join(matched_keywords))\n",
    "    \n",
    "    return match_scores, matched_keywords_list\n",
    "\n",
    "# Define a list of stopwords to exclude\n",
    "stopwords = [\"is\", \"and\", \"are\"]\n",
    "\n",
    "# Load the dataset with keywords (assuming it's in a separate Excel file)\n",
    "keywords_excel_path = 'path_to_keywords_excel_file.xlsx'\n",
    "keywords_data = pd.read_excel(keywords_excel_path)\n",
    "\n",
    "# Replace 'path_to_your_excel_file.xlsx' with the actual path to your Excel file with multiple sheets\n",
    "excel_file_path = 'path_to_your_excel_file.xlsx'\n",
    "\n",
    "# Create an Excel writer to save the matched data for each sheet in a separate sheet\n",
    "output_excel_path = 'matched_output.xlsx'\n",
    "with pd.ExcelWriter(output_excel_path, engine='xlsxwriter') as writer:\n",
    "    # Iterate through sheets in the Excel file with multiple sheets\n",
    "    for sheet_name in pd.ExcelFile(excel_file_path).sheet_names:\n",
    "        # Read the data from the current sheet\n",
    "        sheet_data = pd.read_excel(excel_file_path, sheet_name)\n",
    "        \n",
    "        # Initialize an empty list to store the matched data\n",
    "        matched_data = []\n",
    "        \n",
    "        # Iterate through both datasets and match keywords with text\n",
    "        for keywords_index, keywords_row in keywords_data.iterrows():\n",
    "            name = keywords_row['name']  # Assuming 'name' is a column in the keywords Excel file\n",
    "            address = keywords_row['address']  # Assuming 'address' is a column in the keywords Excel file\n",
    "            keywords = keywords_row['keywords'].split()  # Assuming keywords are separated by space\n",
    "            \n",
    "            print(f\"Matching keywords for {name} - {address} in sheet '{sheet_name}': {keywords}\")\n",
    "            \n",
    "            for row_index, row in sheet_data.iterrows():\n",
    "                text_column = 'text_column'  # Replace with the actual column name containing text in your Excel file\n",
    "                text = row[text_column]\n",
    "                \n",
    "                # Calculate match scores and matched keywords (excluding stopwords)\n",
    "                match_scores, matched_keywords_list = calculate_match_scores_and_matched_keywords(keywords, text, stopwords)\n",
    "                \n",
    "                # Calculate the match score percentage and convert it to an integer\n",
    "                match_score_percentage = int(sum(match_scores) / len(keywords) * 100)\n",
    "                \n",
    "                # Append the matched data to the list\n",
    "                matched_data.append({\n",
    "                    'name': name,\n",
    "                    'address': address,\n",
    "                    'keywords': keywords_row['keywords'],\n",
    "                    'original_text': text,\n",
    "                    'matched_keywords': ','.join(matched_keywords_list),\n",
    "                    'match_scores': ','.join([f'{score:.2f}' for score in match_scores]),\n",
    "                    'match_score %': match_score_percentage,  # Convert to int\n",
    "                })\n",
    "        \n",
    "        # Create a DataFrame from the matched data\n",
    "        matched_df = pd.DataFrame(matched_data)\n",
    "        \n",
    "        # Save the DataFrame to an Excel sheet for the current sheet\n",
    "        matched_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "        \n",
    "        # Display a message indicating that the data has been saved\n",
    "        print(f\"Matched data for sheet '{sheet_name}' has been saved to '{output_excel_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0efa48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to calculate match scores and matched keywords while excluding stopwords\n",
    "def calculate_match_scores_and_matched_keywords(keywords, text, stopwords):\n",
    "    if not isinstance(text, str):\n",
    "        return [], []  # Return empty lists if the text is not a string\n",
    "    \n",
    "    # Convert both keywords and text to lowercase for case-insensitive matching\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Initialize a list to store match scores for each keyword\n",
    "    match_scores = []\n",
    "    \n",
    "    # Initialize a list to store matched keywords\n",
    "    matched_keywords_list = []\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        keyword_parts = keyword.lower().split()\n",
    "        total_parts = len(keyword_parts)\n",
    "        \n",
    "        # Filter out stopwords\n",
    "        keyword_parts = [part for part in keyword_parts if part not in stopwords]\n",
    "        \n",
    "        matched_parts = sum(keyword_part in text_lower for keyword_part in keyword_parts)\n",
    "        match_score = matched_parts / total_parts if total_parts > 0 else 0.0\n",
    "        match_scores.append(match_score)\n",
    "        \n",
    "        # Store the matched keyword (excluding stopwords)\n",
    "        matched_keywords = [keyword_part for keyword_part in keyword_parts if keyword_part in text_lower]\n",
    "        matched_keywords_list.append(\" \".join(matched_keywords))\n",
    "    \n",
    "    return match_scores, matched_keywords_list\n",
    "\n",
    "# Define a list of stopwords to exclude\n",
    "stopwords = [\"is\", \"and\", \"are\"]\n",
    "\n",
    "# Load the dataset with keywords (assuming it's in a separate Excel file)\n",
    "keywords_excel_path = 'path_to_keywords_excel_file.xlsx'\n",
    "keywords_data = pd.read_excel(keywords_excel_path)\n",
    "\n",
    "# Replace 'path_to_your_excel_file.xlsx' with the actual path to your Excel file with multiple sheets\n",
    "excel_file_path = 'path_to_your_excel_file.xlsx'\n",
    "\n",
    "# Create an Excel writer to save the matched data for each sheet in a separate sheet\n",
    "output_excel_path = 'matched_output.xlsx'\n",
    "with pd.ExcelWriter(output_excel_path, engine='xlsxwriter') as writer:\n",
    "    # Iterate through sheets in the Excel file with multiple sheets\n",
    "    for sheet_name in pd.ExcelFile(excel_file_path).sheet_names:\n",
    "        # Read the data from the current sheet\n",
    "        sheet_data = pd.read_excel(excel_file_path, sheet_name)\n",
    "        \n",
    "        # Initialize an empty list to store the matched data\n",
    "        matched_data = []\n",
    "        \n",
    "        # Iterate through both datasets and match keywords with text\n",
    "        for keywords_index, keywords_row in keywords_data.iterrows():\n",
    "            name = keywords_row['name']  # Assuming 'name' is a column in the keywords Excel file\n",
    "            address = keywords_row['address']  # Assuming 'address' is a column in the keywords Excel file\n",
    "            keywords = keywords_row['keywords'].split()  # Assuming keywords are separated by space\n",
    "            \n",
    "            print(f\"Matching keywords for {name} - {address} in sheet '{sheet_name}': {keywords}\")\n",
    "            \n",
    "            for row_index, row in sheet_data.iterrows():\n",
    "                text_column = 'text_column'  # Replace with the actual column name containing text in your Excel file\n",
    "                text = row[text_column]\n",
    "                \n",
    "                # Calculate match scores and matched keywords (excluding stopwords)\n",
    "                match_scores, matched_keywords_list = calculate_match_scores_and_matched_keywords(keywords, text, stopwords)\n",
    "                \n",
    "                # Calculate the match score percentage and convert it to an integer\n",
    "                match_score_percentage = int(sum(match_scores) / len(keywords) * 100)\n",
    "                \n",
    "                # Append the matched data to the list\n",
    "                matched_data.append({\n",
    "                    'name': name,\n",
    "                    'address': address,\n",
    "                    'keywords': keywords_row['keywords'],\n",
    "                    'original_text': text,\n",
    "                    'matched_keywords': ','.join(matched_keywords_list),\n",
    "                    'match_scores': ','.join([f'{score:.2f}' for score in match_scores]),\n",
    "                    'match_score %': match_score_percentage,  # Convert to int\n",
    "                })\n",
    "        \n",
    "        # Create a DataFrame from the matched data\n",
    "        matched_df = pd.DataFrame(matched_data)\n",
    "        \n",
    "        # Save the DataFrame to an Excel sheet for the current sheet\n",
    "        matched_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "        \n",
    "        # Display a message indicating that the data has been saved\n",
    "        print(f\"Matched data for sheet '{sheet_name}' has been saved to '{output_excel_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a844d46a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18be674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to calculate match scores and matched keywords while excluding stopwords\n",
    "def calculate_match_scores_and_matched_keywords(keywords, text, stopwords):\n",
    "    if not isinstance(text, str):\n",
    "        return [], []  # Return empty lists if the text is not a string\n",
    "    \n",
    "    # Convert both keywords and text to lowercase for case-insensitive matching\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Initialize a list to store match scores for each keyword\n",
    "    match_scores = []\n",
    "    \n",
    "    # Initialize a list to store matched keywords\n",
    "    matched_keywords_list = []\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        keyword_parts = keyword.lower().split()\n",
    "        total_parts = len(keyword_parts)\n",
    "        \n",
    "        # Filter out stopwords\n",
    "        keyword_parts = [part for part in keyword_parts if part not in stopwords]\n",
    "        \n",
    "        matched_parts = sum(keyword_part in text_lower for keyword_part in keyword_parts)\n",
    "        match_score = matched_parts / total_parts if total_parts > 0 else 0.0\n",
    "        match_scores.append(match_score)\n",
    "        \n",
    "        # Store the matched keyword (excluding stopwords)\n",
    "        matched_keywords = [keyword_part for keyword_part in keyword_parts if keyword_part in text_lower]\n",
    "        matched_keywords_list.append(\" \".join(matched_keywords))\n",
    "    \n",
    "    return match_scores, matched_keywords_list\n",
    "\n",
    "# Define a list of stopwords to exclude\n",
    "stopwords = [\"is\", \"and\", \"are\"]\n",
    "\n",
    "# Load the dataset with keywords (assuming it's in a separate Excel file)\n",
    "keywords_excel_path = 'path_to_keywords_excel_file.xlsx'\n",
    "keywords_data = pd.read_excel(keywords_excel_path)\n",
    "\n",
    "# Replace 'path_to_your_excel_file.xlsx' with the actual path to your Excel file with multiple sheets\n",
    "excel_file_path = 'path_to_your_excel_file.xlsx'\n",
    "\n",
    "# Create an Excel writer to save the matched data for each sheet in a separate sheet\n",
    "output_excel_path = 'matched_output.xlsx'\n",
    "with pd.ExcelWriter(output_excel_path, engine='xlsxwriter') as writer:\n",
    "    # Iterate through sheets in the Excel file with multiple sheets\n",
    "    for sheet_name in pd.ExcelFile(excel_file_path).sheet_names:\n",
    "        # Read the data from the current sheet\n",
    "        sheet_data = pd.read_excel(excel_file_path, sheet_name)\n",
    "        \n",
    "        # Initialize an empty list to store the matched data\n",
    "        matched_data = []\n",
    "        \n",
    "        # Iterate through both datasets and match keywords with text\n",
    "        for keywords_index, keywords_row in keywords_data.iterrows():\n",
    "            name = keywords_row['name']  # Assuming 'name' is a column in the keywords Excel file\n",
    "            address = keywords_row['address']  # Assuming 'address' is a column in the keywords Excel file\n",
    "            keywords = keywords_row['keywords'].split()  # Assuming keywords are separated by space\n",
    "            \n",
    "            print(f\"Matching keywords for {name} - {address} in sheet '{sheet_name}': {keywords}\")\n",
    "            \n",
    "            for row_index, row in sheet_data.iterrows():\n",
    "                text_column = 'text_column'  # Replace with the actual column name containing text in your Excel file\n",
    "                text = row[text_column]\n",
    "                \n",
    "                # Calculate match scores and matched keywords (excluding stopwords)\n",
    "                match_scores, matched_keywords_list = calculate_match_scores_and_matched_keywords(keywords, text, stopwords)\n",
    "                \n",
    "                # Calculate the match score percentage based on the length of the original text\n",
    "                match_score_percentage = int(sum(match_scores) / len(text.split()) * 100) if text else 0\n",
    "                \n",
    "                # Append the matched data to the list\n",
    "                matched_data.append({\n",
    "                    'name': name,\n",
    "                    'address': address,\n",
    "                    'keywords': keywords_row['keywords'],\n",
    "                    'original_text': text,\n",
    "                    'matched_keywords': ','.join(matched_keywords_list),\n",
    "                    'match_scores': ','.join([f'{score:.2f}' for score in match_scores]),\n",
    "                    'match_score %': match_score_percentage,  # Convert to int\n",
    "                })\n",
    "        \n",
    "        # Create a DataFrame from the matched data\n",
    "        matched_df = pd.DataFrame(matched_data)\n",
    "        \n",
    "        # Save the DataFrame to an Excel sheet for the current sheet\n",
    "        matched_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "        \n",
    "        # Display a message indicating that the data has been saved\n",
    "        print(f\"Matched data for sheet '{sheet_name}' has been saved to '{output_excel_path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2f05dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25edba9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47dfba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to calculate match scores and matched keywords while excluding stopwords\n",
    "def calculate_match_scores_and_matched_keywords(keywords, text, stopwords):\n",
    "    if not isinstance(text, str):\n",
    "        return [], []  # Return empty lists if the text is not a string\n",
    "    \n",
    "    # Convert both keywords and text to lowercase for case-insensitive matching\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Initialize a list to store match scores for each keyword\n",
    "    match_scores = []\n",
    "    \n",
    "    # Initialize a list to store matched keywords\n",
    "    matched_keywords_list = []\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        keyword_parts = keyword.lower().split()\n",
    "        total_parts = len(keyword_parts)\n",
    "        \n",
    "        # Filter out stopwords\n",
    "        keyword_parts = [part for part in keyword_parts if part not in stopwords]\n",
    "        \n",
    "        matched_parts = sum(keyword_part in text_lower for keyword_part in keyword_parts)\n",
    "        match_score = matched_parts / total_parts if total_parts > 0 else 0.0\n",
    "        match_scores.append(match_score)\n",
    "        \n",
    "        # Store the matched keyword (excluding stopwords)\n",
    "        matched_keywords = [keyword_part for keyword_part in keyword_parts if keyword_part in text_lower]\n",
    "        matched_keywords_list.append(\" \".join(matched_keywords))\n",
    "    \n",
    "    return match_scores, matched_keywords_list\n",
    "\n",
    "# Define a list of stopwords to exclude\n",
    "stopwords = [\"is\", \"and\", \"are\"]\n",
    "\n",
    "# Load the dataset with keywords (assuming it's in a separate Excel file)\n",
    "keywords_excel_path = 'path_to_keywords_excel_file.xlsx'\n",
    "keywords_data = pd.read_excel(keywords_excel_path)\n",
    "\n",
    "# Replace 'path_to_your_excel_file.xlsx' with the actual path to your Excel file with multiple sheets\n",
    "excel_file_path = 'path_to_your_excel_file.xlsx'\n",
    "\n",
    "# Create an Excel writer to save the matched data for each sheet in a separate sheet\n",
    "output_excel_path = 'matched_output.xlsx'\n",
    "with pd.ExcelWriter(output_excel_path, engine='xlsxwriter') as writer:\n",
    "    # Iterate through sheets in the Excel file with multiple sheets\n",
    "    for sheet_name in pd.ExcelFile(excel_file_path).sheet_names:\n",
    "        # Read the data from the current sheet\n",
    "        sheet_data = pd.read_excel(excel_file_path, sheet_name)\n",
    "        \n",
    "        # Initialize an empty list to store the matched data\n",
    "        matched_data = []\n",
    "        \n",
    "        # Iterate through both datasets and match keywords with text\n",
    "        for keywords_index, keywords_row in keywords_data.iterrows():\n",
    "            name = keywords_row['name']  # Assuming 'name' is a column in the keywords Excel file\n",
    "            address = keywords_row['address']  # Assuming 'address' is a column in the keywords Excel file\n",
    "            keywords = keywords_row['keywords'].split()  # Assuming keywords are separated by space\n",
    "            \n",
    "            print(f\"Matching keywords for {name} - {address} in sheet '{sheet_name}': {keywords}\")\n",
    "            \n",
    "            for row_index, row in sheet_data.iterrows():\n",
    "                text_column = 'text_column'  # Replace with the actual column name containing text in your Excel file\n",
    "                text = row[text_column]\n",
    "                \n",
    "                # Calculate match scores and matched keywords (excluding stopwords)\n",
    "                match_scores, matched_keywords_list = calculate_match_scores_and_matched_keywords(keywords, text, stopwords)\n",
    "                \n",
    "                # Calculate the match score percentage based on the length of unique words in the original text\n",
    "                unique_words_length = len(set(text.lower().split())) if text else 0\n",
    "                match_score_percentage = int(sum(match_scores) / unique_words_length * 100) if unique_words_length > 0 else 0\n",
    "                \n",
    "                # Append the matched data to the list\n",
    "                matched_data.append({\n",
    "                    'name': name,\n",
    "                    'address': address,\n",
    "                    'keywords': keywords_row['keywords'],\n",
    "                    'original_text': text,\n",
    "                    'matched_keywords': ','.join(matched_keywords_list),\n",
    "                    'match_scores': ','.join([f'{score:.2f}' for score in match_scores]),\n",
    "                    'match_score %': match_score_percentage,  # Convert to int\n",
    "                })\n",
    "        \n",
    "        # Create a DataFrame from the matched data\n",
    "        matched_df = pd.DataFrame(matched_data)\n",
    "        \n",
    "        # Save the DataFrame to an Excel sheet for the current sheet\n",
    "        matched_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "        \n",
    "        # Display a message indicating that the data has been saved\n",
    "        print(f\"Matched data for sheet '{sheet_name}' has been saved to '{output_excel_path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb97656",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to calculate match scores and matched keywords while excluding stopwords\n",
    "def calculate_match_scores_and_matched_keywords(keywords, text, stopwords):\n",
    "    if not isinstance(text, str):\n",
    "        return [], []  # Return empty lists if the text is not a string\n",
    "    \n",
    "    # Convert both keywords and text to lowercase for case-insensitive matching\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Initialize a list to store match scores for each keyword\n",
    "    match_scores = []\n",
    "    \n",
    "    # Initialize a list to store matched keywords\n",
    "    matched_keywords_list = []\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        keyword_parts = keyword.lower().split()\n",
    "        total_parts = len(keyword_parts)\n",
    "        \n",
    "        # Filter out stopwords\n",
    "        keyword_parts = [part for part in keyword_parts if part not in stopwords]\n",
    "        \n",
    "        matched_parts = sum(keyword_part in text_lower for keyword_part in keyword_parts)\n",
    "        match_score = matched_parts / total_parts if total_parts > 0 else 0.0\n",
    "        match_scores.append(match_score)\n",
    "        \n",
    "        # Store the matched keyword (excluding stopwords)\n",
    "        matched_keywords = [keyword_part for keyword_part in keyword_parts if keyword_part in text_lower]\n",
    "        matched_keywords_list.append(\" \".join(matched_keywords))\n",
    "    \n",
    "    return match_scores, matched_keywords_list\n",
    "\n",
    "# Define a list of stopwords to exclude\n",
    "stopwords = [\"is\", \"and\", \"are\"]\n",
    "\n",
    "# Load the dataset with keywords (assuming it's in a separate Excel file)\n",
    "keywords_excel_path = 'path_to_keywords_excel_file.xlsx'\n",
    "keywords_data = pd.read_excel(keywords_excel_path)\n",
    "\n",
    "# Replace 'path_to_your_excel_file.xlsx' with the actual path to your Excel file with multiple sheets\n",
    "excel_file_path = 'path_to_your_excel_file.xlsx'\n",
    "\n",
    "# Create an Excel writer to save the matched data for each sheet in a separate sheet\n",
    "output_excel_path = 'matched_output.xlsx'\n",
    "with pd.ExcelWriter(output_excel_path, engine='xlsxwriter') as writer:\n",
    "    # Iterate through sheets in the Excel file with multiple sheets\n",
    "    for sheet_name in pd.ExcelFile(excel_file_path).sheet_names:\n",
    "        # Read the data from the current sheet\n",
    "        sheet_data = pd.read_excel(excel_file_path, sheet_name)\n",
    "        \n",
    "        # Initialize an empty list to store the matched data\n",
    "        matched_data = []\n",
    "        \n",
    "        # Iterate through both datasets and match keywords with text\n",
    "        for keywords_index, keywords_row in keywords_data.iterrows():\n",
    "            name = keywords_row['name']  # Assuming 'name' is a column in the keywords Excel file\n",
    "            address = keywords_row['address']  # Assuming 'address' is a column in the keywords Excel file\n",
    "            keywords = keywords_row['keywords'].split()  # Assuming keywords are separated by space\n",
    "            \n",
    "            print(f\"Matching keywords for {name} - {address} in sheet '{sheet_name}': {keywords}\")\n",
    "            \n",
    "            for row_index, row in sheet_data.iterrows():\n",
    "                text_column = 'text_column'  # Replace with the actual column name containing text in your Excel file\n",
    "                text = row[text_column]\n",
    "                \n",
    "                # Calculate match scores and matched keywords (excluding stopwords)\n",
    "                match_scores, matched_keywords_list = calculate_match_scores_and_matched_keywords(keywords, text, stopwords)\n",
    "                \n",
    "                # Calculate the match score percentage based on the length of unique words in the original text\n",
    "                unique_words_length = len(set(matched_keywords_list)) if matched_keywords_list else 0\n",
    "                match_score_percentage = int(unique_words_length / len(set(text.lower().split())) * 100) if text else 0\n",
    "                \n",
    "                # Append the matched data to the list\n",
    "                matched_data.append({\n",
    "                    'name': name,\n",
    "                    'address': address,\n",
    "                    'keywords': keywords_row['keywords'],\n",
    "                    'original_text': text,\n",
    "                    'matched_keywords': ','.join(matched_keywords_list),\n",
    "                    'match_scores': ','.join([f'{score:.2f}' for score in match_scores]),\n",
    "                    'match_score %': match_score_percentage,  # Convert to int\n",
    "                })\n",
    "        \n",
    "        # Create a DataFrame from the matched data\n",
    "        matched_df = pd.DataFrame(matched_data)\n",
    "        \n",
    "        # Save the DataFrame to an Excel sheet for the current sheet\n",
    "        matched_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "        \n",
    "        # Display a message indicating that the data has been saved\n",
    "        print(f\"Matched data for sheet '{sheet_name}' has been saved to '{output_excel_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d810b2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing stopwords from original text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cba74ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to calculate match scores and matched keywords while excluding stopwords\n",
    "def calculate_match_scores_and_matched_keywords(keywords, text, stopwords):\n",
    "    if not isinstance(text, str):\n",
    "        return [], []  # Return empty lists if the text is not a string\n",
    "    \n",
    "    # Convert both keywords and text to lowercase for case-insensitive matching\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Remove stopwords from the original text\n",
    "    text_parts = [part for part in text_lower.split() if part not in stopwords]\n",
    "    text_without_stopwords = \" \".join(text_parts)\n",
    "    \n",
    "    # Initialize a list to store match scores for each keyword\n",
    "    match_scores = []\n",
    "    \n",
    "    # Initialize a list to store matched keywords\n",
    "    matched_keywords_list = []\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        keyword_parts = keyword.lower().split()\n",
    "        total_parts = len(keyword_parts)\n",
    "        \n",
    "        # Filter out stopwords\n",
    "        keyword_parts = [part for part in keyword_parts if part not in stopwords]\n",
    "        \n",
    "        matched_parts = sum(keyword_part in text_without_stopwords for keyword_part in keyword_parts)\n",
    "        match_score = matched_parts / total_parts if total_parts > 0 else 0.0\n",
    "        match_scores.append(match_score)\n",
    "        \n",
    "        # Store the matched keyword (excluding stopwords)\n",
    "        matched_keywords = [keyword_part for keyword_part in keyword_parts if keyword_part in text_without_stopwords]\n",
    "        matched_keywords_list.append(\" \".join(matched_keywords))\n",
    "    \n",
    "    return match_scores, matched_keywords_list\n",
    "\n",
    "# Define a list of stopwords to exclude\n",
    "stopwords = [\"is\", \"and\", \"are\"]\n",
    "\n",
    "# Load the dataset with keywords (assuming it's in a separate Excel file)\n",
    "keywords_excel_path = 'path_to_keywords_excel_file.xlsx'\n",
    "keywords_data = pd.read_excel(keywords_excel_path)\n",
    "\n",
    "# Replace 'path_to_your_excel_file.xlsx' with the actual path to your Excel file with multiple sheets\n",
    "excel_file_path = 'path_to_your_excel_file.xlsx'\n",
    "\n",
    "# Create an Excel writer to save the matched data for each sheet in a separate sheet\n",
    "output_excel_path = 'matched_output.xlsx'\n",
    "with pd.ExcelWriter(output_excel_path, engine='xlsxwriter') as writer:\n",
    "    # Iterate through sheets in the Excel file with multiple sheets\n",
    "    for sheet_name in pd.ExcelFile(excel_file_path).sheet_names:\n",
    "        # Read the data from the current sheet\n",
    "        sheet_data = pd.read_excel(excel_file_path, sheet_name)\n",
    "        \n",
    "        # Initialize an empty list to store the matched data\n",
    "        matched_data = []\n",
    "        \n",
    "        # Iterate through both datasets and match keywords with text\n",
    "        for keywords_index, keywords_row in keywords_data.iterrows():\n",
    "            name = keywords_row['name']  # Assuming 'name' is a column in the keywords Excel file\n",
    "            address = keywords_row['address']  # Assuming 'address' is a column in the keywords Excel file\n",
    "            keywords = keywords_row['keywords'].split()  # Assuming keywords are separated by space\n",
    "            \n",
    "            print(f\"Matching keywords for {name} - {address} in sheet '{sheet_name}': {keywords}\")\n",
    "            \n",
    "            for row_index, row in sheet_data.iterrows():\n",
    "                text_column = 'text_column'  # Replace with the actual column name containing text in your Excel file\n",
    "                text = row[text_column]\n",
    "                \n",
    "                # Calculate match scores and matched keywords (excluding stopwords)\n",
    "                match_scores, matched_keywords_list = calculate_match_scores_and_matched_keywords(keywords, text, stopwords)\n",
    "                \n",
    "                # Calculate the match score percentage based on the length of the original text\n",
    "                match_score_percentage = int(sum(match_scores) / len(text_without_stopwords.split()) * 100) if text_without_stopwords else 0\n",
    "                \n",
    "                # Append the matched data to the list\n",
    "                matched_data.append({\n",
    "                    'name': name,\n",
    "                    'address': address,\n",
    "                    'keywords': keywords_row['keywords'],\n",
    "                    'original_text': text_without_stopwords,\n",
    "                    'matched_keywords': ','.join(matched_keywords_list),\n",
    "                    'match_scores': ','.join([f'{score:.2f}' for score in match_scores]),\n",
    "                    'match_score %': match_score_percentage,  # Convert to int\n",
    "                })\n",
    "        \n",
    "        # Create a DataFrame from the matched data\n",
    "        matched_df = pd.DataFrame(matched_data)\n",
    "        \n",
    "        # Save the DataFrame to an Excel sheet for the current sheet\n",
    "        matched_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "        \n",
    "        # Display a message indicating that the data has been saved\n",
    "        print(f\"Matched data for sheet '{sheet_name}' has been saved to '{output_excel_path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dbdbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to calculate match scores and matched keywords while excluding stopwords\n",
    "def calculate_match_scores_and_matched_keywords(keywords, text, stopwords):\n",
    "    if not isinstance(text, str):\n",
    "        return [], []  # Return empty lists if the text is not a string\n",
    "    \n",
    "    # Convert both keywords and text to lowercase for case-insensitive matching\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Remove stopwords from the original text\n",
    "    text_parts = [part for part in text_lower.split() if part not in stopwords]\n",
    "    text_without_stopwords = \" \".join(text_parts)\n",
    "    \n",
    "    # Initialize a list to store match scores for each keyword\n",
    "    match_scores = []\n",
    "    \n",
    "    # Initialize a list to store matched keywords\n",
    "    matched_keywords_list = []\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        keyword_parts = keyword.lower().split()\n",
    "        total_parts = len(keyword_parts)\n",
    "        \n",
    "        # Filter out stopwords\n",
    "        keyword_parts = [part for part in keyword_parts if part not in stopwords]\n",
    "        \n",
    "        matched_parts = sum(keyword_part in text_without_stopwords for keyword_part in keyword_parts)\n",
    "        match_score = matched_parts / total_parts if total_parts > 0 else 0.0\n",
    "        match_scores.append(match_score)\n",
    "        \n",
    "        # Store the matched keyword (excluding stopwords)\n",
    "        matched_keywords = [keyword_part for keyword_part in keyword_parts if keyword_part in text_without_stopwords]\n",
    "        matched_keywords_list.append(\" \".join(matched_keywords))\n",
    "    \n",
    "    return match_scores, matched_keywords_list, text_without_stopwords\n",
    "\n",
    "# Define a list of stopwords to exclude\n",
    "stopwords = [\"is\", \"and\", \"are\"]\n",
    "\n",
    "# Load the dataset with keywords (assuming it's in a separate Excel file)\n",
    "keywords_excel_path = 'path_to_keywords_excel_file.xlsx'\n",
    "keywords_data = pd.read_excel(keywords_excel_path)\n",
    "\n",
    "# Replace 'path_to_your_excel_file.xlsx' with the actual path to your Excel file with multiple sheets\n",
    "excel_file_path = 'path_to_your_excel_file.xlsx'\n",
    "\n",
    "# Create an Excel writer to save the matched data for each sheet in a separate sheet\n",
    "output_excel_path = 'matched_output.xlsx'\n",
    "with pd.ExcelWriter(output_excel_path, engine='xlsxwriter') as writer:\n",
    "    # Iterate through sheets in the Excel file with multiple sheets\n",
    "    for sheet_name in pd.ExcelFile(excel_file_path).sheet_names:\n",
    "        # Read the data from the current sheet\n",
    "        sheet_data = pd.read_excel(excel_file_path, sheet_name)\n",
    "        \n",
    "        # Initialize an empty list to store the matched data\n",
    "        matched_data = []\n",
    "        \n",
    "        # Iterate through both datasets and match keywords with text\n",
    "        for keywords_index, keywords_row in keywords_data.iterrows():\n",
    "            name = keywords_row['name']  # Assuming 'name' is a column in the keywords Excel file\n",
    "            address = keywords_row['address']  # Assuming 'address' is a column in the keywords Excel file\n",
    "            keywords = keywords_row['keywords'].split()  # Assuming keywords are separated by space\n",
    "            \n",
    "            print(f\"Matching keywords for {name} - {address} in sheet '{sheet_name}': {keywords}\")\n",
    "            \n",
    "            for row_index, row in sheet_data.iterrows():\n",
    "                text_column = 'text_column'  # Replace with the actual column name containing text in your Excel file\n",
    "                text = row[text_column]\n",
    "                \n",
    "                # Calculate match scores, matched keywords, and remove stopwords from the original text\n",
    "                match_scores, matched_keywords_list, text_without_stopwords = calculate_match_scores_and_matched_keywords(keywords, text, stopwords)\n",
    "                \n",
    "                # Calculate the match score percentage based on the length of the original text\n",
    "                match_score_percentage = int(sum(match_scores) / len(text_without_stopwords.split()) * 100) if text_without_stopwords else 0\n",
    "                \n",
    "                # Append the matched data to the list\n",
    "                matched_data.append({\n",
    "                    'name': name,\n",
    "                    'address': address,\n",
    "                    'keywords': keywords_row['keywords'],\n",
    "                    'original_text': text_without_stopwords,\n",
    "                    'matched_keywords': ','.join(matched_keywords_list),\n",
    "                    'match_scores': ','.join([f'{score:.2f}' for score in match_scores]),\n",
    "                    'match_score %': match_score_percentage,  # Convert to int\n",
    "                })\n",
    "        \n",
    "        # Create a DataFrame from the matched data\n",
    "        matched_df = pd.DataFrame(matched_data)\n",
    "        \n",
    "        # Save the DataFrame to an Excel sheet for the current sheet\n",
    "        matched_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "        \n",
    "        # Display a message indicating that the data has been saved\n",
    "        print(f\"Matched data for sheet '{sheet_name}' has been saved to '{output_excel_path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202ec354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to calculate match scores and matched keywords while excluding stopwords\n",
    "def calculate_match_scores_and_matched_keywords(keywords, text, stopwords):\n",
    "    if not isinstance(text, str):\n",
    "        return 0, []  # Return 0 if the text is not a string\n",
    "    \n",
    "    # Convert both keywords and text to lowercase for case-insensitive matching\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Remove stopwords from the original text\n",
    "    text_parts = [part for part in text_lower.split() if part not in stopwords]\n",
    "    text_without_stopwords = \" \".join(text_parts)\n",
    "    \n",
    "    # Convert both keywords to lowercase for case-insensitive matching\n",
    "    keywords_lower = [keyword.lower() for keyword in keywords]\n",
    "    \n",
    "    # Filter out stopwords from keywords\n",
    "    keywords_without_stopwords = [keyword for keyword in keywords_lower if keyword not in stopwords]\n",
    "    \n",
    "    # Count the unique matched keywords\n",
    "    unique_matched_keywords = set(keyword for keyword in keywords_without_stopwords if keyword in text_without_stopwords)\n",
    "    \n",
    "    # Calculate the match score percentage based on the count of unique matched keywords\n",
    "    match_score_percentage = len(unique_matched_keywords) / len(set(text_without_stopwords.split())) if text_without_stopwords else 0\n",
    "    \n",
    "    return match_score_percentage, list(unique_matched_keywords)\n",
    "\n",
    "# Define a list of stopwords to exclude\n",
    "stopwords = [\"is\", \"and\", \"are\"]\n",
    "\n",
    "# Load the dataset with keywords (assuming it's in a separate Excel file)\n",
    "keywords_excel_path = 'path_to_keywords_excel_file.xlsx'\n",
    "keywords_data = pd.read_excel(keywords_excel_path)\n",
    "\n",
    "# Replace 'path_to_your_excel_file.xlsx' with the actual path to your Excel file with multiple sheets\n",
    "excel_file_path = 'path_to_your_excel_file.xlsx'\n",
    "\n",
    "# Create an Excel writer to save the matched data for each sheet in a separate sheet\n",
    "output_excel_path = 'matched_output.xlsx'\n",
    "with pd.ExcelWriter(output_excel_path, engine='xlsxwriter') as writer:\n",
    "    # Iterate through sheets in the Excel file with multiple sheets\n",
    "    for sheet_name in pd.ExcelFile(excel_file_path).sheet_names:\n",
    "        # Read the data from the current sheet\n",
    "        sheet_data = pd.read_excel(excel_file_path, sheet_name)\n",
    "        \n",
    "        # Initialize an empty list to store the matched data\n",
    "        matched_data = []\n",
    "        \n",
    "        # Iterate through both datasets and match keywords with text\n",
    "        for keywords_index, keywords_row in keywords_data.iterrows():\n",
    "            name = keywords_row['name']  # Assuming 'name' is a column in the keywords Excel file\n",
    "            address = keywords_row['address']  # Assuming 'address' is a column in the keywords Excel file\n",
    "            keywords = keywords_row['keywords'].split()  # Assuming keywords are separated by space\n",
    "            \n",
    "            print(f\"Matching keywords for {name} - {address} in sheet '{sheet_name}': {keywords}\")\n",
    "            \n",
    "            for row_index, row in sheet_data.iterrows():\n",
    "                text_column = 'text_column'  # Replace with the actual column name containing text in your Excel file\n",
    "                text = row[text_column]\n",
    "                \n",
    "                # Calculate match score percentage and unique matched keywords\n",
    "                match_score_percentage, unique_matched_keywords = calculate_match_scores_and_matched_keywords(keywords, text, stopwords)\n",
    "                \n",
    "                # Append the matched data to the list\n",
    "                matched_data.append({\n",
    "                    'name': name,\n",
    "                    'address': address,\n",
    "                    'keywords': keywords_row['keywords'],\n",
    "                    'original_text': text,\n",
    "                    'matched_keywords': ','.join(unique_matched_keywords),\n",
    "                    'match_score %': match_score_percentage,  # This is the match score percentage\n",
    "                })\n",
    "        \n",
    "        # Create a DataFrame from the matched data\n",
    "        matched_df = pd.DataFrame(matched_data)\n",
    "        \n",
    "        # Save the DataFrame to an Excel sheet for the current sheet\n",
    "        matched_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "        \n",
    "        # Display a message indicating that the data has been saved\n",
    "        print(f\"Matched data for sheet '{sheet_name}' has been saved to '{output_excel_path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce78ec3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to calculate match scores and matched keywords while excluding stopwords\n",
    "def calculate_match_scores_and_matched_keywords(keywords, text, stopwords):\n",
    "    if not isinstance(text, str):\n",
    "        return 0, []  # Return 0 if the text is not a string\n",
    "    \n",
    "    # Convert both keywords and text to lowercase for case-insensitive matching\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Remove stopwords from the original text\n",
    "    text_parts = [part for part in text_lower.split() if part not in stopwords]\n",
    "    text_without_stopwords = \" \".join(text_parts)\n",
    "    \n",
    "    # Convert both keywords to lowercase for case-insensitive matching\n",
    "    keywords_lower = [keyword.lower() for keyword in keywords]\n",
    "    \n",
    "    # Filter out stopwords from keywords\n",
    "    keywords_without_stopwords = [keyword for keyword in keywords_lower if keyword not in stopwords]\n",
    "    \n",
    "    # Find the unique matched keywords\n",
    "    unique_matched_keywords = set(keyword for keyword in keywords_without_stopwords if keyword in text_without_stopwords)\n",
    "    \n",
    "    # Calculate the match score percentage based on the count of unique matched keywords\n",
    "    match_score_percentage = len(unique_matched_keywords) / len(set(text_without_stopwords.split())) if text_without_stopwords else 0\n",
    "    \n",
    "    return match_score_percentage, list(unique_matched_keywords)\n",
    "\n",
    "# Define a list of stopwords to exclude\n",
    "stopwords = [\"is\", \"and\", \"are\"]\n",
    "\n",
    "# Load the dataset with keywords (assuming it's in a separate Excel file)\n",
    "keywords_excel_path = 'path_to_keywords_excel_file.xlsx'\n",
    "keywords_data = pd.read_excel(keywords_excel_path)\n",
    "\n",
    "# Replace 'path_to_your_excel_file.xlsx' with the actual path to your Excel file with multiple sheets\n",
    "excel_file_path = 'path_to_your_excel_file.xlsx'\n",
    "\n",
    "# Create an Excel writer to save the matched data for each sheet in a separate sheet\n",
    "output_excel_path = 'matched_output.xlsx'\n",
    "with pd.ExcelWriter(output_excel_path, engine='xlsxwriter') as writer:\n",
    "    # Iterate through sheets in the Excel file with multiple sheets\n",
    "    for sheet_name in pd.ExcelFile(excel_file_path).sheet_names:\n",
    "        # Read the data from the current sheet\n",
    "        sheet_data = pd.read_excel(excel_file_path, sheet_name)\n",
    "        \n",
    "        # Initialize an empty list to store the matched data\n",
    "        matched_data = []\n",
    "        \n",
    "        # Iterate through both datasets and match keywords with text\n",
    "        for keywords_index, keywords_row in keywords_data.iterrows():\n",
    "            name = keywords_row['name']  # Assuming 'name' is a column in the keywords Excel file\n",
    "            address = keywords_row['address']  # Assuming 'address' is a column in the keywords Excel file\n",
    "            keywords = keywords_row['keywords'].split()  # Assuming keywords are separated by space\n",
    "            \n",
    "            print(f\"Matching keywords for {name} - {address} in sheet '{sheet_name}': {keywords}\")\n",
    "            \n",
    "            for row_index, row in sheet_data.iterrows():\n",
    "                text_column = 'text_column'  # Replace with the actual column name containing text in your Excel file\n",
    "                text = row[text_column]\n",
    "                \n",
    "                # Calculate match score percentage and unique matched keywords\n",
    "                match_score_percentage, unique_matched_keywords = calculate_match_scores_and_matched_keywords(keywords, text, stopwords)\n",
    "                \n",
    "                # Append the matched data to the list\n",
    "                matched_data.append({\n",
    "                    'name': name,\n",
    "                    'address': address,\n",
    "                    'keywords': keywords_row['keywords'],\n",
    "                    'original_text': text,\n",
    "                    'matched_keywords': ', '.join(unique_matched_keywords),\n",
    "                    'match_score %': match_score_percentage,  # This is the match score percentage\n",
    "                })\n",
    "        \n",
    "        # Create a DataFrame from the matched data\n",
    "        matched_df = pd.DataFrame(matched_data)\n",
    "        \n",
    "        # Save the DataFrame to an Excel sheet for the current sheet\n",
    "        matched_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "        \n",
    "        # Display a message indicating that the data has been saved\n",
    "        print(f\"Matched data for sheet '{sheet_name}' has been saved to '{output_excel_path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f939bec4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77123fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to calculate match scores and matched keywords while excluding stopwords\n",
    "def calculate_match_scores_and_matched_keywords(keywords, text, stopwords):\n",
    "    if not isinstance(text, str):\n",
    "        return 0, []  # Return 0 if the text is not a string\n",
    "    \n",
    "    # Convert both keywords and text to lowercase for case-insensitive matching\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Remove stopwords from the original text\n",
    "    text_parts = [part for part in text_lower.split() if part not in stopwords]\n",
    "    text_without_stopwords = \" \".join(text_parts)\n",
    "    \n",
    "    # Convert both keywords to lowercase for case-insensitive matching\n",
    "    keywords_lower = [keyword.lower() for keyword in keywords]\n",
    "    \n",
    "    # Filter out stopwords from keywords\n",
    "    keywords_without_stopwords = [keyword for keyword in keywords_lower if keyword not in stopwords]\n",
    "    \n",
    "    # Find the unique matched keywords\n",
    "    unique_matched_keywords = set(keyword for keyword in keywords_without_stopwords if keyword in text_without_stopwords)\n",
    "    \n",
    "    # Calculate the match score percentage based on the count of unique matched keywords\n",
    "    match_score_percentage = len(unique_matched_keywords) / len(set(text_without_stopwords.split())) if text_without_stopwords else 0\n",
    "    \n",
    "    return match_score_percentage, list(unique_matched_keywords)\n",
    "\n",
    "# Define a list of stopwords to exclude\n",
    "stopwords = [\"is\", \"and\", \"are\"]\n",
    "\n",
    "# Load the dataset with keywords (assuming it's in a separate Excel file)\n",
    "keywords_excel_path = 'path_to_keywords_excel_file.xlsx'\n",
    "keywords_data = pd.read_excel(keywords_excel_path)\n",
    "\n",
    "# Replace 'path_to_your_excel_file.xlsx' with the actual path to your Excel file with multiple sheets\n",
    "excel_file_path = 'path_to_your_excel_file.xlsx'\n",
    "\n",
    "# Create an Excel writer to save the matched data for each sheet in a separate sheet\n",
    "output_excel_path = 'matched_output.xlsx'\n",
    "with pd.ExcelWriter(output_excel_path, engine='xlsxwriter') as writer:\n",
    "    # Iterate through sheets in the Excel file with multiple sheets\n",
    "    for sheet_name in pd.ExcelFile(excel_file_path).sheet_names:\n",
    "        # Read the data from the current sheet\n",
    "        sheet_data = pd.read_excel(excel_file_path, sheet_name)\n",
    "        \n",
    "        # Initialize an empty list to store the matched data\n",
    "        matched_data = []\n",
    "        \n",
    "        # Iterate through both datasets and match keywords with text\n",
    "        for keywords_index, keywords_row in keywords_data.iterrows():\n",
    "            name = keywords_row['name']  # Assuming 'name' is a column in the keywords Excel file\n",
    "            address = keywords_row['address']  # Assuming 'address' is a column in the keywords Excel file\n",
    "            keywords = keywords_row['keywords'].split()  # Assuming keywords are separated by space\n",
    "            \n",
    "            print(f\"Matching keywords for {name} - {address} in sheet '{sheet_name}': {keywords}\")\n",
    "            \n",
    "            for row_index, row in sheet_data.iterrows():\n",
    "                text_column = 'text_column'  # Replace with the actual column name containing text in your Excel file\n",
    "                text = row[text_column]\n",
    "                \n",
    "                # Calculate match score percentage and unique matched keywords\n",
    "                match_score_percentage, unique_matched_keywords = calculate_match_scores_and_matched_keywords(keywords, text, stopwords)\n",
    "                \n",
    "                # Append the matched data to the list\n",
    "                matched_data.append({\n",
    "                    'name': name,\n",
    "                    'address': address,\n",
    "                    'keywords': keywords_row['keywords'],\n",
    "                    'original_text': text,\n",
    "                    'matched_keywords': ', '.join(unique_matched_keywords),\n",
    "                    'match_score %': match_score_percentage,  # This is the match score percentage\n",
    "                })\n",
    "        \n",
    "        # Create a DataFrame from the matched data\n",
    "        matched_df = pd.DataFrame(matched_data)\n",
    "        \n",
    "        # Save the DataFrame to an Excel sheet for the current sheet\n",
    "        matched_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "        \n",
    "        # Display a message indicating that the data has been saved\n",
    "        print(f\"Matched data for sheet '{sheet_name}' has been saved to '{output_excel_path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5a278e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to calculate match scores and matched keywords while excluding stopwords\n",
    "def calculate_match_scores_and_matched_keywords(keywords, text, stopwords):\n",
    "    if not isinstance(text, str):\n",
    "        return 0, []  # Return 0 if the text is not a string\n",
    "    \n",
    "    # Convert both keywords and text to lowercase for case-insensitive matching\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Remove stopwords from the original text\n",
    "    text_parts = [part for part in text_lower.split() if part not in stopwords]\n",
    "    text_without_stopwords = \" \".join(text_parts)\n",
    "    \n",
    "    # Convert both keywords to lowercase for case-insensitive matching\n",
    "    keywords_lower = [keyword.lower() for keyword in keywords]\n",
    "    \n",
    "    # Filter out stopwords from keywords\n",
    "    keywords_without_stopwords = [keyword for keyword in keywords_lower if keyword not in stopwords]\n",
    "    \n",
    "    # Find the unique matched keywords\n",
    "    matched_keywords = [keyword for keyword in keywords_without_stopwords if keyword in text_without_stopwords]\n",
    "    \n",
    "    # Calculate the match score percentage based on the count of unique matched keywords\n",
    "    match_score_percentage = len(set(matched_keywords)) / len(set(text_without_stopwords.split())) if text_without_stopwords else 0\n",
    "    \n",
    "    return match_score_percentage, matched_keywords\n",
    "\n",
    "# Define a list of stopwords to exclude\n",
    "stopwords = [\"is\", \"and\", \"are\"]\n",
    "\n",
    "# Load the dataset with keywords (assuming it's in a separate Excel file)\n",
    "keywords_excel_path = 'path_to_keywords_excel_file.xlsx'\n",
    "keywords_data = pd.read_excel(keywords_excel_path)\n",
    "\n",
    "# Replace 'path_to_your_excel_file.xlsx' with the actual path to your Excel file with multiple sheets\n",
    "excel_file_path = 'path_to_your_excel_file.xlsx'\n",
    "\n",
    "# Create an Excel writer to save the matched data for each sheet in a separate sheet\n",
    "output_excel_path = 'matched_output.xlsx'\n",
    "with pd.ExcelWriter(output_excel_path, engine='xlsxwriter') as writer:\n",
    "    # Iterate through sheets in the Excel file with multiple sheets\n",
    "    for sheet_name in pd.ExcelFile(excel_file_path).sheet_names:\n",
    "        # Read the data from the current sheet\n",
    "        sheet_data = pd.read_excel(excel_file_path, sheet_name)\n",
    "        \n",
    "        # Initialize an empty list to store the matched data\n",
    "        matched_data = []\n",
    "        \n",
    "        # Iterate through both datasets and match keywords with text\n",
    "        for keywords_index, keywords_row in keywords_data.iterrows():\n",
    "            name = keywords_row['name']  # Assuming 'name' is a column in the keywords Excel file\n",
    "            address = keywords_row['address']  # Assuming 'address' is a column in the keywords Excel file\n",
    "            keywords = keywords_row['keywords'].split()  # Assuming keywords are separated by space\n",
    "            \n",
    "            print(f\"Matching keywords for {name} - {address} in sheet '{sheet_name}': {keywords}\")\n",
    "            \n",
    "            for row_index, row in sheet_data.iterrows():\n",
    "                text_column = 'text_column'  # Replace with the actual column name containing text in your Excel file\n",
    "                text = row[text_column]\n",
    "                \n",
    "                # Calculate match score percentage and matched keywords\n",
    "                match_score_percentage, matched_keywords = calculate_match_scores_and_matched_keywords(keywords, text, stopwords)\n",
    "                \n",
    "                # Append the matched data to the list\n",
    "                matched_data.append({\n",
    "                    'name': name,\n",
    "                    'address': address,\n",
    "                    'keywords': keywords_row['keywords'],\n",
    "                    'original_text': text,\n",
    "                    'matched_keywords': ', '.join(matched_keywords),\n",
    "                    'match_score %': match_score_percentage,  # This is the match score percentage\n",
    "                })\n",
    "        \n",
    "        # Create a DataFrame from the matched data\n",
    "        matched_df = pd.DataFrame(matched_data)\n",
    "        \n",
    "        # Save the DataFrame to an Excel sheet for the current sheet\n",
    "        matched_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "        \n",
    "        # Display a message indicating that the data has been saved\n",
    "        print(f\"Matched data for sheet '{sheet_name}' has been saved to '{output_excel_path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03613439",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca2c487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate match scores and matched keywords while excluding stopwords\n",
    "def calculate_match_scores_and_matched_keywords(keywords, text, stopwords):\n",
    "    if not isinstance(text, str):\n",
    "        return 0, ''  # Return 0 if the text is not a string\n",
    "    \n",
    "    # Convert both keywords and text to lowercase for case-insensitive matching\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Remove stopwords from the original text\n",
    "    text_parts = [part for part in text_lower.split() if part not in stopwords]\n",
    "    text_without_stopwords = \" \".join(text_parts)\n",
    "    \n",
    "    # Convert both keywords to lowercase for case-insensitive matching\n",
    "    keywords_lower = [keyword.lower() for keyword in keywords]\n",
    "    \n",
    "    # Filter out stopwords from keywords\n",
    "    keywords_without_stopwords = [keyword for keyword in keywords_lower if keyword not in stopwords]\n",
    "    \n",
    "    # Find the matched keywords\n",
    "    matched_keywords = [keyword for keyword in keywords_without_stopwords if keyword in text_without_stopwords]\n",
    "    \n",
    "    # Calculate the match score percentage based on the count of unique matched keywords\n",
    "    match_score_percentage = len(set(matched_keywords)) / len(set(text_without_stopwords.split())) if text_without_stopwords else 0\n",
    "    \n",
    "    return match_score_percentage, ', '.join(matched_keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e908a4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to calculate match scores and matched keywords while excluding stopwords\n",
    "def calculate_match_scores_and_matched_keywords(keywords, text, stopwords):\n",
    "    if not isinstance(text, str):\n",
    "        return 0, ''  # Return 0 if the text is not a string\n",
    "    \n",
    "    # Convert both keywords and text to lowercase for case-insensitive matching\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Remove stopwords from the original text\n",
    "    text_parts = [part for part in text_lower.split() if part not in stopwords]\n",
    "    text_without_stopwords = \" \".join(text_parts)\n",
    "    \n",
    "    # Convert both keywords to lowercase for case-insensitive matching\n",
    "    keywords_lower = [keyword.lower() for keyword in keywords]\n",
    "    \n",
    "    # Filter out stopwords from keywords\n",
    "    keywords_without_stopwords = [keyword for keyword in keywords_lower if keyword not in stopwords]\n",
    "    \n",
    "    # Find the matched keywords\n",
    "    matched_keywords = [keyword for keyword in keywords_without_stopwords if keyword in text_without_stopwords]\n",
    "    \n",
    "    # Calculate the match score percentage based on the count of unique matched keywords\n",
    "    match_score_percentage = len(set(matched_keywords)) / len(set(text_without_stopwords.split())) if text_without_stopwords else 0\n",
    "    \n",
    "    return match_score_percentage, ', '.join(matched_keywords)\n",
    "\n",
    "# Define a list of stopwords to exclude\n",
    "stopwords = [\"is\", \"and\", \"are\"]\n",
    "\n",
    "# Load the dataset with keywords (assuming it's in a separate Excel file)\n",
    "keywords_excel_path = 'path_to_keywords_excel_file.xlsx'\n",
    "keywords_data = pd.read_excel(keywords_excel_path)\n",
    "\n",
    "# Replace 'path_to_your_excel_file.xlsx' with the actual path to your Excel file with multiple sheets\n",
    "excel_file_path = 'path_to_your_excel_file.xlsx'\n",
    "\n",
    "# Create an Excel writer to save the matched data for each sheet in a separate sheet\n",
    "output_excel_path = 'matched_output.xlsx'\n",
    "with pd.ExcelWriter(output_excel_path, engine='xlsxwriter') as writer:\n",
    "    # Iterate through sheets in the Excel file with multiple sheets\n",
    "    for sheet_name in pd.ExcelFile(excel_file_path).sheet_names:\n",
    "        # Read the data from the current sheet\n",
    "        sheet_data = pd.read_excel(excel_file_path, sheet_name)\n",
    "        \n",
    "        # Initialize an empty list to store the matched data\n",
    "        matched_data = []\n",
    "        \n",
    "        # Iterate through both datasets and match keywords with text\n",
    "        for keywords_index, keywords_row in keywords_data.iterrows():\n",
    "            name = keywords_row['name']  # Assuming 'name' is a column in the keywords Excel file\n",
    "            address = keywords_row['address']  # Assuming 'address' is a column in the keywords Excel file\n",
    "            keywords = keywords_row['keywords'].split()  # Assuming keywords are separated by space\n",
    "            \n",
    "            print(f\"Matching keywords for {name} - {address} in sheet '{sheet_name}': {keywords}\")\n",
    "            \n",
    "            for row_index, row in sheet_data.iterrows():\n",
    "                text_column = 'text_column'  # Replace with the actual column name containing text in your Excel file\n",
    "                text = row[text_column]\n",
    "                \n",
    "                # Calculate match score percentage and matched keywords\n",
    "                match_score_percentage, matched_keywords = calculate_match_scores_and_matched_keywords(keywords, text, stopwords)\n",
    "                \n",
    "                # Append the matched data to the list\n",
    "                matched_data.append({\n",
    "                    'name': name,\n",
    "                    'address': address,\n",
    "                    'keywords': keywords_row['keywords'],\n",
    "                    'original_text': text,\n",
    "                    'matched_keywords': matched_keywords,\n",
    "                    'match_score %': match_score_percentage,  # This is the match score percentage\n",
    "                })\n",
    "        \n",
    "        # Create a DataFrame from the matched data\n",
    "        matched_df = pd.DataFrame(matched_data)\n",
    "        \n",
    "        # Save the DataFrame to an Excel sheet for the current sheet\n",
    "        matched_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "        \n",
    "        # Display a message indicating that the data has been saved\n",
    "        print(f\"Matched data for sheet '{sheet_name}' has been saved to '{output_excel_path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9414a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c5f9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to calculate match scores and matched keywords while excluding stopwords\n",
    "def calculate_match_scores_and_matched_keywords(keywords, text, stopwords):\n",
    "    if not isinstance(text, str):\n",
    "        return 0, ''  # Return 0 if the text is not a string\n",
    "    \n",
    "    # Convert both keywords and text to lowercase for case-insensitive matching\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Remove stopwords from the original text\n",
    "    text_parts = [part for part in text_lower.split() if part not in stopwords]\n",
    "    text_without_stopwords = \" \".join(text_parts)\n",
    "    \n",
    "    # Convert both keywords to lowercase for case-insensitive matching\n",
    "    keywords_lower = [keyword.lower() for keyword in keywords]\n",
    "    \n",
    "    # Filter out stopwords from keywords\n",
    "    keywords_without_stopwords = [keyword for keyword in keywords_lower if keyword not in stopwords]\n",
    "    \n",
    "    # Find the matched keywords\n",
    "    matched_keywords = [keyword for keyword in keywords_without_stopwords if keyword in text_without_stopwords]\n",
    "    \n",
    "    # Calculate the match score percentage based on the count of unique matched keywords\n",
    "    match_score_percentage = len(set(matched_keywords)) / len(set(text_without_stopwords.split())) if text_without_stopwords else 0\n",
    "    \n",
    "    return match_score_percentage, ', '.join(matched_keywords)\n",
    "\n",
    "# Define a list of stopwords to exclude\n",
    "stopwords = [\"is\", \"and\", \"are\"]\n",
    "\n",
    "# Load the dataset with keywords (assuming it's in a separate Excel file)\n",
    "keywords_excel_path = 'path_to_keywords_excel_file.xlsx'\n",
    "keywords_data = pd.read_excel(keywords_excel_path)\n",
    "\n",
    "# Replace 'path_to_your_excel_file.xlsx' with the actual path to your Excel file with multiple sheets\n",
    "excel_file_path = 'path_to_your_excel_file.xlsx'\n",
    "\n",
    "# Create an Excel writer to save the matched data for each sheet in a separate sheet\n",
    "output_excel_path = 'matched_output.xlsx'\n",
    "with pd.ExcelWriter(output_excel_path, engine='xlsxwriter') as writer:\n",
    "    # Iterate through sheets in the Excel file with multiple sheets\n",
    "    for sheet_name in pd.ExcelFile(excel_file_path).sheet_names:\n",
    "        # Read the data from the current sheet\n",
    "        sheet_data = pd.read_excel(excel_file_path, sheet_name)\n",
    "        \n",
    "        # Initialize an empty list to store the matched data\n",
    "        matched_data = []\n",
    "        \n",
    "        # Iterate through both datasets and match keywords with text\n",
    "        for keywords_index, keywords_row in keywords_data.iterrows():\n",
    "            name = keywords_row['name']  # Assuming 'name' is a column in the keywords Excel file\n",
    "            address = keywords_row['address']  # Assuming 'address' is a column in the keywords Excel file\n",
    "            keywords = keywords_row['keywords'].split()  # Assuming keywords are separated by space\n",
    "            \n",
    "            print(f\"Matching keywords for {name} - {address} in sheet '{sheet_name}': {keywords}\")\n",
    "            \n",
    "            for row_index, row in sheet_data.iterrows():\n",
    "                text_column = 'text_column'  # Replace with the actual column name containing text in your Excel file\n",
    "                text = row[text_column]\n",
    "                \n",
    "                # Calculate match score percentage and matched keywords\n",
    "                match_score_percentage, matched_keywords = calculate_match_scores_and_matched_keywords(keywords, text, stopwords)\n",
    "                \n",
    "                # Add the \"horizontal\" column value from the current row in sheet_data\n",
    "                horizontal_value = row['horizontal']  # Replace 'horizontal' with the actual column name in your Excel file\n",
    "                \n",
    "                # Append the matched data to the list\n",
    "                matched_data.append({\n",
    "                    'name': name,\n",
    "                    'address': address,\n",
    "                    'keywords': keywords_row['keywords'],\n",
    "                    'original_text': text,\n",
    "                    'matched_keywords': matched_keywords,\n",
    "                    'match_score %': match_score_percentage,  # This is the match score percentage\n",
    "                    'horizontal': horizontal_value,  # Adding the \"horizontal\" column\n",
    "                })\n",
    "        \n",
    "        # Create a DataFrame from the matched data\n",
    "        matched_df = pd.DataFrame(matched_data)\n",
    "        \n",
    "        # Save the DataFrame to an Excel sheet for the current sheet\n",
    "        matched_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "        \n",
    "        # Display a message indicating that the data has been saved\n",
    "        print(f\"Matched data for sheet '{sheet_name}' has been saved to '{output_excel_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dff3b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pytesseract\n",
    "from openpyxl import Workbook\n",
    "import os\n",
    "\n",
    "screenshot_folder = 'path/to/screenshots'\n",
    "\n",
    "def extract_data_from_screenshot(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    text = pytesseract.image_to_string(image)\n",
    "\n",
    "    # Extract data based on specific patterns or keywords\n",
    "    name = extract_field(text, \"Name:\")\n",
    "    username = extract_field(text, \"Username:\")\n",
    "    siterole = extract_field(text, \"Siterole:\")\n",
    "    domain = extract_field(text, \"Domain:\")\n",
    "    organization = extract_field(text, \"Organization:\")\n",
    "\n",
    "    return {'Name': name, 'Username': username, 'Siterole': siterole, 'Domain': domain, 'Organization': organization}\n",
    "\n",
    "def extract_field(text, field_name):\n",
    "    # Example: Extract the field value following the field name\n",
    "    start_index = text.find(field_name)\n",
    "    if start_index != -1:\n",
    "        start_index += len(field_name)\n",
    "        end_index = text.find('\\n', start_index)\n",
    "        if end_index != -1:\n",
    "            return text[start_index:end_index].strip()\n",
    "\n",
    "    return None\n",
    "\n",
    "screenshot_files = os.listdir(screenshot_folder)\n",
    "\n",
    "extracted_data = []\n",
    "for file in screenshot_files:\n",
    "    if file.endswith('.png') or file.endswith('.jpg'):\n",
    "        image_path = os.path.join(screenshot_folder, file)\n",
    "        data = extract_data_from_screenshot(image_path)\n",
    "        data['File'] = file  # Add the file name to the extracted data\n",
    "        extracted_data.append(data)\n",
    "\n",
    "# Create Excel workbook\n",
    "workbook = Workbook()\n",
    "sheet = workbook.active\n",
    "\n",
    "# Write headers\n",
    "headers = ['File', 'Name', 'Username', 'Siterole', 'Domain', 'Organization']\n",
    "for col_idx, header in enumerate(headers, start=1):\n",
    "    sheet.cell(row=1, column=col_idx, value=header)\n",
    "\n",
    "# Write data\n",
    "for row_idx, data in enumerate(extracted_data, start=2):\n",
    "    sheet.cell(row=row_idx, column=1, value=data['File'])\n",
    "    sheet.cell(row=row_idx, column=2, value=data['Name'])\n",
    "    sheet.cell(row=row_idx, column=3, value=data['Username'])\n",
    "    sheet.cell(row=row_idx, column=4, value=data['Siterole'])\n",
    "    sheet.cell(row=row_idx, column=5, value=data['Domain'])\n",
    "    sheet.cell(row=row_idx, column=6, value=data['Organization'])\n",
    "\n",
    "# Save the workbook\n",
    "workbook.save('extracted_data.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca806bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to calculate match scores and matched keywords while excluding stopwords\n",
    "def calculate_match_scores_and_matched_keywords(keywords, text, stopwords):\n",
    "    if not isinstance(text, str):\n",
    "        return 0, ''  # Return 0 if the text is not a string\n",
    "    \n",
    "    # Convert both keywords and text to lowercase for case-insensitive matching\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Remove stopwords from the original text\n",
    "    text_parts = [part for part in text_lower.split() if part not in stopwords]\n",
    "    text_without_stopwords = \" \".join(text_parts)\n",
    "    \n",
    "    # Convert both keywords to lowercase for case-insensitive matching\n",
    "    keywords_lower = [keyword.lower() for keyword in keywords]\n",
    "    \n",
    "    # Filter out stopwords from keywords\n",
    "    keywords_without_stopwords = [keyword for keyword in keywords_lower if keyword not in stopwords]\n",
    "    \n",
    "    # Find the matched keywords\n",
    "    matched_keywords = [keyword for keyword in keywords_without_stopwords if keyword in text_without_stopwords]\n",
    "    \n",
    "    # Calculate the match score percentage based on the count of unique matched keywords\n",
    "    match_score_percentage = len(set(matched_keywords)) / len(set(text_without_stopwords.split())) if text_without_stopwords else 0\n",
    "    \n",
    "    return match_score_percentage, ', '.join(matched_keywords)\n",
    "\n",
    "# Define a list of stopwords to exclude\n",
    "stopwords = [\"is\", \"and\", \"are\"]\n",
    "\n",
    "# Load the dataset with keywords (assuming it's in a separate Excel file)\n",
    "keywords_excel_path = 'path_to_keywords_excel_file.xlsx'\n",
    "keywords_data = pd.read_excel(keywords_excel_path)\n",
    "\n",
    "# Replace 'path_to_your_excel_file.xlsx' with the actual path to your Excel file with multiple sheets\n",
    "excel_file_path = 'path_to_your_excel_file.xlsx'\n",
    "\n",
    "# Create an Excel writer to save the matched data for each sheet in a separate sheet\n",
    "output_excel_path = 'matched_output.xlsx'\n",
    "with pd.ExcelWriter(output_excel_path, engine='xlsxwriter') as writer:\n",
    "    # Iterate through sheets in the Excel file with multiple sheets\n",
    "    for sheet_name in pd.ExcelFile(excel_file_path).sheet_names:\n",
    "        # Read the data from the current sheet\n",
    "        sheet_data = pd.read_excel(excel_file_path, sheet_name)\n",
    "        \n",
    "        # Initialize an empty list to store the matched data\n",
    "        matched_data = []\n",
    "        \n",
    "        # Iterate through both datasets and match keywords with text\n",
    "        for keywords_index, keywords_row in keywords_data.iterrows():\n",
    "            name = keywords_row['name']  # Assuming 'name' is a column in the keywords Excel file\n",
    "            address = keywords_row['address']  # Assuming 'address' is a column in the keywords Excel file\n",
    "            keywords = keywords_row['keywords'].split()  # Assuming keywords are separated by space\n",
    "            \n",
    "            print(f\"Matching keywords for {name} - {address} in sheet '{sheet_name}': {keywords}\")\n",
    "            \n",
    "            for row_index, row in sheet_data.iterrows():\n",
    "                text_column = 'text_column'  # Replace with the actual column name containing text in your Excel file\n",
    "                text = row[text_column]\n",
    "                \n",
    "                # Calculate match score percentage and matched keywords\n",
    "                match_score_percentage, matched_keywords = calculate_match_scores_and_matched_keywords(keywords, text, stopwords)\n",
    "                \n",
    "                # Add the \"horizontal\" column value from the current row in sheet_data\n",
    "                horizontal_value = row['horizontal']  # Replace 'horizontal' with the actual column name in your Excel file\n",
    "                \n",
    "                # Add the \"Section\" column value from the current row in sheet_data\n",
    "                section_value = row['Section']  # Replace 'Section' with the actual column name in your Excel file\n",
    "                \n",
    "                # Add the \"Controller\" column value from the current row in keywords_data\n",
    "                controller_value = keywords_row['Controller']  # Assuming 'Controller' is a column in the keywords Excel file\n",
    "                \n",
    "                # Append the matched data to the list\n",
    "                matched_data.append({\n",
    "                    'name': name,\n",
    "                    'address': address,\n",
    "                    'keywords': keywords_row['keywords'],\n",
    "                    'original_text': text,\n",
    "                    'matched_keywords': matched_keywords,\n",
    "                    'match_score %': match_score_percentage,  # This is the match score percentage\n",
    "                    'horizontal': horizontal_value,  # Adding the \"horizontal\" column\n",
    "                    'Section': section_value,  # Adding the \"Section\" column\n",
    "                    'Controller': controller_value,  # Adding the \"Controller\" column\n",
    "                })\n",
    "        \n",
    "        # Create a DataFrame from the matched data\n",
    "        matched_df = pd.DataFrame(matched_data)\n",
    "        \n",
    "        # Save the DataFrame to an Excel sheet for the current sheet\n",
    "        matched_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "        \n",
    "        # Display a message indicating that the data has been saved\n",
    "        print(f\"Matched data for sheet '{sheet_name}' has been saved to '{output_excel_path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1475a91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
